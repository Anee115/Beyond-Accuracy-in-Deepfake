{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d403f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python exe: c:\\Users\\aneek\\anaconda3\\envs\\tf_gpu_env\\python.exe\n",
      "python ver: 3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:49:16) [MSC v.1929 64 bit (AMD64)]\n",
      "torch      : 1.12.1+cu113 c:\\Users\\aneek\\anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\torch\\__init__.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aneek\\anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"python exe:\", sys.executable)   # full path to the interpreter\n",
    "print(\"python ver:\", sys.version)\n",
    "\n",
    "# try torch only in the working notebook\n",
    "try:\n",
    "    import torch\n",
    "    print(\"torch      :\", torch.__version__, torch.__file__)\n",
    "except ModuleNotFoundError as e:\n",
    "    print(\"torch not importable:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f959d74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "Num GPUs Available:  1\n",
      "CUDA version: 64_112\n",
      "cuDNN version: 64_8\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15113651829206502316\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5713690624\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12919620335628397997\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)  # This should print the version of TensorFlow\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "print(\"CUDA version:\", tf.sysconfig.get_build_info()[\"cuda_version\"])\n",
    "print(\"cuDNN version:\", tf.sysconfig.get_build_info()[\"cudnn_version\"])\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a940428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu113\n",
      "CUDA Available:  True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"CUDA Available: \", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d0ceea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow running on GPU: tf.Tensor(\n",
      "[[19. 22.]\n",
      " [43. 50.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow devices:\")\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "# Force TensorFlow to use GPU\n",
    "tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)\n",
    "\n",
    "# Test a simple matrix multiplication\n",
    "with tf.device('/GPU:0'):\n",
    "    a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "    b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "    print(\"TensorFlow running on GPU:\", c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "814f0ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch CUDA Version: 11.3\n",
      "Torch cuDNN Version: 8302\n",
      "Available GPUs: 1\n",
      "GPU Name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch CUDA Version:\", torch.version.cuda)\n",
    "print(\"Torch cuDNN Version:\", torch.backends.cudnn.version())\n",
    "print(\"Available GPUs:\", torch.cuda.device_count())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93f64a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated GPU memory: 0.00 GB\n",
      "Reserved GPU memory: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Allocated GPU memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "print(f\"Reserved GPU memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081143cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8baa7d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import psutil\n",
    "\n",
    "class PowerMonitor:\n",
    "    def __init__(self):\n",
    "        self.gpu_available = tf.config.list_physical_devices('GPU')\n",
    "        \n",
    "        # Hardware power specifications (adjust these values for your system)\n",
    "        self.cpu_tdp = 65    # Typical TDP for desktop CPUs in watts\n",
    "        self.gpu_tdp = 250   # Typical TDP for desktop GPUs in watts\n",
    "        \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get system stats with power estimation\"\"\"\n",
    "        stats = {\n",
    "            'timestamp': time.time(),\n",
    "            'cpu_%': psutil.cpu_percent(interval=0.1),\n",
    "            'ram_mb': psutil.virtual_memory().used / (1024**2),\n",
    "            'gpu_mem_mb': 0,\n",
    "            'power_w': self.cpu_tdp * (psutil.cpu_percent()/100) * 0.85  # Base CPU power\n",
    "        }\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            try:\n",
    "                # TensorFlow GPU memory monitoring\n",
    "                mem_info = tf.config.experimental.get_memory_info('GPU:0')\n",
    "                stats.update({\n",
    "                    'gpu_mem_mb': mem_info['current'] / (1024**2),\n",
    "                    'power_w': self.cpu_tdp * (psutil.cpu_percent()/100) * 0.85 + \n",
    "                              self.gpu_tdp * 0.5 * 0.75  # Add GPU power estimate\n",
    "                })\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        return stats\n",
    "\n",
    "# Initialize monitor\n",
    "monitor = PowerMonitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51f8d5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "class PowerMonitor1:\n",
    "    def __init__(self):\n",
    "        self.gpu_available = torch.cuda.is_available()\n",
    "        self.process = psutil.Process(os.getpid())  # Track current process\n",
    "        \n",
    "        # Hardware power specifications\n",
    "        self.cpu_tdp = 65\n",
    "        self.gpu_tdp = 250\n",
    "        \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get process-specific stats with power estimation\"\"\"\n",
    "        process_memory = self.process.memory_info()\n",
    "        \n",
    "        stats = {\n",
    "            'timestamp': time.time(),\n",
    "            'cpu_%': psutil.cpu_percent(interval=0.1),\n",
    "            'process_ram_mb': process_memory.rss / (1024**2),  # Only this process's RAM\n",
    "            'gpu_mem_mb': 0,\n",
    "            'power_w': self.cpu_tdp * (psutil.cpu_percent()/100) * 0.85\n",
    "        }\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            try:\n",
    "                gpu_memory_allocated = torch.cuda.memory_allocated()\n",
    "                stats.update({\n",
    "                    'gpu_mem_mb': gpu_memory_allocated / (1024**2),\n",
    "                    'power_w': self.cpu_tdp * (psutil.cpu_percent()/100) * 0.85 + \n",
    "                              self.gpu_tdp * 0.5 * 0.75\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error retrieving GPU memory: {e}\")\n",
    "                \n",
    "        return stats\n",
    "\n",
    "# Initialize monitor1\n",
    "monitor1 = PowerMonitor1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "997f0805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9870, 160, 160, 3), (11274, 160, 160, 3))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import h5py\n",
    "\n",
    "# Open the HDF5 file for reading\n",
    "#with h5py.File(\"D:\\\\thesis\\dataset\\deepfake dataset\\images_celeb_224R_processed.h5\", \"r\") as h5f:\n",
    "with h5py.File(\"D:\\\\thesis\\dataset\\Celeb-Df-v2\\images_celeb_balanced_224R_processed.h5\", \"r\") as h5f:\n",
    "    # Load HOG features\n",
    "    real_frames_array1 = h5f[\"ori_actor\"][:]\n",
    "    fake_frames_array1 = h5f[\"ori_youtube\"][:]\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Function to resize images from (224, 224) to (160, 160)\n",
    "def resize_images(image_array, target_size=(160, 160)):\n",
    "    resized_images = np.array([cv2.resize(img, target_size) for img in image_array])\n",
    "    return resized_images\n",
    "\n",
    "\n",
    "# Resize the images\n",
    "real_frames_array1 = resize_images(real_frames_array1, target_size=(160, 160))\n",
    "fake_frames_array1 = resize_images(fake_frames_array1, target_size=(160, 160))\n",
    "\n",
    "# Checking the new shapes\n",
    "real_frames_array1.shape, fake_frames_array1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b73ba021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data real shape: (6909, 160, 160, 3)\n",
      "Testing real data shape: (2961, 160, 160, 3)\n",
      "Training fake data shape: (7891, 160, 160, 3)\n",
      "Testing  fake data shape: (3383, 160, 160, 3)\n",
      "train_hog_real: 6218 images, val_hog_real: 691 images\n",
      "train_hog_fake: 7101 images, val_hog_fake: 790 images\n",
      "Total train: 13319 images\n",
      "Total test: 10852 images\n",
      "Total val: 1481 images\n",
      "Train Labels: 13319 \n",
      "Test Labels: 10852 \n",
      "Val Labels: 1481 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the data into train (70%) and test (30%)\n",
    "X_train_real, X_test_real = train_test_split(real_frames_array1, test_size=0.3, random_state=42)\n",
    "X_train_fake, X_test_fake = train_test_split(fake_frames_array1, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Output the shape to confirm the split dimensions\n",
    "print(\"Training data real shape:\", X_train_real.shape)\n",
    "print(\"Testing real data shape:\", X_test_real.shape)\n",
    "print(\"Training fake data shape:\", X_train_fake.shape)\n",
    "print(\"Testing  fake data shape:\", X_test_fake.shape)\n",
    "########################################################################################################################################\n",
    "#######################################divide into 60,10 train and val\n",
    "#########################################################################################################################################\n",
    "def extract_validation(train_data):\n",
    "    \"\"\"\n",
    "    Extract every 10th sample from the training data and store it in a validation set.\n",
    "\n",
    "    Parameters:\n",
    "        train_data (list or np.array): The training dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated training dataset and validation dataset.\n",
    "    \"\"\"\n",
    "    # Select every 10th sample for the validation set\n",
    "    validation_data = train_data[::10]\n",
    "\n",
    "    # Remove the selected samples from the training dataset\n",
    "    updated_train_data = [train_data[i] for i in range(len(train_data)) if i % 10 != 0]\n",
    "\n",
    "    return np.array(updated_train_data), np.array(validation_data)\n",
    "\n",
    "\n",
    "# Perform the operation for each dataset\n",
    "train_hog_real, val_hog_real = extract_validation(X_train_real)\n",
    "train_hog_fake, val_hog_fake = extract_validation(X_train_fake)\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"train_hog_real: {len(train_hog_real)} images, val_hog_real: {len(val_hog_real)} images\")\n",
    "print(f\"train_hog_fake: {len(train_hog_fake)} images, val_hog_fake: {len(val_hog_fake)} images\")\n",
    "\n",
    "\n",
    "############################################################################################################################################################\n",
    "#################################################concatenate the labels 0,1 real and fake\n",
    "#############################################################################################################################################################\n",
    "\n",
    "\n",
    "train_labels_real = np.zeros(len(train_hog_real), dtype=int)\n",
    "train_labels_fake = np.ones(len(train_hog_fake), dtype=int)\n",
    "\n",
    "# Concatenate all training datasets into a single `train` variable\n",
    "train = np.concatenate([train_hog_real, train_hog_fake], axis=0)\n",
    "train_labels=np.concatenate([train_labels_real, train_labels_fake], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "test_labels_real = np.zeros(len(X_test_real), dtype=int)\n",
    "test_labels_fake = np.ones(len(X_train_fake), dtype=int)\n",
    "\n",
    "# Concatenate all testing datasets into a single `test` variable\n",
    "test = np.concatenate([X_test_real, X_train_fake], axis=0)\n",
    "test_labels = np.concatenate([test_labels_real, test_labels_fake], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "val_labels_real = np.zeros(len(val_hog_real), dtype=int)\n",
    "val_labels_fake = np.ones(len(val_hog_fake), dtype=int)\n",
    "\n",
    "# Concatenate all validation datasets into a single `val` variable\n",
    "val = np.concatenate([val_hog_real, val_hog_fake], axis=0)\n",
    "val_labels = np.concatenate([val_labels_real, val_labels_fake], axis=0)\n",
    "\n",
    "# Print the results for verification\n",
    "print(f\"Total train: {len(train)} images\")\n",
    "print(f\"Total test: {len(test)} images\")\n",
    "print(f\"Total val: {len(val)} images\")\n",
    "\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"Train Labels: {len(train_labels)} \")\n",
    "print(f\"Test Labels: {len(test_labels)} \")\n",
    "print(f\"Val Labels: {len(val_labels)} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec3b0a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10946bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aneek\\anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\huggingface_hub\\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n",
      "Some weights of Swinv2ForImageClassification were not initialized from the model checkpoint at microsoft/swinv2-tiny-patch4-window8-256 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import AutoImageProcessor, Swinv2ForImageClassification, Swinv2Config\n",
    "\n",
    "\n",
    "# Load Swin Transformer V2 model and processor for image classification\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/swinv2-tiny-patch4-window8-256\")\n",
    "config = Swinv2Config.from_pretrained(\"microsoft/swinv2-tiny-patch4-window8-256\")\n",
    "\n",
    "# Modify for binary classification\n",
    "config.num_labels = 2\n",
    "\n",
    "# Load model and update classifier head\n",
    "model = Swinv2ForImageClassification.from_pretrained(\n",
    "    \"microsoft/swinv2-tiny-patch4-window8-256\",\n",
    "    config=config,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "model.classifier = nn.Linear(model.classifier.in_features, config.num_labels)\n",
    "\n",
    "\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Dataset class\n",
    "class ImageClassificationDataset(Dataset):\n",
    "    def __init__(self, images, labels, processor):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = Image.fromarray(image)\n",
    "        elif isinstance(image, str):\n",
    "            image = Image.open(image).convert(\"RGB\")\n",
    "\n",
    "        inputs = self.processor(images=image, return_tensors=\"pt\")\n",
    "        return {k: v.squeeze(0) for k, v in inputs.items()}, torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e5c0e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, val_loader, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs, labels = batch\n",
    "            inputs = {key: val.to(device).float() for key, val in inputs.items()}  # Ensure float32\n",
    "            labels = labels.to(device).long()  # Ensure labels are long\n",
    "            optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)  # Lower learning rate\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs).logits\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss = criterion(outputs.float(), labels)  # Convert logits to float32\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_acc = correct / total\n",
    "        val_acc = evaluate(model, val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Loss: {total_loss/len(train_loader):.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            inputs, labels = batch\n",
    "            inputs = {key: val.to(device).float() for key, val in inputs.items()}  # Ensure float32\n",
    "            labels = labels.to(device).long()  # Ensure labels are long\n",
    "\n",
    "            outputs = model(**inputs).logits\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea219257",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Convert data into PyTorch Dataset\n",
    "train_dataset = ImageClassificationDataset(train, train_labels, processor)\n",
    "val_dataset = ImageClassificationDataset(val, val_labels, processor)\n",
    "test_dataset = ImageClassificationDataset(test, test_labels, processor)\n",
    "\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "205c788a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 0.5689 | Train Acc: 0.7096 | Val Acc: 0.7502\n",
      "Epoch 2/10 | Loss: 0.3123 | Train Acc: 0.8896 | Val Acc: 0.8859\n",
      "Epoch 3/10 | Loss: 0.3119 | Train Acc: 0.9492 | Val Acc: 0.9338\n",
      "Epoch 4/10 | Loss: 0.2487 | Train Acc: 0.9738 | Val Acc: 0.9615\n",
      "Epoch 5/10 | Loss: 0.1829 | Train Acc: 0.9832 | Val Acc: 0.9561\n",
      "Epoch 6/10 | Loss: 0.1085 | Train Acc: 0.9908 | Val Acc: 0.9467\n",
      "Epoch 7/10 | Loss: 0.0964 | Train Acc: 0.9926 | Val Acc: 0.9730\n",
      "Epoch 8/10 | Loss: 0.0600 | Train Acc: 0.9947 | Val Acc: 0.9689\n",
      "Epoch 9/10 | Loss: 0.0236 | Train Acc: 0.9986 | Val Acc: 0.9770\n",
      "Epoch 10/10 | Loss: 0.0188 | Train Acc: 0.9985 | Val Acc: 0.9716\n",
      "Test Accuracy: 0.9927\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 10  # Increase epochs for better accuracy\n",
    "train_model(model, train_loader, val_loader, epochs)\n",
    "\n",
    "# Final evaluation on test data\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b73baa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n",
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 4.5%\n",
      "Time Usage: 220.1 s\n",
      "GPU Memory Used: 220.6 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor1.get_stats()\n",
    "# Final evaluation on test data\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "#7.7 gpu\n",
    "\n",
    "end = monitor1.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")#7.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd042556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9927\n",
      "Recall: 0.9927\n",
      "F1 Score: 0.9927\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_metrics(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            inputs, labels = batch\n",
    "            inputs = {key: val.to(device).float() for key, val in inputs.items()}\n",
    "            labels = labels.to(device).long()\n",
    "\n",
    "            outputs = model(**inputs).logits\n",
    "            preds = outputs.argmax(1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Calculate metrics on test data\n",
    "precision, recall, f1 = evaluate_metrics(model, test_loader)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05f93db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DFC on Celebdf ON (swimtransformer): 0.5187\n"
     ]
    }
   ],
   "source": [
    "# Convert data into PyTorch Dataset\n",
    "test_dataset = ImageClassificationDataset(test_hog, test_labels, processor)\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "# Final evaluation on test data\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "print(f\"Test Accuracy of DFC on Celebdf ON (swimtransformer): {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5685926d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of FF++ on Celebdf ON (swimtransformer): 0.3454\n"
     ]
    }
   ],
   "source": [
    "# Convert data into PyTorch Dataset\n",
    "test_dataset = ImageClassificationDataset(test_ff, test_labels_ff, processor)\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "# Final evaluation on test data\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "print(f\"Test Accuracy of FF++ on Celebdf ON (swimtransformer): {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d8c3e0",
   "metadata": {},
   "source": [
    "# DFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd444431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celeb shape: (5000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (5000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "celeb shape: (2500, 160, 160, 3), dtype: uint8\n",
      "ffhq shape: (2500, 160, 160, 3), dtype: uint8\n",
      "gdwct shape: (1000, 160, 160, 3), dtype: uint8\n",
      "attagan shape: (1000, 160, 160, 3), dtype: uint8\n",
      "stargan shape: (1000, 160, 160, 3), dtype: uint8\n",
      "stylegan2 shape: (1000, 160, 160, 3), dtype: uint8\n",
      "stylegan shape: (1000, 160, 160, 3), dtype: uint8\n",
      "celeb_train: 1750 images, celeb_test: 750 images\n",
      "ffhq_train: 1750 images, ffhq_test: 750 images\n",
      "attgan_train: 700 images, attgan_test: 300 images\n",
      "stargan_train: 700 images, stargan_test: 300 images\n",
      "gdwct_train: 700 images, gdwct_test: 300 images\n",
      "stylegan2_train: 700 images, stylegan2_test: 300 images\n",
      "stylegan_train: 700 images, stylegan_test: 300 images\n",
      "celeb_train: 1575 images, celeb_val: 175 images\n",
      "ffhq_train: 1575 images, ffhq_val: 175 images\n",
      "attgan_train: 630 images, attgan_val: 70 images\n",
      "stargan_train: 630 images, stargan_val: 70 images\n",
      "gdwct_train: 630 images, gdwct_val: 70 images\n",
      "stylegan2_train: 630 images, stylegan2_val: 70 images\n",
      "stylegan_train: 630 images, stylegan_val: 70 images\n",
      "Total train: 6300 images\n",
      "Total test: 3000 images\n",
      "Total val: 700 images\n",
      "Train Labels: 6300 \n",
      "Test Labels: 3000 \n",
      "Val Labels: 700 \n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "# Open the HDF5 file in read mode\n",
    "with h5py.File('D://thesis//dataset//deepfake dataset//resized_images.h5', 'r') as h5f:\n",
    "    # Access each dataset\n",
    "    celeb = np.array(h5f['celeb'])\n",
    "    ffhq = np.array(h5f['ffhq'])\n",
    "    gdwct = np.array(h5f['gdwct'])\n",
    "    attgan = np.array(h5f['attgan'])\n",
    "    stargan = np.array(h5f['stargan'])\n",
    "    stylegan2 = np.array(h5f['stylegan2'])\n",
    "    stylegan = np.array(h5f['stylegan'])\n",
    "\n",
    "# Now, 'celeb', 'ffhq', etc., are NumPy arrays containing your datasets\n",
    "print(f\"celeb shape: {celeb.shape}, dtype: {celeb.dtype}\")\n",
    "print(f\"ffhq shape: {ffhq.shape}, dtype: {ffhq.dtype}\")\n",
    "print(f\"ffhq shape: {gdwct.shape}, dtype: {gdwct.dtype}\")\n",
    "print(f\"ffhq shape: {attgan.shape}, dtype: {attgan.dtype}\")\n",
    "print(f\"ffhq shape: {stargan.shape}, dtype: {stargan.dtype}\")\n",
    "print(f\"ffhq shape: {stylegan2.shape}, dtype: {stylegan2.dtype}\")\n",
    "print(f\"ffhq shape: {stylegan.shape}, dtype: {stylegan.dtype}\")\n",
    "# Repeat for other datasets as needed\n",
    "import cv2\n",
    "# Function to resize images from (224, 224) to (160, 160)\n",
    "def resize_images(image_array, target_size=(160, 160)):\n",
    "    resized_images = np.array([cv2.resize(img, target_size) for img in image_array])\n",
    "    return resized_images\n",
    "\n",
    "celeb = resize_images(celeb, target_size=(160, 160))\n",
    "ffhq = resize_images(ffhq, target_size=(160, 160))\n",
    "gdwct = resize_images(gdwct, target_size=(160, 160))\n",
    "attgan = resize_images(attgan, target_size=(160, 160))\n",
    "stargan = resize_images(stargan, target_size=(160, 160))\n",
    "stylegan = resize_images(stargan, target_size=(160, 160))\n",
    "stylegan2 = resize_images(stylegan2, target_size=(160, 160))\n",
    "import random\n",
    "# Randomly select 2500 distinct images\n",
    "random_indices = random.sample(range(len(celeb)), 2500)  # Get 2500 random indices\n",
    "celeb = celeb[random_indices]  # Select the random subse\n",
    "\n",
    "import random\n",
    "# Randomly select 2500 distinct images\n",
    "random_indices = random.sample(range(len(ffhq)), 2500)  # Get 2500 random indices\n",
    "ffhq = ffhq[random_indices]  # Select the random subse\n",
    "print(f\"celeb shape: {celeb.shape}, dtype: {celeb.dtype}\")\n",
    "print(f\"ffhq shape: {ffhq.shape}, dtype: {ffhq.dtype}\")\n",
    "print(f\"gdwct shape: {gdwct.shape}, dtype: {gdwct.dtype}\")\n",
    "print(f\"attagan shape: {attgan.shape}, dtype: {attgan.dtype}\")\n",
    "print(f\"stargan shape: {stargan.shape}, dtype: {stargan.dtype}\")\n",
    "print(f\"stylegan2 shape: {stylegan2.shape}, dtype: {stylegan2.dtype}\")\n",
    "print(f\"stylegan shape: {stylegan.shape}, dtype: {stylegan.dtype}\")\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def split_data(data, train_ratio=0.7):\n",
    "    \"\"\"\n",
    "    Splits data into training and testing sets based on the specified ratio.\n",
    "\n",
    "    Parameters:\n",
    "        data (list or np.array): The dataset to split.\n",
    "        train_ratio (float): The ratio of the data to include in the training set.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two datasets - train and test.\n",
    "    \"\"\"\n",
    "    # Shuffle the data\n",
    "    random.shuffle(data)\n",
    "\n",
    "    # Calculate the split index\n",
    "    split_index = int(len(data) * train_ratio)\n",
    "\n",
    "    # Split the data\n",
    "    train_data = data[:split_index]\n",
    "    test_data = data[split_index:]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "# Split `celeb` into 70% train and 30% test\n",
    "celeb_train_hog, celeb_test_hog = split_data(celeb, train_ratio=0.7)\n",
    "\n",
    "# Split `ffhq` into 70% train and 30% test\n",
    "ffhq_train_hog, ffhq_test_hog = split_data(ffhq, train_ratio=0.7)\n",
    "\n",
    "# Split `attgan` into 70% train and 30% test\n",
    "attgan_train_hog, attgan_test_hog = split_data(attgan, train_ratio=0.7)\n",
    "\n",
    "# Split `stargan` into 70% train and 30% test\n",
    "stargan_train_hog, stargan_test_hog = split_data(stargan, train_ratio=0.7)\n",
    "\n",
    "# Split `gdwct` into 70% train and 30% test\n",
    "gdwct_train_hog, gdwct_test_hog = split_data(gdwct, train_ratio=0.7)\n",
    "\n",
    "# Split `stylegan2` into 70% train and 30% test_hog\n",
    "stylegan2_train_hog, stylegan2_test_hog = split_data(stylegan2, train_ratio=0.7)\n",
    "\n",
    "# Split `stylegan` into 70% train and 30% test_hog\n",
    "stylegan_train_hog, stylegan_test_hog = split_data(stylegan, train_ratio=0.7)\n",
    "\n",
    "# Convert to NumPy arrays if needed\n",
    "celeb_train_hog, celeb_test_hog = np.array(celeb_train_hog), np.array(celeb_test_hog)\n",
    "ffhq_train_hog, ffhq_test_hog = np.array(ffhq_train_hog), np.array(ffhq_test_hog)\n",
    "attgan_train_hog, attgan_test_hog = np.array(attgan_train_hog), np.array(attgan_test_hog)\n",
    "stargan_train_hog, stargan_test_hog = np.array(stargan_train_hog), np.array(stargan_test_hog)\n",
    "gdwct_train_hog, gdwct_test_hog = np.array(gdwct_train_hog), np.array(gdwct_test_hog)\n",
    "stylegan2_train_hog, stylegan2_test_hog = np.array(stylegan2_train_hog), np.array(stylegan2_test_hog)\n",
    "stylegan_train_hog, stylegan_test_hog = np.array(stylegan_train_hog), np.array(stylegan_test_hog)\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"celeb_train: {len(celeb_train_hog)} images, celeb_test: {len(celeb_test_hog)} images\")\n",
    "print(f\"ffhq_train: {len(ffhq_train_hog)} images, ffhq_test: {len(ffhq_test_hog)} images\")\n",
    "print(f\"attgan_train: {len(attgan_train_hog)} images, attgan_test: {len(attgan_test_hog)} images\")\n",
    "print(f\"stargan_train: {len(stargan_train_hog)} images, stargan_test: {len(stargan_test_hog)} images\")\n",
    "print(f\"gdwct_train: {len(gdwct_train_hog)} images, gdwct_test: {len(gdwct_test_hog)} images\")\n",
    "print(f\"stylegan2_train: {len(stylegan2_train_hog)} images, stylegan2_test: {len(stylegan2_test_hog)} images\")\n",
    "print(f\"stylegan_train: {len(stylegan_train_hog)} images, stylegan_test: {len(stylegan_test_hog)} images\")\n",
    "\n",
    "########################################################################################################################################\n",
    "#######################################divide into 60,10 train and val\n",
    "#########################################################################################################################################\n",
    "def extract_validation(train_data):\n",
    "    \"\"\"\n",
    "    Extract every 10th sample from the training data and store it in a validation set.\n",
    "\n",
    "    Parameters:\n",
    "        train_data (list or np.array): The training dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated training dataset and validation dataset.\n",
    "    \"\"\"\n",
    "    # Select every 10th sample for the validation set\n",
    "    validation_data = train_data[::10]\n",
    "\n",
    "    # Remove the selected samples from the training dataset\n",
    "    updated_train_data = [train_data[i] for i in range(len(train_data)) if i % 10 != 0]\n",
    "\n",
    "    return np.array(updated_train_data), np.array(validation_data)\n",
    "\n",
    "\n",
    "# Perform the operation for each dataset\n",
    "celeb_train_hog, celeb_val_hog = extract_validation(celeb_train_hog)\n",
    "ffhq_train_hog, ffhq_val_hog = extract_validation(ffhq_train_hog)\n",
    "attgan_train_hog, attgan_val_hog = extract_validation(attgan_train_hog)\n",
    "stargan_train_hog, stargan_val_hog = extract_validation(stargan_train_hog)\n",
    "gdwct_train_hog, gdwct_val_hog = extract_validation(gdwct_train_hog)\n",
    "stylegan2_train_hog, stylegan2_val_hog = extract_validation(stylegan2_train_hog)\n",
    "stylegan_train_hog, stylegan_val_hog = extract_validation(stylegan_train_hog)\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"celeb_train: {len(celeb_train_hog)} images, celeb_val: {len(celeb_val_hog)} images\")\n",
    "print(f\"ffhq_train: {len(ffhq_train_hog)} images, ffhq_val: {len(ffhq_val_hog)} images\")\n",
    "print(f\"attgan_train: {len(attgan_train_hog)} images, attgan_val: {len(attgan_val_hog)} images\")\n",
    "print(f\"stargan_train: {len(stargan_train_hog)} images, stargan_val: {len(stargan_val_hog)} images\")\n",
    "print(f\"gdwct_train: {len(gdwct_train_hog)} images, gdwct_val: {len(gdwct_val_hog)} images\")\n",
    "print(f\"stylegan2_train: {len(stylegan2_train_hog)} images, stylegan2_val: {len(stylegan2_val_hog)} images\")\n",
    "print(f\"stylegan_train: {len(stylegan_train_hog)} images, stylegan_val: {len(stylegan_val_hog)} images\")\n",
    "############################################################################################################################################################\n",
    "#################################################concatenate the labels 0,1 real and fake\n",
    "#############################################################################################################################################################\n",
    "\n",
    "\n",
    "celeb_train_labels = np.zeros(len(celeb_train_hog), dtype=int)\n",
    "ffhq_train_labels = np.zeros(len(ffhq_train_hog), dtype=int)\n",
    "atta_train_labels = np.ones(len(attgan_train_hog), dtype=int)\n",
    "star_train_labels = np.ones(len(stargan_train_hog), dtype=int)\n",
    "gdwct_train_labels = np.ones(len(gdwct_train_hog), dtype=int)\n",
    "stylegan2_train_labels = np.ones(len(stylegan2_train_hog), dtype=int)\n",
    "stylegan_train_labels = np.ones(len(stylegan_train_hog), dtype=int)\n",
    "\n",
    "# Concatenate all training datasets into a single `train` variable\n",
    "train_hog = np.concatenate([celeb_train_hog, ffhq_train_hog, attgan_train_hog, stargan_train_hog, gdwct_train_hog, stylegan2_train_hog, stylegan_train_hog], axis=0)\n",
    "train_labels=np.concatenate([celeb_train_labels, ffhq_train_labels, atta_train_labels, star_train_labels, gdwct_train_labels, stylegan2_train_labels,\n",
    "                              stylegan_train_labels], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "celeb_test_labels = np.zeros(len(celeb_test_hog), dtype=int)\n",
    "ffhq_test_labels = np.zeros(len(ffhq_test_hog), dtype=int)\n",
    "atta_test_labels = np.ones(len(attgan_test_hog), dtype=int)\n",
    "star_test_labels = np.ones(len(stargan_test_hog), dtype=int)\n",
    "gdwct_test_labels = np.ones(len(gdwct_test_hog), dtype=int)\n",
    "stylegan2_test_labels = np.ones(len(stylegan2_test_hog), dtype=int)\n",
    "stylegan_test_labels = np.ones(len(stylegan_test_hog), dtype=int)\n",
    "\n",
    "# Concatenate all testing datasets into a single `test` variable\n",
    "test_hog = np.concatenate([celeb_test_hog, ffhq_test_hog, attgan_test_hog, stargan_test_hog, gdwct_test_hog, stylegan2_test_hog, stylegan_test_hog], axis=0)\n",
    "test_labels = np.concatenate([celeb_test_labels, ffhq_test_labels, atta_test_labels, star_test_labels, gdwct_test_labels, stylegan2_test_labels,\n",
    "                        stylegan_test_labels], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "celeb_val_labels = np.zeros(len(celeb_val_hog), dtype=int)\n",
    "ffhq_val_labels = np.zeros(len(ffhq_val_hog), dtype=int)\n",
    "atta_val_labels = np.ones(len(attgan_val_hog), dtype=int)\n",
    "star_val_labels = np.ones(len(stargan_val_hog), dtype=int)\n",
    "gdwct_val_labels = np.ones(len(gdwct_val_hog), dtype=int)\n",
    "stylegan2_val_labels = np.ones(len(stylegan2_val_hog), dtype=int)\n",
    "stylegan_val_labels = np.ones(len(stylegan_val_hog), dtype=int)\n",
    "\n",
    "# Concatenate all validation datasets into a single `val` variable\n",
    "val_hog = np.concatenate([celeb_val_hog, ffhq_val_hog, attgan_val_hog, stargan_val_hog, gdwct_val_hog, stylegan2_val_hog, stylegan_val_hog], axis=0)\n",
    "val_labels = np.concatenate([celeb_val_labels, ffhq_val_labels, atta_val_labels, star_val_labels, gdwct_val_labels, stylegan2_val_labels,\n",
    "                       stylegan_val_labels], axis=0)\n",
    "\n",
    "# Print the results for verification\n",
    "print(f\"Total train: {len(train_hog)} images\")\n",
    "print(f\"Total test: {len(test_hog)} images\")\n",
    "print(f\"Total val: {len(val_hog)} images\")\n",
    "\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"Train Labels: {len(train_labels)} \")\n",
    "print(f\"Test Labels: {len(test_labels)} \")\n",
    "print(f\"Val Labels: {len(val_labels)} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e28547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into PyTorch Dataset\n",
    "train_dataset = ImageClassificationDataset(train_hog, train_labels, processor)\n",
    "val_dataset = ImageClassificationDataset(val_hog, val_labels, processor)\n",
    "test_dataset = ImageClassificationDataset(test_hog, test_labels, processor)\n",
    "\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bfc558a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 0.3232 | Train Acc: 0.8870 | Val Acc: 0.9943\n",
      "Epoch 2/10 | Loss: 0.0716 | Train Acc: 0.9924 | Val Acc: 0.9986\n",
      "Epoch 3/10 | Loss: 0.0037 | Train Acc: 0.9997 | Val Acc: 0.9986\n",
      "Epoch 4/10 | Loss: 0.0026 | Train Acc: 0.9997 | Val Acc: 0.9986\n",
      "Epoch 5/10 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.9986\n",
      "Epoch 6/10 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.9986\n",
      "Epoch 7/10 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.9986\n",
      "Epoch 8/10 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.9986\n",
      "Epoch 9/10 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.9986\n",
      "Epoch 10/10 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.9986\n",
      "Test Accuracy: 0.9980\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 10  # Increase epochs for better accuracy\n",
    "train_model(model, train_loader, val_loader, epochs)\n",
    "\n",
    "# Final evaluation on test data\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad15658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n",
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 1.8%\n",
      "Time Usage: 528.7 s\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor.get_stats()\n",
    "# Final evaluation on test data\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "#7.7 gpu\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd1325ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n",
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 6.2%\n",
      "Time Usage: 115.0 s\n",
      "GPU Memory Used: 220.6 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor1.get_stats()\n",
    "# Final evaluation on test data\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "#7.7 gpu\n",
    "\n",
    "end = monitor1.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")#7.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aee1300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9980\n",
      "Recall: 0.9980\n",
      "F1 Score: 0.9980\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_metrics(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            inputs, labels = batch\n",
    "            inputs = {key: val.to(device).float() for key, val in inputs.items()}\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            labels = labels.to(device).long()\n",
    "\n",
    "            outputs = model(**inputs).logits\n",
    "            preds = outputs.argmax(1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Calculate metrics on test data\n",
    "precision, recall, f1 = evaluate_metrics(model, test_loader)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eaeec15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of Celeb-DFv2 on DFC ON (Swim Transformer): 0.7017\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ImageClassificationDataset(test, test_labels, processor)\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "# Final evaluation on test data\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "print(f\"Test Accuracy of Celeb-DFv2 on DFC ON (Swim Transformer): {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2178af46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of FF++ on dfc ON (Swim Transformer): 0.6726\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ImageClassificationDataset(test_ff, test_labels_ff, processor)\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "# Final evaluation on test data\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "print(f\"Test Accuracy of FF++ on dfc ON (Swim Transformer): {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f578dba",
   "metadata": {},
   "source": [
    "# FF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "405bec66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from the HDF5 file.\n",
      "Data loaded successfully from the HDF5 file.\n",
      "Data loaded successfully from the HDF5 file.\n",
      "Data loaded successfully from the HDF5 file.\n",
      "Shape of the concatenated array: (2808, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (3299, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (1742, 160, 160, 3)\n",
      "Shape of the concatenated array: (1742, 160, 160, 3)\n",
      "Training data ACTOR real shape: (1965, 160, 160, 3) Testing real data shape: (843, 160, 160, 3)\n",
      "Training data Youtube real shape: (1458, 160, 160, 3) Testing real data shape: (625, 160, 160, 3)\n",
      "Training data DFD fake shape: (2309, 160, 160, 3) Testing fake data shape: (990, 160, 160, 3)\n",
      "Training data DF fake shape: (1458, 160, 160, 3) Testing fake data shape: (625, 160, 160, 3)\n",
      "Training data f2f fake shape: (1458, 160, 160, 3) Testing fake data shape: (625, 160, 160, 3)\n",
      "Training data fshifter fake shape: (1458, 160, 160, 3) Testing fake data shape: (625, 160, 160, 3)\n",
      "Training data fswap fake shape: (1219, 160, 160, 3) Testing fake data shape: (523, 160, 160, 3)\n",
      "Training data nt fake shape: (1219, 160, 160, 3) Testing fake data shape: (523, 160, 160, 3)\n",
      "train_ori_actor hog_real: 1768 images, val_ori_actor hog_real: 197 images\n",
      "train_ ori_youtube hog_real: 1312 images, val_ ori_youtube hog_real: 146 images\n",
      "train_hog_mni_dfd_fake: 2078 images, val_hog_mni_dfd_fake: 231 images\n",
      "train_hog_mni_df_fake: 1312 images, val_hog_mni_df_fake: 146 images\n",
      "train_hog_mni_f2f_fake: 1312 images, val_hog_mni_f2f_fake: 146 images\n",
      "train_hog_mni_fshifter_fake: 1312 images, val_hog_mni_fshifter_fake: 146 images\n",
      "train_hog_mni_fswap_fake: 1097 images, val_hog_mni_fswap_fake: 122 images\n",
      "train_hog_mni_nt_fake: 1097 images, val_hog_mni_nt_fake: 122 images\n",
      "Total train: 11288 images, and shape:(11288, 160, 160, 3)\n",
      "Total test: 5379 images, and shape:(5379, 160, 160, 3)\n",
      "Total val: 1256 images, and shape:(1256, 160, 160, 3)\n",
      "Train Labels: 11288 \n",
      "Test Labels: 5379 \n",
      "Val Labels: 1256 \n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the HDF5 file for reading\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_orignal_processed.h5\", \"r\") as h5f:\n",
    "    org_seq_actor_array = h5f[\"ori_actor\"][:]\n",
    "    org_seq_youtube_array = h5f[\"ori_youtube\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_fake1_processed.h5\", \"r\") as h5f:\n",
    "    meni_seq_dfd_array = h5f[\"mni_dfd\"][:]\n",
    "    meni_seq_df_array = h5f[\"mni_df\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_fake2_processed.h5\", \"r\") as h5f:\n",
    "    meni_seq_f2f_array = h5f[\"mni_f2f\"][:]\n",
    "    meni_seq_fshifter_array = h5f[\"mni_fshifter\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_fake3_processed.h5\", \"r\") as h5f:\n",
    "    meni_seq_fswap_array = h5f[\"mni_fswap\"][:]\n",
    "    meni_seq_nt_array = h5f[\"mni_nt\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "# Output the shape of the resulting array\n",
    "print(f\"Shape of the concatenated array: {org_seq_actor_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {org_seq_youtube_array.shape}\")\n",
    "\n",
    "print(f\"Shape of the concatenated array: {meni_seq_dfd_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_df_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_fshifter_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_f2f_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_fswap_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_nt_array.shape}\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ori_actor_train_real, ori_actor_test_real = train_test_split(org_seq_actor_array, test_size=0.3, random_state=42)\n",
    "ori_youtube_train_real, ori_youtube_test_real = train_test_split(org_seq_youtube_array, test_size=0.3, random_state=42)\n",
    "# Split the data into train (70%) and test (30%)\n",
    "mni_dfd_train_fake, mni_dfd_test_fake = train_test_split(meni_seq_dfd_array, test_size=0.3, random_state=42)\n",
    "mni_df_train_fake, mni_df_test_fake = train_test_split(meni_seq_df_array, test_size=0.3, random_state=42)\n",
    "mni_f2f_train_fake, mni_f2f_test_fake = train_test_split(meni_seq_f2f_array, test_size=0.3, random_state=42)\n",
    "mni_fshifter_train_fake, mni_fshifter_test_fake = train_test_split(meni_seq_fshifter_array, test_size=0.3, random_state=42)\n",
    "mni_fswap_train_fake, mni_fswap_test_fake = train_test_split(meni_seq_fswap_array, test_size=0.3, random_state=42)\n",
    "mni_nt_train_fake, mni_nt_test_fake = train_test_split(meni_seq_nt_array, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Output the shape to confirm the split dimensions\n",
    "print(\"Training data ACTOR real shape:\", ori_actor_train_real.shape, \"Testing real data shape:\", ori_actor_test_real.shape)\n",
    "print(\"Training data Youtube real shape:\", ori_youtube_train_real.shape, \"Testing real data shape:\", ori_youtube_test_real.shape)\n",
    "\n",
    "print(\"Training data DFD fake shape:\", mni_dfd_train_fake.shape, \"Testing fake data shape:\", mni_dfd_test_fake.shape)\n",
    "print(\"Training data DF fake shape:\", mni_df_train_fake.shape, \"Testing fake data shape:\", mni_df_test_fake.shape)\n",
    "print(\"Training data f2f fake shape:\", mni_f2f_train_fake.shape, \"Testing fake data shape:\", mni_f2f_test_fake.shape)\n",
    "print(\"Training data fshifter fake shape:\", mni_fshifter_train_fake.shape, \"Testing fake data shape:\", mni_fshifter_test_fake.shape)\n",
    "print(\"Training data fswap fake shape:\", mni_fswap_train_fake.shape, \"Testing fake data shape:\", mni_fswap_test_fake.shape)\n",
    "print(\"Training data nt fake shape:\", mni_nt_train_fake.shape, \"Testing fake data shape:\", mni_nt_test_fake.shape)\n",
    "########################################################################################################################################\n",
    "#######################################divide into 60,10 train and val\n",
    "#########################################################################################################################################\n",
    "def extract_validation(train_data):\n",
    "    \"\"\"\n",
    "    Extract every 10th sample from the training data and store it in a validation set.\n",
    "\n",
    "    Parameters:\n",
    "        train_data (list or np.array): The training dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated training dataset and validation dataset.\n",
    "    \"\"\"\n",
    "    # Select every 10th sample for the validation set\n",
    "    validation_data = train_data[::10]\n",
    "\n",
    "    # Remove the selected samples from the training dataset\n",
    "    updated_train_data = [train_data[i] for i in range(len(train_data)) if i % 10 != 0]\n",
    "\n",
    "    return np.array(updated_train_data), np.array(validation_data)\n",
    "\n",
    "\n",
    "# Perform the operation for each dataset\n",
    "train_hog_ori_actor_real, val_hog_ori_actor_real = extract_validation(ori_actor_train_real)\n",
    "train_hog_ori_youtube_real, val_hog_ori_youtube_real = extract_validation(ori_youtube_train_real)\n",
    "train_hog_mni_dfd_fake, val_hog_mni_dfd_fake = extract_validation(mni_dfd_train_fake)\n",
    "train_hog_mni_df_fake, val_hog_mni_df_fake = extract_validation(mni_df_train_fake)\n",
    "train_hog_mni_f2f_fake, val_hog_mni_f2f_fake = extract_validation(mni_f2f_train_fake)\n",
    "train_hog_mni_fshifter_fake, val_hog_mni_fshifter_fake = extract_validation(mni_fshifter_train_fake)\n",
    "train_hog_mni_fswap_fake, val_hog_mni_fswap_fake = extract_validation(mni_fswap_train_fake)\n",
    "train_hog_mni_nt_fake, val_hog_mni_nt_fake = extract_validation(mni_nt_train_fake)\n",
    "# Print results for verification\n",
    "print(f\"train_ori_actor hog_real: {len(train_hog_ori_actor_real)} images, val_ori_actor hog_real: {len(val_hog_ori_actor_real)} images\")\n",
    "print(f\"train_ ori_youtube hog_real: {len(train_hog_ori_youtube_real)} images, val_ ori_youtube hog_real: {len(val_hog_ori_youtube_real)} images\")\n",
    "print(f\"train_hog_mni_dfd_fake: {len(train_hog_mni_dfd_fake)} images, val_hog_mni_dfd_fake: {len(val_hog_mni_dfd_fake)} images\")\n",
    "print(f\"train_hog_mni_df_fake: {len(train_hog_mni_df_fake)} images, val_hog_mni_df_fake: {len(val_hog_mni_df_fake)} images\")\n",
    "print(f\"train_hog_mni_f2f_fake: {len(train_hog_mni_f2f_fake)} images, val_hog_mni_f2f_fake: {len(val_hog_mni_f2f_fake)} images\")\n",
    "print(f\"train_hog_mni_fshifter_fake: {len(train_hog_mni_fshifter_fake)} images, val_hog_mni_fshifter_fake: {len(val_hog_mni_fshifter_fake)} images\")\n",
    "print(f\"train_hog_mni_fswap_fake: {len(train_hog_mni_fswap_fake)} images, val_hog_mni_fswap_fake: {len(val_hog_mni_fswap_fake)} images\")\n",
    "print(f\"train_hog_mni_nt_fake: {len(train_hog_mni_nt_fake)} images, val_hog_mni_nt_fake: {len(val_hog_mni_nt_fake)} images\")\n",
    "############################################################################################################################################################\n",
    "#################################################concatenate the labels 0,1 real and fake\n",
    "#############################################################################################################################################################\n",
    "\n",
    "\n",
    "train_ori_actor_labels_real = np.zeros(len(train_hog_ori_actor_real), dtype=int)\n",
    "train_ori_youtube_labels_real = np.zeros(len(train_hog_ori_youtube_real), dtype=int)\n",
    "train_mni_dfd_labels_fake = np.ones(len(train_hog_mni_dfd_fake), dtype=int)\n",
    "train_mni_df_labels_fake = np.ones(len(train_hog_mni_df_fake), dtype=int)\n",
    "train_mni_f2f_labels_fake = np.ones(len(train_hog_mni_f2f_fake), dtype=int)\n",
    "train_mni_fshifter_labels_fake = np.ones(len(train_hog_mni_fshifter_fake), dtype=int)\n",
    "train_mni_fswap_labels_fake = np.ones(len(train_hog_mni_fswap_fake), dtype=int)\n",
    "train_mni_nt_labels_fake = np.ones(len(train_hog_mni_nt_fake), dtype=int)\n",
    "\n",
    "test_ori_actor_labels_real = np.zeros(len(ori_actor_test_real), dtype=int)\n",
    "test_ori_youtube_labels_real = np.zeros(len(ori_youtube_test_real), dtype=int)\n",
    "test_mni_dfd_labels_fake = np.ones(len(mni_dfd_test_fake), dtype=int)\n",
    "test_mni_df_labels_fake = np.ones(len(mni_df_test_fake), dtype=int)\n",
    "test_mni_f2f_labels_fake = np.ones(len(mni_f2f_test_fake), dtype=int)\n",
    "test_mni_fshifter_labels_fake = np.ones(len(mni_fshifter_test_fake), dtype=int)\n",
    "test_mni_fswap_labels_fake = np.ones(len(mni_fswap_test_fake), dtype=int)\n",
    "test_mni_nt_labels_fake = np.ones(len(mni_nt_test_fake), dtype=int)\n",
    "\n",
    "\n",
    "val_ori_actor_labels_real = np.zeros(len(val_hog_ori_actor_real), dtype=int)\n",
    "val_ori_youtube_labels_real = np.zeros(len(val_hog_ori_youtube_real), dtype=int)\n",
    "val_mni_dfd_labels_fake = np.ones(len(val_hog_mni_dfd_fake), dtype=int)\n",
    "val_mni_df_labels_fake = np.ones(len(val_hog_mni_df_fake), dtype=int)\n",
    "val_mni_f2f_labels_fake = np.ones(len(val_hog_mni_f2f_fake), dtype=int)\n",
    "val_mni_fshifter_labels_fake = np.ones(len(val_hog_mni_fshifter_fake), dtype=int)\n",
    "val_mni_fswap_labels_fake = np.ones(len(val_hog_mni_fswap_fake), dtype=int)\n",
    "val_mni_nt_labels_fake = np.ones(len(val_hog_mni_nt_fake), dtype=int)\n",
    "##################################################################################################################\n",
    "\n",
    "# Concatenate all training datasets into a single `train` variable\n",
    "train_ff = np.concatenate([train_hog_ori_actor_real, train_hog_ori_youtube_real,train_hog_mni_dfd_fake,train_hog_mni_df_fake,\n",
    "                            train_hog_mni_f2f_fake,train_hog_mni_fshifter_fake,train_hog_mni_fswap_fake,train_hog_mni_nt_fake], axis=0)\n",
    "\n",
    "train_labels_ff = np.concatenate([train_ori_actor_labels_real, train_ori_youtube_labels_real,train_mni_dfd_labels_fake,train_mni_df_labels_fake,\n",
    "                            train_mni_f2f_labels_fake,train_mni_fshifter_labels_fake,train_mni_fswap_labels_fake,train_mni_nt_labels_fake], axis=0)\n",
    "\n",
    "# Concatenate all validation datasets into a single `val` variable\n",
    "val_ff = np.concatenate([val_hog_ori_actor_real, val_hog_ori_youtube_real, val_hog_mni_dfd_fake, val_hog_mni_df_fake,\n",
    "                            val_hog_mni_f2f_fake, val_hog_mni_fshifter_fake, val_hog_mni_fswap_fake, val_hog_mni_nt_fake], axis=0)\n",
    "val_labels_ff = np.concatenate([val_ori_actor_labels_real, val_ori_youtube_labels_real, val_mni_dfd_labels_fake, val_mni_df_labels_fake,\n",
    "                            val_mni_f2f_labels_fake, val_mni_fshifter_labels_fake, val_mni_fswap_labels_fake, val_mni_nt_labels_fake], axis=0)\n",
    "# Concatenate all testing datasets into a single `test` variable\n",
    "test_ff = np.concatenate([ori_actor_test_real, ori_youtube_test_real, mni_dfd_test_fake,\n",
    "                           mni_df_test_fake, mni_f2f_test_fake, mni_fshifter_test_fake,\n",
    "                           mni_fswap_test_fake, mni_nt_test_fake], axis=0)\n",
    "test_labels_ff = np.concatenate([test_ori_actor_labels_real, test_ori_youtube_labels_real, test_mni_dfd_labels_fake, test_mni_df_labels_fake,\n",
    "                            test_mni_f2f_labels_fake, test_mni_fshifter_labels_fake, test_mni_fswap_labels_fake, test_mni_nt_labels_fake], axis=0)\n",
    "\n",
    "\n",
    "# Print the results for verification\n",
    "# Print the results for verification\n",
    "print(f\"Total train: {len(train_ff)} images, and shape:{train_ff.shape}\")\n",
    "print(f\"Total test: {len(test_ff)} images, and shape:{test_ff.shape}\")\n",
    "print(f\"Total val: {len(val_ff)} images, and shape:{val_ff.shape}\")\n",
    "\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"Train Labels: {len(train_labels_ff)} \")\n",
    "print(f\"Test Labels: {len(test_labels_ff)} \")\n",
    "print(f\"Val Labels: {len(val_labels_ff)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d03ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into PyTorch Dataset\n",
    "train_dataset = ImageClassificationDataset(train_ff, train_labels_ff, processor)\n",
    "val_dataset = ImageClassificationDataset(val_ff, val_labels_ff, processor)\n",
    "test_dataset = ImageClassificationDataset(test_ff, test_labels_ff, processor)\n",
    "\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bf4ddaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Loss: 0.5802 | Train Acc: 0.7325 | Val Acc: 0.7062\n",
      "Epoch 2/10 | Loss: 0.5270 | Train Acc: 0.7712 | Val Acc: 0.7556\n",
      "Epoch 3/10 | Loss: 0.4831 | Train Acc: 0.8039 | Val Acc: 0.7898\n",
      "Epoch 4/10 | Loss: 0.4381 | Train Acc: 0.8249 | Val Acc: 0.8105\n",
      "Epoch 5/10 | Loss: 0.3844 | Train Acc: 0.8532 | Val Acc: 0.7938\n",
      "Epoch 6/10 | Loss: 0.3415 | Train Acc: 0.8783 | Val Acc: 0.7747\n",
      "Epoch 7/10 | Loss: 0.2966 | Train Acc: 0.8970 | Val Acc: 0.7978\n",
      "Epoch 8/10 | Loss: 0.2591 | Train Acc: 0.9203 | Val Acc: 0.7914\n",
      "Epoch 9/10 | Loss: 0.2379 | Train Acc: 0.9324 | Val Acc: 0.8049\n",
      "Epoch 10/10 | Loss: 0.2289 | Train Acc: 0.9407 | Val Acc: 0.8169\n",
      "Test Accuracy: 0.8015\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 10  # Increase epochs for better accuracy\n",
    "train_model(model, train_loader, val_loader, epochs)\n",
    "\n",
    "\n",
    "# Final evaluation on test data\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4a2955a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Loss: 0.5773 | Train Acc: 0.7344 | Val Acc: 0.7396\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 1  # Increase epochs for better accuracy\n",
    "train_model(model, train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bcd51df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n",
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 4.5%\n",
      "Time Usage: 111.8 s\n",
      "GPU Memory Used: 220.6 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor1.get_stats()\n",
    "# Final evaluation on test data\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "#7.7 gpu\n",
    "\n",
    "end = monitor1.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")#7.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899eeac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 8.7%\n",
      "RAM Used: 426.0 MB\n",
      "Time Usage: 75.7 s\n",
      "GPU Memory Used: 0.0 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "start = monitor.get_stats()\n",
    "# Final evaluation on test data\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b87f3e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7907\n",
      "Recall: 0.8015\n",
      "F1 Score: 0.7899\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_metrics(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            inputs, labels = batch\n",
    "            inputs = {key: val.to(device).float() for key, val in inputs.items()}\n",
    "            labels = labels.to(device).long()\n",
    "\n",
    "            outputs = model(**inputs).logits\n",
    "            preds = outputs.argmax(1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Calculate metrics on test data\n",
    "precision, recall, f1 = evaluate_metrics(model, test_loader)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87c83955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DFC on F++ ON (Swim Transformer): 0.4510\n"
     ]
    }
   ],
   "source": [
    "# Convert data into PyTorch Dataset\n",
    "\n",
    "test_dataset = ImageClassificationDataset(test_hog, test_labels, processor)\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "# Final evaluation on test data\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "print(f\"Test Accuracy of DFC on F++ ON (Swim Transformer): {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c5db608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of Celeb-DF(V2) on F++ ON (Swim Transformer): 0.3794\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ImageClassificationDataset(test, test_labels, processor)\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "# Final evaluation on test data\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "print(f\"Test Accuracy of Celeb-DF(V2) on F++ ON (Swim Transformer): {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
