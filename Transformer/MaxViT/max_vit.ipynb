{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d403f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python exe: c:\\Users\\aneek\\anaconda3\\envs\\tf_gpu_env\\python.exe\n",
      "python ver: 3.9.23 | packaged by conda-forge | (main, Jun  4 2025, 17:49:16) [MSC v.1929 64 bit (AMD64)]\n",
      "torch      : 1.12.1+cu113 c:\\Users\\aneek\\anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\torch\\__init__.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aneek\\anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"python exe:\", sys.executable)   # full path to the interpreter\n",
    "print(\"python ver:\", sys.version)\n",
    "\n",
    "# try torch only in the working notebook\n",
    "try:\n",
    "    import torch\n",
    "    print(\"torch      :\", torch.__version__, torch.__file__)\n",
    "except ModuleNotFoundError as e:\n",
    "    print(\"torch not importable:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f959d74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "Num GPUs Available:  1\n",
      "CUDA version: 64_112\n",
      "cuDNN version: 64_8\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2821328081990942938\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5713690624\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3825921087133055220\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)  # This should print the version of TensorFlow\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "print(\"CUDA version:\", tf.sysconfig.get_build_info()[\"cuda_version\"])\n",
    "print(\"cuDNN version:\", tf.sysconfig.get_build_info()[\"cudnn_version\"])\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a940428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu113\n",
      "CUDA Available:  True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"CUDA Available: \", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04d0ceea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "TensorFlow running on GPU: tf.Tensor(\n",
      "[[19. 22.]\n",
      " [43. 50.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow devices:\")\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "# Force TensorFlow to use GPU\n",
    "tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)\n",
    "\n",
    "# Test a simple matrix multiplication\n",
    "with tf.device('/GPU:0'):\n",
    "    a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "    b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "    print(\"TensorFlow running on GPU:\", c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814f0ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch CUDA Version: 11.3\n",
      "Torch cuDNN Version: 8302\n",
      "Available GPUs: 1\n",
      "GPU Name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Torch CUDA Version:\", torch.version.cuda)\n",
    "print(\"Torch cuDNN Version:\", torch.backends.cudnn.version())\n",
    "print(\"Available GPUs:\", torch.cuda.device_count())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f64a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated GPU memory: 0.00 GB\n",
      "Reserved GPU memory: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"Allocated GPU memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "print(f\"Reserved GPU memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "081143cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8baa7d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import psutil\n",
    "\n",
    "class PowerMonitor:\n",
    "    def __init__(self):\n",
    "        self.gpu_available = tf.config.list_physical_devices('GPU')\n",
    "        \n",
    "        # Hardware power specifications (adjust these values for your system)\n",
    "        self.cpu_tdp = 65    # Typical TDP for desktop CPUs in watts\n",
    "        self.gpu_tdp = 250   # Typical TDP for desktop GPUs in watts\n",
    "        \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get system stats with power estimation\"\"\"\n",
    "        stats = {\n",
    "            'timestamp': time.time(),\n",
    "            'cpu_%': psutil.cpu_percent(interval=0.1),\n",
    "            'ram_mb': psutil.virtual_memory().used / (1024**2),\n",
    "            'gpu_mem_mb': 0,\n",
    "            'power_w': self.cpu_tdp * (psutil.cpu_percent()/100) * 0.85  # Base CPU power\n",
    "        }\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            try:\n",
    "                # TensorFlow GPU memory monitoring\n",
    "                mem_info = tf.config.experimental.get_memory_info('GPU:0')\n",
    "                stats.update({\n",
    "                    'gpu_mem_mb': mem_info['current'] / (1024**2),\n",
    "                    'power_w': self.cpu_tdp * (psutil.cpu_percent()/100) * 0.85 + \n",
    "                              self.gpu_tdp * 0.5 * 0.75  # Add GPU power estimate\n",
    "                })\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        return stats\n",
    "\n",
    "# Initialize monitor\n",
    "monitor = PowerMonitor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f13496c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "class PowerMonitor1:\n",
    "    def __init__(self):\n",
    "        self.gpu_available = torch.cuda.is_available()\n",
    "        self.process = psutil.Process(os.getpid())  # Track current process\n",
    "        \n",
    "        # Hardware power specifications\n",
    "        self.cpu_tdp = 65\n",
    "        self.gpu_tdp = 250\n",
    "        \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get process-specific stats with power estimation\"\"\"\n",
    "        process_memory = self.process.memory_info()\n",
    "        \n",
    "        stats = {\n",
    "            'timestamp': time.time(),\n",
    "            'cpu_%': psutil.cpu_percent(interval=0.1),\n",
    "            'process_ram_mb': process_memory.rss / (1024**2),  # Only this process's RAM\n",
    "            'gpu_mem_mb': 0,\n",
    "            'power_w': self.cpu_tdp * (psutil.cpu_percent()/100) * 0.85\n",
    "        }\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            try:\n",
    "                gpu_memory_allocated = torch.cuda.memory_allocated()\n",
    "                stats.update({\n",
    "                    'gpu_mem_mb': gpu_memory_allocated / (1024**2),\n",
    "                    'power_w': self.cpu_tdp * (psutil.cpu_percent()/100) * 0.85 + \n",
    "                              self.gpu_tdp * 0.5 * 0.75\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error retrieving GPU memory: {e}\")\n",
    "                \n",
    "        return stats\n",
    "\n",
    "# Initialize monitor1\n",
    "monitor1 = PowerMonitor1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b73ba021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data real shape: (6909, 160, 160, 3)\n",
      "Testing real data shape: (2961, 160, 160, 3)\n",
      "Training fake data shape: (7891, 160, 160, 3)\n",
      "Testing  fake data shape: (3383, 160, 160, 3)\n",
      "train_hog_real: 6218 images, val_hog_real: 691 images\n",
      "train_hog_fake: 7101 images, val_hog_fake: 790 images\n",
      "Total train: 13319 images\n",
      "Total test: 10852 images\n",
      "Total val: 1481 images\n",
      "Train Labels: 13319 \n",
      "Test Labels: 10852 \n",
      "Val Labels: 1481 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the data into train (70%) and test (30%)\n",
    "X_train_real, X_test_real = train_test_split(real_frames_array1, test_size=0.3, random_state=42)\n",
    "X_train_fake, X_test_fake = train_test_split(fake_frames_array1, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Output the shape to confirm the split dimensions\n",
    "print(\"Training data real shape:\", X_train_real.shape)\n",
    "print(\"Testing real data shape:\", X_test_real.shape)\n",
    "print(\"Training fake data shape:\", X_train_fake.shape)\n",
    "print(\"Testing  fake data shape:\", X_test_fake.shape)\n",
    "########################################################################################################################################\n",
    "#######################################divide into 60,10 train and val\n",
    "#########################################################################################################################################\n",
    "def extract_validation(train_data):\n",
    "    \"\"\"\n",
    "    Extract every 10th sample from the training data and store it in a validation set.\n",
    "\n",
    "    Parameters:\n",
    "        train_data (list or np.array): The training dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated training dataset and validation dataset.\n",
    "    \"\"\"\n",
    "    # Select every 10th sample for the validation set\n",
    "    validation_data = train_data[::10]\n",
    "\n",
    "    # Remove the selected samples from the training dataset\n",
    "    updated_train_data = [train_data[i] for i in range(len(train_data)) if i % 10 != 0]\n",
    "\n",
    "    return np.array(updated_train_data), np.array(validation_data)\n",
    "\n",
    "\n",
    "# Perform the operation for each dataset\n",
    "train_hog_real, val_hog_real = extract_validation(X_train_real)\n",
    "train_hog_fake, val_hog_fake = extract_validation(X_train_fake)\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"train_hog_real: {len(train_hog_real)} images, val_hog_real: {len(val_hog_real)} images\")\n",
    "print(f\"train_hog_fake: {len(train_hog_fake)} images, val_hog_fake: {len(val_hog_fake)} images\")\n",
    "\n",
    "\n",
    "############################################################################################################################################################\n",
    "#################################################concatenate the labels 0,1 real and fake\n",
    "#############################################################################################################################################################\n",
    "\n",
    "\n",
    "train_labels_real = np.zeros(len(train_hog_real), dtype=int)\n",
    "train_labels_fake = np.ones(len(train_hog_fake), dtype=int)\n",
    "\n",
    "# Concatenate all training datasets into a single `train` variable\n",
    "train = np.concatenate([train_hog_real, train_hog_fake], axis=0)\n",
    "train_labels=np.concatenate([train_labels_real, train_labels_fake], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "test_labels_real = np.zeros(len(X_test_real), dtype=int)\n",
    "test_labels_fake = np.ones(len(X_train_fake), dtype=int)\n",
    "\n",
    "# Concatenate all testing datasets into a single `test` variable\n",
    "test = np.concatenate([X_test_real, X_train_fake], axis=0)\n",
    "test_labels = np.concatenate([test_labels_real, test_labels_fake], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "val_labels_real = np.zeros(len(val_hog_real), dtype=int)\n",
    "val_labels_fake = np.ones(len(val_hog_fake), dtype=int)\n",
    "\n",
    "# Concatenate all validation datasets into a single `val` variable\n",
    "val = np.concatenate([val_hog_real, val_hog_fake], axis=0)\n",
    "val_labels = np.concatenate([val_labels_real, val_labels_fake], axis=0)\n",
    "\n",
    "# Print the results for verification\n",
    "print(f\"Total train: {len(train)} images\")\n",
    "print(f\"Total test: {len(test)} images\")\n",
    "print(f\"Total val: {len(val)} images\")\n",
    "\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"Train Labels: {len(train_labels)} \")\n",
    "print(f\"Test Labels: {len(test_labels)} \")\n",
    "print(f\"Val Labels: {len(val_labels)} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec3b0a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10946bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Load MaxViT Model\n",
    "model_name = \"maxvit_base_tf_224\"  # Options: maxvit_tiny_tf_224, maxvit_small_tf_224, etc.\n",
    "model = timm.create_model(model_name, pretrained=True, num_classes=2)  # Set your num_classes\n",
    "config = resolve_data_config({}, model=model)\n",
    "transform = create_transform(**config)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 2. Custom Dataset (same as before)\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = Image.fromarray(image)\n",
    "        elif isinstance(image, str):\n",
    "            image = Image.open(image).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e5c0e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim  # This is the missing \n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import LinearLR, CosineAnnealingLR  # Add these imports\n",
    "# 3. Training Function\n",
    "def train_model(model, train_loader, val_loader, epochs=10):\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    # Warmup + cosine scheduling\n",
    "    scheduler = torch.optim.lr_scheduler.SequentialLR(\n",
    "        optimizer,\n",
    "        [\n",
    "            LinearLR(optimizer, start_factor=0.01, total_iters=3),\n",
    "            CosineAnnealingLR(optimizer, T_max=epochs-3)\n",
    "        ],\n",
    "        milestones=[3]\n",
    "    )\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            images, labels = images.to(device, non_blocking=True), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        train_acc = 100 * correct / total\n",
    "        val_metrics = evaluate_metrics(model, val_loader)\n",
    "        print(f\"Epoch {epoch+1}: LR = {optimizer.param_groups[0]['lr']:.2e}, Loss = {train_loss/len(train_loader):.4f}, Acc = {train_acc:.2f}%\")\n",
    "        print(f\"Val Metrics: {val_metrics}\\n\")\n",
    "\n",
    "# 4. Evaluation Function\n",
    "def evaluate_metrics(model, data_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = outputs.argmax(1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(all_labels, all_preds),\n",
    "        'precision': precision_score(all_labels, all_preds, average='weighted'),\n",
    "        'recall': recall_score(all_labels, all_preds, average='weighted'),\n",
    "        'f1': f1_score(all_labels, all_preds, average='weighted')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea219257",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Convert data into PyTorch Dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mImageDataset\u001b[49m(train, train_labels, transform)\n\u001b[0;32m      3\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m ImageDataset(val, val_labels, transform)\n\u001b[0;32m      4\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m ImageDataset(test, test_labels, transform)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageDataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert data into PyTorch Dataset\n",
    "train_dataset = ImageDataset(train, train_labels, transform)\n",
    "val_dataset = ImageDataset(val, val_labels, transform)\n",
    "test_dataset = ImageDataset(test, test_labels, transform)\n",
    "\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d7d70f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 833/833 [4:51:39<00:00, 21.01s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: LR = 3.40e-05, Loss = 0.6930, Acc = 52.59%\n",
      "Val Metrics: {'accuracy': 0.5665091154625254, 'precision': 0.5630607328757162, 'recall': 0.5665091154625254, 'f1': 0.5573460582633291}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 833/833 [4:59:47<00:00, 21.59s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: LR = 6.70e-05, Loss = 0.2765, Acc = 87.33%\n",
      "Val Metrics: {'accuracy': 0.9392302498311952, 'precision': 0.9440657849220603, 'recall': 0.9392302498311952, 'f1': 0.9388276149495407}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 833/833 [5:03:26<00:00, 21.86s/it]  \n",
      "c:\\Users\\aneek\\anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: LR = 1.00e-04, Loss = 0.0942, Acc = 96.58%\n",
      "Val Metrics: {'accuracy': 0.9642133693450371, 'precision': 0.9643988890380686, 'recall': 0.9642133693450371, 'f1': 0.9642316722241191}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 833/833 [5:03:31<00:00, 21.86s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: LR = 9.50e-05, Loss = 0.0680, Acc = 97.47%\n",
      "Val Metrics: {'accuracy': 0.7947332883187036, 'precision': 0.8517726670674368, 'recall': 0.7947332883187036, 'f1': 0.7823510974143892}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 833/833 [5:04:32<00:00, 21.94s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: LR = 8.12e-05, Loss = 0.0421, Acc = 98.46%\n",
      "Val Metrics: {'accuracy': 0.9696151249155975, 'precision': 0.9699381372137323, 'recall': 0.9696151249155975, 'f1': 0.9695799843668622}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 833/833 [4:50:57<00:00, 20.96s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: LR = 6.11e-05, Loss = 0.0266, Acc = 99.10%\n",
      "Val Metrics: {'accuracy': 0.9702903443619176, 'precision': 0.9709898434049478, 'recall': 0.9702903443619176, 'f1': 0.9702375234353311}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 833/833 [5:00:05<00:00, 21.62s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: LR = 3.89e-05, Loss = 0.0137, Acc = 99.59%\n",
      "Val Metrics: {'accuracy': 0.9810938555030385, 'precision': 0.9814094130348642, 'recall': 0.9810938555030385, 'f1': 0.9811064607521133}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 833/833 [5:02:57<00:00, 21.82s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: LR = 1.88e-05, Loss = 0.0064, Acc = 99.78%\n",
      "Val Metrics: {'accuracy': 0.9736664415935179, 'precision': 0.9745708286455621, 'recall': 0.9736664415935179, 'f1': 0.9736918037732227}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 833/833 [5:02:36<00:00, 21.80s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: LR = 4.95e-06, Loss = 0.0013, Acc = 99.97%\n",
      "Val Metrics: {'accuracy': 0.9891964888588791, 'precision': 0.989222902736277, 'recall': 0.9891964888588791, 'f1': 0.989193370085226}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 833/833 [4:53:06<00:00, 21.11s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: LR = 0.00e+00, Loss = 0.0006, Acc = 99.98%\n",
      "Val Metrics: {'accuracy': 0.9891964888588791, 'precision': 0.9891981147666367, 'recall': 0.9891964888588791, 'f1': 0.9891954892485665}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 10  # Increase epochs for better accuracy\n",
    "train_model(model, train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9888dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n",
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 2.1%\n",
      "Time Usage: 868.4 s\n",
      "GPU Memory Used: 929.1 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor1.get_stats()\n",
    "# Final evaluation on test data\n",
    "test_metrics = evaluate_metrics(model, test_loader)\n",
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "#7.7 gpu\n",
    "\n",
    "end = monitor1.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")#7.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "269c7ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM Used: 16.2 MB\n"
     ]
    }
   ],
   "source": [
    "start = monitor.get_stats()\n",
    "test_metrics = evaluate_metrics(model, test_loader)\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e6ef27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = evaluate_metrics(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a807606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics:\n",
      "- Accuracy: 0.9963\n",
      "- Precision: 0.9963\n",
      "- Recall: 0.9963\n",
      "- F1 Score: 0.9963\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Metrics:\")\n",
    "print(f\"- Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"- Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"- Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"- F1 Score: {test_metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd265bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 2.7%\n",
      "RAM Used: 7636.5 MB\n",
      "Time Usage: 186467.5 s\n",
      "GPU Memory Used: 0.0 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "#7.8 gpu\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15a9d251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DFC on Celeb DF (v2)\n",
      "Test Metrics:\n",
      "- Accuracy: 0.4947\n",
      "- Precision: 0.4561\n",
      "- Recall: 0.4947\n",
      "- F1 Score: 0.3524\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_dataset = ImageDataset(test_hog, test_labels, transform)\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Test Accuracy of DFC on Celeb DF (v2)\")\n",
    "# Final evaluation on test data\n",
    "test_metrics = evaluate_metrics(model, test_loader)\n",
    "print(f\"Test Metrics:\")\n",
    "print(f\"- Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"- Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"- Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"- F1 Score: {test_metrics['f1']:.4f}\")\n",
    "#print(f\"Test Accuracy of DFC on Celeb DF (v2): {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5406d724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of FF++ on Celeb DF (v2)\n",
      "Test Metrics:\n",
      "- Accuracy: 0.3813\n",
      "- Precision: 0.6900\n",
      "- Recall: 0.3813\n",
      "- F1 Score: 0.3412\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_dataset = ImageDataset(test_ff, test_labels_ff, transform)\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Test Accuracy of FF++ on Celeb DF (v2)\")\n",
    "# Final evaluation on test data\n",
    "test_metrics = evaluate_metrics(model, test_loader)\n",
    "print(f\"Test Metrics:\")\n",
    "print(f\"- Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"- Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"- Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"- F1 Score: {test_metrics['f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d8c3e0",
   "metadata": {},
   "source": [
    "# DFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd444431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celeb shape: (5000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (5000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "celeb shape: (2500, 160, 160, 3), dtype: uint8\n",
      "ffhq shape: (2500, 160, 160, 3), dtype: uint8\n",
      "gdwct shape: (1000, 160, 160, 3), dtype: uint8\n",
      "attagan shape: (1000, 160, 160, 3), dtype: uint8\n",
      "stargan shape: (1000, 160, 160, 3), dtype: uint8\n",
      "stylegan2 shape: (1000, 160, 160, 3), dtype: uint8\n",
      "stylegan shape: (1000, 160, 160, 3), dtype: uint8\n",
      "celeb_train: 1750 images, celeb_test: 750 images\n",
      "ffhq_train: 1750 images, ffhq_test: 750 images\n",
      "attgan_train: 700 images, attgan_test: 300 images\n",
      "stargan_train: 700 images, stargan_test: 300 images\n",
      "gdwct_train: 700 images, gdwct_test: 300 images\n",
      "stylegan2_train: 700 images, stylegan2_test: 300 images\n",
      "stylegan_train: 700 images, stylegan_test: 300 images\n",
      "celeb_train: 1575 images, celeb_val: 175 images\n",
      "ffhq_train: 1575 images, ffhq_val: 175 images\n",
      "attgan_train: 630 images, attgan_val: 70 images\n",
      "stargan_train: 630 images, stargan_val: 70 images\n",
      "gdwct_train: 630 images, gdwct_val: 70 images\n",
      "stylegan2_train: 630 images, stylegan2_val: 70 images\n",
      "stylegan_train: 630 images, stylegan_val: 70 images\n",
      "Total train: 6300 images\n",
      "Total test: 3000 images\n",
      "Total val: 700 images\n",
      "Train Labels: 6300 \n",
      "Test Labels: 3000 \n",
      "Val Labels: 700 \n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "# Open the HDF5 file in read mode\n",
    "with h5py.File('D://thesis//dataset//deepfake dataset//resized_images.h5', 'r') as h5f:\n",
    "    # Access each dataset\n",
    "    celeb = np.array(h5f['celeb'])\n",
    "    ffhq = np.array(h5f['ffhq'])\n",
    "    gdwct = np.array(h5f['gdwct'])\n",
    "    attgan = np.array(h5f['attgan'])\n",
    "    stargan = np.array(h5f['stargan'])\n",
    "    stylegan2 = np.array(h5f['stylegan2'])\n",
    "    stylegan = np.array(h5f['stylegan'])\n",
    "\n",
    "# Now, 'celeb', 'ffhq', etc., are NumPy arrays containing your datasets\n",
    "print(f\"celeb shape: {celeb.shape}, dtype: {celeb.dtype}\")\n",
    "print(f\"ffhq shape: {ffhq.shape}, dtype: {ffhq.dtype}\")\n",
    "print(f\"ffhq shape: {gdwct.shape}, dtype: {gdwct.dtype}\")\n",
    "print(f\"ffhq shape: {attgan.shape}, dtype: {attgan.dtype}\")\n",
    "print(f\"ffhq shape: {stargan.shape}, dtype: {stargan.dtype}\")\n",
    "print(f\"ffhq shape: {stylegan2.shape}, dtype: {stylegan2.dtype}\")\n",
    "print(f\"ffhq shape: {stylegan.shape}, dtype: {stylegan.dtype}\")\n",
    "# Repeat for other datasets as needed\n",
    "import cv2\n",
    "# Function to resize images from (224, 224) to (160, 160)\n",
    "def resize_images(image_array, target_size=(160, 160)):\n",
    "    resized_images = np.array([cv2.resize(img, target_size) for img in image_array])\n",
    "    return resized_images\n",
    "\n",
    "celeb = resize_images(celeb, target_size=(160, 160))\n",
    "ffhq = resize_images(ffhq, target_size=(160, 160))\n",
    "gdwct = resize_images(gdwct, target_size=(160, 160))\n",
    "attgan = resize_images(attgan, target_size=(160, 160))\n",
    "stargan = resize_images(stargan, target_size=(160, 160))\n",
    "stylegan = resize_images(stargan, target_size=(160, 160))\n",
    "stylegan2 = resize_images(stylegan2, target_size=(160, 160))\n",
    "import random\n",
    "# Randomly select 2500 distinct images\n",
    "random_indices = random.sample(range(len(celeb)), 2500)  # Get 2500 random indices\n",
    "celeb = celeb[random_indices]  # Select the random subse\n",
    "\n",
    "import random\n",
    "# Randomly select 2500 distinct images\n",
    "random_indices = random.sample(range(len(ffhq)), 2500)  # Get 2500 random indices\n",
    "ffhq = ffhq[random_indices]  # Select the random subse\n",
    "print(f\"celeb shape: {celeb.shape}, dtype: {celeb.dtype}\")\n",
    "print(f\"ffhq shape: {ffhq.shape}, dtype: {ffhq.dtype}\")\n",
    "print(f\"gdwct shape: {gdwct.shape}, dtype: {gdwct.dtype}\")\n",
    "print(f\"attagan shape: {attgan.shape}, dtype: {attgan.dtype}\")\n",
    "print(f\"stargan shape: {stargan.shape}, dtype: {stargan.dtype}\")\n",
    "print(f\"stylegan2 shape: {stylegan2.shape}, dtype: {stylegan2.dtype}\")\n",
    "print(f\"stylegan shape: {stylegan.shape}, dtype: {stylegan.dtype}\")\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def split_data(data, train_ratio=0.7):\n",
    "    \"\"\"\n",
    "    Splits data into training and testing sets based on the specified ratio.\n",
    "\n",
    "    Parameters:\n",
    "        data (list or np.array): The dataset to split.\n",
    "        train_ratio (float): The ratio of the data to include in the training set.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two datasets - train and test.\n",
    "    \"\"\"\n",
    "    # Shuffle the data\n",
    "    random.shuffle(data)\n",
    "\n",
    "    # Calculate the split index\n",
    "    split_index = int(len(data) * train_ratio)\n",
    "\n",
    "    # Split the data\n",
    "    train_data = data[:split_index]\n",
    "    test_data = data[split_index:]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "# Split `celeb` into 70% train and 30% test\n",
    "celeb_train_hog, celeb_test_hog = split_data(celeb, train_ratio=0.7)\n",
    "\n",
    "# Split `ffhq` into 70% train and 30% test\n",
    "ffhq_train_hog, ffhq_test_hog = split_data(ffhq, train_ratio=0.7)\n",
    "\n",
    "# Split `attgan` into 70% train and 30% test\n",
    "attgan_train_hog, attgan_test_hog = split_data(attgan, train_ratio=0.7)\n",
    "\n",
    "# Split `stargan` into 70% train and 30% test\n",
    "stargan_train_hog, stargan_test_hog = split_data(stargan, train_ratio=0.7)\n",
    "\n",
    "# Split `gdwct` into 70% train and 30% test\n",
    "gdwct_train_hog, gdwct_test_hog = split_data(gdwct, train_ratio=0.7)\n",
    "\n",
    "# Split `stylegan2` into 70% train and 30% test_hog\n",
    "stylegan2_train_hog, stylegan2_test_hog = split_data(stylegan2, train_ratio=0.7)\n",
    "\n",
    "# Split `stylegan` into 70% train and 30% test_hog\n",
    "stylegan_train_hog, stylegan_test_hog = split_data(stylegan, train_ratio=0.7)\n",
    "\n",
    "# Convert to NumPy arrays if needed\n",
    "celeb_train_hog, celeb_test_hog = np.array(celeb_train_hog), np.array(celeb_test_hog)\n",
    "ffhq_train_hog, ffhq_test_hog = np.array(ffhq_train_hog), np.array(ffhq_test_hog)\n",
    "attgan_train_hog, attgan_test_hog = np.array(attgan_train_hog), np.array(attgan_test_hog)\n",
    "stargan_train_hog, stargan_test_hog = np.array(stargan_train_hog), np.array(stargan_test_hog)\n",
    "gdwct_train_hog, gdwct_test_hog = np.array(gdwct_train_hog), np.array(gdwct_test_hog)\n",
    "stylegan2_train_hog, stylegan2_test_hog = np.array(stylegan2_train_hog), np.array(stylegan2_test_hog)\n",
    "stylegan_train_hog, stylegan_test_hog = np.array(stylegan_train_hog), np.array(stylegan_test_hog)\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"celeb_train: {len(celeb_train_hog)} images, celeb_test: {len(celeb_test_hog)} images\")\n",
    "print(f\"ffhq_train: {len(ffhq_train_hog)} images, ffhq_test: {len(ffhq_test_hog)} images\")\n",
    "print(f\"attgan_train: {len(attgan_train_hog)} images, attgan_test: {len(attgan_test_hog)} images\")\n",
    "print(f\"stargan_train: {len(stargan_train_hog)} images, stargan_test: {len(stargan_test_hog)} images\")\n",
    "print(f\"gdwct_train: {len(gdwct_train_hog)} images, gdwct_test: {len(gdwct_test_hog)} images\")\n",
    "print(f\"stylegan2_train: {len(stylegan2_train_hog)} images, stylegan2_test: {len(stylegan2_test_hog)} images\")\n",
    "print(f\"stylegan_train: {len(stylegan_train_hog)} images, stylegan_test: {len(stylegan_test_hog)} images\")\n",
    "\n",
    "########################################################################################################################################\n",
    "#######################################divide into 60,10 train and val\n",
    "#########################################################################################################################################\n",
    "def extract_validation(train_data):\n",
    "    \"\"\"\n",
    "    Extract every 10th sample from the training data and store it in a validation set.\n",
    "\n",
    "    Parameters:\n",
    "        train_data (list or np.array): The training dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated training dataset and validation dataset.\n",
    "    \"\"\"\n",
    "    # Select every 10th sample for the validation set\n",
    "    validation_data = train_data[::10]\n",
    "\n",
    "    # Remove the selected samples from the training dataset\n",
    "    updated_train_data = [train_data[i] for i in range(len(train_data)) if i % 10 != 0]\n",
    "\n",
    "    return np.array(updated_train_data), np.array(validation_data)\n",
    "\n",
    "\n",
    "# Perform the operation for each dataset\n",
    "celeb_train_hog, celeb_val_hog = extract_validation(celeb_train_hog)\n",
    "ffhq_train_hog, ffhq_val_hog = extract_validation(ffhq_train_hog)\n",
    "attgan_train_hog, attgan_val_hog = extract_validation(attgan_train_hog)\n",
    "stargan_train_hog, stargan_val_hog = extract_validation(stargan_train_hog)\n",
    "gdwct_train_hog, gdwct_val_hog = extract_validation(gdwct_train_hog)\n",
    "stylegan2_train_hog, stylegan2_val_hog = extract_validation(stylegan2_train_hog)\n",
    "stylegan_train_hog, stylegan_val_hog = extract_validation(stylegan_train_hog)\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"celeb_train: {len(celeb_train_hog)} images, celeb_val: {len(celeb_val_hog)} images\")\n",
    "print(f\"ffhq_train: {len(ffhq_train_hog)} images, ffhq_val: {len(ffhq_val_hog)} images\")\n",
    "print(f\"attgan_train: {len(attgan_train_hog)} images, attgan_val: {len(attgan_val_hog)} images\")\n",
    "print(f\"stargan_train: {len(stargan_train_hog)} images, stargan_val: {len(stargan_val_hog)} images\")\n",
    "print(f\"gdwct_train: {len(gdwct_train_hog)} images, gdwct_val: {len(gdwct_val_hog)} images\")\n",
    "print(f\"stylegan2_train: {len(stylegan2_train_hog)} images, stylegan2_val: {len(stylegan2_val_hog)} images\")\n",
    "print(f\"stylegan_train: {len(stylegan_train_hog)} images, stylegan_val: {len(stylegan_val_hog)} images\")\n",
    "############################################################################################################################################################\n",
    "#################################################concatenate the labels 0,1 real and fake\n",
    "#############################################################################################################################################################\n",
    "\n",
    "\n",
    "celeb_train_labels = np.zeros(len(celeb_train_hog), dtype=int)\n",
    "ffhq_train_labels = np.zeros(len(ffhq_train_hog), dtype=int)\n",
    "atta_train_labels = np.ones(len(attgan_train_hog), dtype=int)\n",
    "star_train_labels = np.ones(len(stargan_train_hog), dtype=int)\n",
    "gdwct_train_labels = np.ones(len(gdwct_train_hog), dtype=int)\n",
    "stylegan2_train_labels = np.ones(len(stylegan2_train_hog), dtype=int)\n",
    "stylegan_train_labels = np.ones(len(stylegan_train_hog), dtype=int)\n",
    "\n",
    "# Concatenate all training datasets into a single `train` variable\n",
    "train_hog = np.concatenate([celeb_train_hog, ffhq_train_hog, attgan_train_hog, stargan_train_hog, gdwct_train_hog, stylegan2_train_hog, stylegan_train_hog], axis=0)\n",
    "train_labels=np.concatenate([celeb_train_labels, ffhq_train_labels, atta_train_labels, star_train_labels, gdwct_train_labels, stylegan2_train_labels,\n",
    "                              stylegan_train_labels], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "celeb_test_labels = np.zeros(len(celeb_test_hog), dtype=int)\n",
    "ffhq_test_labels = np.zeros(len(ffhq_test_hog), dtype=int)\n",
    "atta_test_labels = np.ones(len(attgan_test_hog), dtype=int)\n",
    "star_test_labels = np.ones(len(stargan_test_hog), dtype=int)\n",
    "gdwct_test_labels = np.ones(len(gdwct_test_hog), dtype=int)\n",
    "stylegan2_test_labels = np.ones(len(stylegan2_test_hog), dtype=int)\n",
    "stylegan_test_labels = np.ones(len(stylegan_test_hog), dtype=int)\n",
    "\n",
    "# Concatenate all testing datasets into a single `test` variable\n",
    "test_hog = np.concatenate([celeb_test_hog, ffhq_test_hog, attgan_test_hog, stargan_test_hog, gdwct_test_hog, stylegan2_test_hog, stylegan_test_hog], axis=0)\n",
    "test_labels = np.concatenate([celeb_test_labels, ffhq_test_labels, atta_test_labels, star_test_labels, gdwct_test_labels, stylegan2_test_labels,\n",
    "                        stylegan_test_labels], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "celeb_val_labels = np.zeros(len(celeb_val_hog), dtype=int)\n",
    "ffhq_val_labels = np.zeros(len(ffhq_val_hog), dtype=int)\n",
    "atta_val_labels = np.ones(len(attgan_val_hog), dtype=int)\n",
    "star_val_labels = np.ones(len(stargan_val_hog), dtype=int)\n",
    "gdwct_val_labels = np.ones(len(gdwct_val_hog), dtype=int)\n",
    "stylegan2_val_labels = np.ones(len(stylegan2_val_hog), dtype=int)\n",
    "stylegan_val_labels = np.ones(len(stylegan_val_hog), dtype=int)\n",
    "\n",
    "# Concatenate all validation datasets into a single `val` variable\n",
    "val_hog = np.concatenate([celeb_val_hog, ffhq_val_hog, attgan_val_hog, stargan_val_hog, gdwct_val_hog, stylegan2_val_hog, stylegan_val_hog], axis=0)\n",
    "val_labels = np.concatenate([celeb_val_labels, ffhq_val_labels, atta_val_labels, star_val_labels, gdwct_val_labels, stylegan2_val_labels,\n",
    "                       stylegan_val_labels], axis=0)\n",
    "\n",
    "# Print the results for verification\n",
    "print(f\"Total train: {len(train_hog)} images\")\n",
    "print(f\"Total test: {len(test_hog)} images\")\n",
    "print(f\"Total val: {len(val_hog)} images\")\n",
    "\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"Train Labels: {len(train_labels)} \")\n",
    "print(f\"Test Labels: {len(test_labels)} \")\n",
    "print(f\"Val Labels: {len(val_labels)} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e28547f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into PyTorch Dataset\n",
    "train_dataset = ImageDataset(train_hog, train_labels, transform)\n",
    "val_dataset = ImageDataset(val_hog, val_labels, transform)\n",
    "test_dataset = ImageDataset(test_hog, test_labels, transform)\n",
    "\n",
    "\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bfc558a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 394/394 [42:18<00:00,  6.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: LR = 3.40e-05, Loss = 0.6811, Acc = 56.37%\n",
      "Val Metrics: {'accuracy': 0.6728571428571428, 'precision': 0.6937771676961794, 'recall': 0.6728571428571428, 'f1': 0.663782706727492}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 394/394 [41:58<00:00,  6.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: LR = 6.70e-05, Loss = 0.1202, Acc = 95.79%\n",
      "Val Metrics: {'accuracy': 0.9871428571428571, 'precision': 0.9872422943457848, 'recall': 0.9871428571428571, 'f1': 0.9871422011327107}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 394/394 [45:45<00:00,  6.97s/it]\n",
      "c:\\Users\\aneek\\anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: LR = 1.00e-04, Loss = 0.0336, Acc = 98.81%\n",
      "Val Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 394/394 [45:44<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: LR = 9.50e-05, Loss = 0.0163, Acc = 99.44%\n",
      "Val Metrics: {'accuracy': 0.9814285714285714, 'precision': 0.9820936639118456, 'recall': 0.9814285714285714, 'f1': 0.9814221639708389}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 394/394 [45:44<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: LR = 8.12e-05, Loss = 0.0124, Acc = 99.62%\n",
      "Val Metrics: {'accuracy': 0.9985714285714286, 'precision': 0.9985754985754985, 'recall': 0.9985714285714286, 'f1': 0.9985714256559707}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 394/394 [45:45<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: LR = 6.11e-05, Loss = 0.0084, Acc = 99.79%\n",
      "Val Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 394/394 [45:45<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: LR = 3.89e-05, Loss = 0.0087, Acc = 99.75%\n",
      "Val Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 394/394 [45:44<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: LR = 1.88e-05, Loss = 0.0008, Acc = 100.00%\n",
      "Val Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 394/394 [45:44<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: LR = 4.95e-06, Loss = 0.0012, Acc = 99.97%\n",
      "Val Metrics: {'accuracy': 0.9985714285714286, 'precision': 0.9985754985754985, 'recall': 0.9985714285714286, 'f1': 0.9985714256559707}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 394/394 [45:45<00:00,  6.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: LR = 0.00e+00, Loss = 0.0002, Acc = 100.00%\n",
      "Val Metrics: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 10  # Increase epochs for better accuracy\n",
    "train_model(model, train_loader, val_loader, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60f93cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n",
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 3.6%\n",
      "Time Usage: 242.6 s\n",
      "GPU Memory Used: 929.1 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor1.get_stats()\n",
    "# Final evaluation on test data\n",
    "test_metrics = evaluate_metrics(model, test_loader)\n",
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "#7.7 gpu\n",
    "\n",
    "end = monitor1.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")#7.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "005db5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics:\n",
      "- Accuracy: 0.9950\n",
      "- Precision: 0.9950\n",
      "- Recall: 0.9950\n",
      "- F1 Score: 0.9950\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Final evaluation on test data\n",
    "test_metrics = evaluate_metrics(model, test_loader)\n",
    "print(f\"Test Metrics:\")\n",
    "print(f\"- Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"- Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"- Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"- F1 Score: {test_metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0d8a39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of Celeb DF(V2) on DFC\n",
      "Test Metrics:\n",
      "- Accuracy: 0.7128\n",
      "- Precision: 0.5969\n",
      "- Recall: 0.7128\n",
      "- F1 Score: 0.6173\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_dataset = ImageDataset(test, test_labels, transform)\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Test Accuracy of Celeb DF(V2) on DFC\")\n",
    "# Final evaluation on test data\n",
    "test_metrics = evaluate_metrics(model, test_loader)\n",
    "print(f\"Test Metrics:\")\n",
    "print(f\"- Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"- Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"- Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"- F1 Score: {test_metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44c29dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of FF++ on DFC:\n",
      "Test Metrics:\n",
      "- Accuracy: 0.7211\n",
      "- Precision: 0.6602\n",
      "- Recall: 0.7211\n",
      "- F1 Score: 0.6504\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_dataset = ImageDataset(test_ff, test_labels_ff, transform)\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Test Accuracy of FF++ on DFC:\")\n",
    "# Final evaluation on test data\n",
    "test_metrics = evaluate_metrics(model, test_loader)\n",
    "print(f\"Test Metrics:\")\n",
    "print(f\"- Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"- Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"- Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"- F1 Score: {test_metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f578dba",
   "metadata": {},
   "source": [
    "# FF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "405bec66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from the HDF5 file.\n",
      "Data loaded successfully from the HDF5 file.\n",
      "Data loaded successfully from the HDF5 file.\n",
      "Data loaded successfully from the HDF5 file.\n",
      "Shape of the concatenated array: (2808, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (3299, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (1742, 160, 160, 3)\n",
      "Shape of the concatenated array: (1742, 160, 160, 3)\n",
      "Training data ACTOR real shape: (1965, 160, 160, 3) Testing real data shape: (843, 160, 160, 3)\n",
      "Training data Youtube real shape: (1458, 160, 160, 3) Testing real data shape: (625, 160, 160, 3)\n",
      "Training data DFD fake shape: (2309, 160, 160, 3) Testing fake data shape: (990, 160, 160, 3)\n",
      "Training data DF fake shape: (1458, 160, 160, 3) Testing fake data shape: (625, 160, 160, 3)\n",
      "Training data f2f fake shape: (1458, 160, 160, 3) Testing fake data shape: (625, 160, 160, 3)\n",
      "Training data fshifter fake shape: (1458, 160, 160, 3) Testing fake data shape: (625, 160, 160, 3)\n",
      "Training data fswap fake shape: (1219, 160, 160, 3) Testing fake data shape: (523, 160, 160, 3)\n",
      "Training data nt fake shape: (1219, 160, 160, 3) Testing fake data shape: (523, 160, 160, 3)\n",
      "train_ori_actor hog_real: 1768 images, val_ori_actor hog_real: 197 images\n",
      "train_ ori_youtube hog_real: 1312 images, val_ ori_youtube hog_real: 146 images\n",
      "train_hog_mni_dfd_fake: 2078 images, val_hog_mni_dfd_fake: 231 images\n",
      "train_hog_mni_df_fake: 1312 images, val_hog_mni_df_fake: 146 images\n",
      "train_hog_mni_f2f_fake: 1312 images, val_hog_mni_f2f_fake: 146 images\n",
      "train_hog_mni_fshifter_fake: 1312 images, val_hog_mni_fshifter_fake: 146 images\n",
      "train_hog_mni_fswap_fake: 1097 images, val_hog_mni_fswap_fake: 122 images\n",
      "train_hog_mni_nt_fake: 1097 images, val_hog_mni_nt_fake: 122 images\n",
      "Total train: 11288 images, and shape:(11288, 160, 160, 3)\n",
      "Total test: 5379 images, and shape:(5379, 160, 160, 3)\n",
      "Total val: 1256 images, and shape:(1256, 160, 160, 3)\n",
      "Train Labels: 11288 \n",
      "Test Labels: 5379 \n",
      "Val Labels: 1256 \n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the HDF5 file for reading\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_orignal_processed.h5\", \"r\") as h5f:\n",
    "    org_seq_actor_array = h5f[\"ori_actor\"][:]\n",
    "    org_seq_youtube_array = h5f[\"ori_youtube\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_fake1_processed.h5\", \"r\") as h5f:\n",
    "    meni_seq_dfd_array = h5f[\"mni_dfd\"][:]\n",
    "    meni_seq_df_array = h5f[\"mni_df\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_fake2_processed.h5\", \"r\") as h5f:\n",
    "    meni_seq_f2f_array = h5f[\"mni_f2f\"][:]\n",
    "    meni_seq_fshifter_array = h5f[\"mni_fshifter\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_fake3_processed.h5\", \"r\") as h5f:\n",
    "    meni_seq_fswap_array = h5f[\"mni_fswap\"][:]\n",
    "    meni_seq_nt_array = h5f[\"mni_nt\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "# Output the shape of the resulting array\n",
    "print(f\"Shape of the concatenated array: {org_seq_actor_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {org_seq_youtube_array.shape}\")\n",
    "\n",
    "print(f\"Shape of the concatenated array: {meni_seq_dfd_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_df_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_fshifter_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_f2f_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_fswap_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_nt_array.shape}\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ori_actor_train_real, ori_actor_test_real = train_test_split(org_seq_actor_array, test_size=0.3, random_state=42)\n",
    "ori_youtube_train_real, ori_youtube_test_real = train_test_split(org_seq_youtube_array, test_size=0.3, random_state=42)\n",
    "# Split the data into train (70%) and test (30%)\n",
    "mni_dfd_train_fake, mni_dfd_test_fake = train_test_split(meni_seq_dfd_array, test_size=0.3, random_state=42)\n",
    "mni_df_train_fake, mni_df_test_fake = train_test_split(meni_seq_df_array, test_size=0.3, random_state=42)\n",
    "mni_f2f_train_fake, mni_f2f_test_fake = train_test_split(meni_seq_f2f_array, test_size=0.3, random_state=42)\n",
    "mni_fshifter_train_fake, mni_fshifter_test_fake = train_test_split(meni_seq_fshifter_array, test_size=0.3, random_state=42)\n",
    "mni_fswap_train_fake, mni_fswap_test_fake = train_test_split(meni_seq_fswap_array, test_size=0.3, random_state=42)\n",
    "mni_nt_train_fake, mni_nt_test_fake = train_test_split(meni_seq_nt_array, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Output the shape to confirm the split dimensions\n",
    "print(\"Training data ACTOR real shape:\", ori_actor_train_real.shape, \"Testing real data shape:\", ori_actor_test_real.shape)\n",
    "print(\"Training data Youtube real shape:\", ori_youtube_train_real.shape, \"Testing real data shape:\", ori_youtube_test_real.shape)\n",
    "\n",
    "print(\"Training data DFD fake shape:\", mni_dfd_train_fake.shape, \"Testing fake data shape:\", mni_dfd_test_fake.shape)\n",
    "print(\"Training data DF fake shape:\", mni_df_train_fake.shape, \"Testing fake data shape:\", mni_df_test_fake.shape)\n",
    "print(\"Training data f2f fake shape:\", mni_f2f_train_fake.shape, \"Testing fake data shape:\", mni_f2f_test_fake.shape)\n",
    "print(\"Training data fshifter fake shape:\", mni_fshifter_train_fake.shape, \"Testing fake data shape:\", mni_fshifter_test_fake.shape)\n",
    "print(\"Training data fswap fake shape:\", mni_fswap_train_fake.shape, \"Testing fake data shape:\", mni_fswap_test_fake.shape)\n",
    "print(\"Training data nt fake shape:\", mni_nt_train_fake.shape, \"Testing fake data shape:\", mni_nt_test_fake.shape)\n",
    "########################################################################################################################################\n",
    "#######################################divide into 60,10 train and val\n",
    "#########################################################################################################################################\n",
    "def extract_validation(train_data):\n",
    "    \"\"\"\n",
    "    Extract every 10th sample from the training data and store it in a validation set.\n",
    "\n",
    "    Parameters:\n",
    "        train_data (list or np.array): The training dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated training dataset and validation dataset.\n",
    "    \"\"\"\n",
    "    # Select every 10th sample for the validation set\n",
    "    validation_data = train_data[::10]\n",
    "\n",
    "    # Remove the selected samples from the training dataset\n",
    "    updated_train_data = [train_data[i] for i in range(len(train_data)) if i % 10 != 0]\n",
    "\n",
    "    return np.array(updated_train_data), np.array(validation_data)\n",
    "\n",
    "\n",
    "# Perform the operation for each dataset\n",
    "train_hog_ori_actor_real, val_hog_ori_actor_real = extract_validation(ori_actor_train_real)\n",
    "train_hog_ori_youtube_real, val_hog_ori_youtube_real = extract_validation(ori_youtube_train_real)\n",
    "train_hog_mni_dfd_fake, val_hog_mni_dfd_fake = extract_validation(mni_dfd_train_fake)\n",
    "train_hog_mni_df_fake, val_hog_mni_df_fake = extract_validation(mni_df_train_fake)\n",
    "train_hog_mni_f2f_fake, val_hog_mni_f2f_fake = extract_validation(mni_f2f_train_fake)\n",
    "train_hog_mni_fshifter_fake, val_hog_mni_fshifter_fake = extract_validation(mni_fshifter_train_fake)\n",
    "train_hog_mni_fswap_fake, val_hog_mni_fswap_fake = extract_validation(mni_fswap_train_fake)\n",
    "train_hog_mni_nt_fake, val_hog_mni_nt_fake = extract_validation(mni_nt_train_fake)\n",
    "# Print results for verification\n",
    "print(f\"train_ori_actor hog_real: {len(train_hog_ori_actor_real)} images, val_ori_actor hog_real: {len(val_hog_ori_actor_real)} images\")\n",
    "print(f\"train_ ori_youtube hog_real: {len(train_hog_ori_youtube_real)} images, val_ ori_youtube hog_real: {len(val_hog_ori_youtube_real)} images\")\n",
    "print(f\"train_hog_mni_dfd_fake: {len(train_hog_mni_dfd_fake)} images, val_hog_mni_dfd_fake: {len(val_hog_mni_dfd_fake)} images\")\n",
    "print(f\"train_hog_mni_df_fake: {len(train_hog_mni_df_fake)} images, val_hog_mni_df_fake: {len(val_hog_mni_df_fake)} images\")\n",
    "print(f\"train_hog_mni_f2f_fake: {len(train_hog_mni_f2f_fake)} images, val_hog_mni_f2f_fake: {len(val_hog_mni_f2f_fake)} images\")\n",
    "print(f\"train_hog_mni_fshifter_fake: {len(train_hog_mni_fshifter_fake)} images, val_hog_mni_fshifter_fake: {len(val_hog_mni_fshifter_fake)} images\")\n",
    "print(f\"train_hog_mni_fswap_fake: {len(train_hog_mni_fswap_fake)} images, val_hog_mni_fswap_fake: {len(val_hog_mni_fswap_fake)} images\")\n",
    "print(f\"train_hog_mni_nt_fake: {len(train_hog_mni_nt_fake)} images, val_hog_mni_nt_fake: {len(val_hog_mni_nt_fake)} images\")\n",
    "############################################################################################################################################################\n",
    "#################################################concatenate the labels 0,1 real and fake\n",
    "#############################################################################################################################################################\n",
    "\n",
    "\n",
    "train_ori_actor_labels_real = np.zeros(len(train_hog_ori_actor_real), dtype=int)\n",
    "train_ori_youtube_labels_real = np.zeros(len(train_hog_ori_youtube_real), dtype=int)\n",
    "train_mni_dfd_labels_fake = np.ones(len(train_hog_mni_dfd_fake), dtype=int)\n",
    "train_mni_df_labels_fake = np.ones(len(train_hog_mni_df_fake), dtype=int)\n",
    "train_mni_f2f_labels_fake = np.ones(len(train_hog_mni_f2f_fake), dtype=int)\n",
    "train_mni_fshifter_labels_fake = np.ones(len(train_hog_mni_fshifter_fake), dtype=int)\n",
    "train_mni_fswap_labels_fake = np.ones(len(train_hog_mni_fswap_fake), dtype=int)\n",
    "train_mni_nt_labels_fake = np.ones(len(train_hog_mni_nt_fake), dtype=int)\n",
    "\n",
    "test_ori_actor_labels_real = np.zeros(len(ori_actor_test_real), dtype=int)\n",
    "test_ori_youtube_labels_real = np.zeros(len(ori_youtube_test_real), dtype=int)\n",
    "test_mni_dfd_labels_fake = np.ones(len(mni_dfd_test_fake), dtype=int)\n",
    "test_mni_df_labels_fake = np.ones(len(mni_df_test_fake), dtype=int)\n",
    "test_mni_f2f_labels_fake = np.ones(len(mni_f2f_test_fake), dtype=int)\n",
    "test_mni_fshifter_labels_fake = np.ones(len(mni_fshifter_test_fake), dtype=int)\n",
    "test_mni_fswap_labels_fake = np.ones(len(mni_fswap_test_fake), dtype=int)\n",
    "test_mni_nt_labels_fake = np.ones(len(mni_nt_test_fake), dtype=int)\n",
    "\n",
    "\n",
    "val_ori_actor_labels_real = np.zeros(len(val_hog_ori_actor_real), dtype=int)\n",
    "val_ori_youtube_labels_real = np.zeros(len(val_hog_ori_youtube_real), dtype=int)\n",
    "val_mni_dfd_labels_fake = np.ones(len(val_hog_mni_dfd_fake), dtype=int)\n",
    "val_mni_df_labels_fake = np.ones(len(val_hog_mni_df_fake), dtype=int)\n",
    "val_mni_f2f_labels_fake = np.ones(len(val_hog_mni_f2f_fake), dtype=int)\n",
    "val_mni_fshifter_labels_fake = np.ones(len(val_hog_mni_fshifter_fake), dtype=int)\n",
    "val_mni_fswap_labels_fake = np.ones(len(val_hog_mni_fswap_fake), dtype=int)\n",
    "val_mni_nt_labels_fake = np.ones(len(val_hog_mni_nt_fake), dtype=int)\n",
    "##################################################################################################################\n",
    "\n",
    "# Concatenate all training datasets into a single `train` variable\n",
    "train_ff = np.concatenate([train_hog_ori_actor_real, train_hog_ori_youtube_real,train_hog_mni_dfd_fake,train_hog_mni_df_fake,\n",
    "                            train_hog_mni_f2f_fake,train_hog_mni_fshifter_fake,train_hog_mni_fswap_fake,train_hog_mni_nt_fake], axis=0)\n",
    "\n",
    "train_labels_ff = np.concatenate([train_ori_actor_labels_real, train_ori_youtube_labels_real,train_mni_dfd_labels_fake,train_mni_df_labels_fake,\n",
    "                            train_mni_f2f_labels_fake,train_mni_fshifter_labels_fake,train_mni_fswap_labels_fake,train_mni_nt_labels_fake], axis=0)\n",
    "\n",
    "# Concatenate all validation datasets into a single `val` variable\n",
    "val_ff = np.concatenate([val_hog_ori_actor_real, val_hog_ori_youtube_real, val_hog_mni_dfd_fake, val_hog_mni_df_fake,\n",
    "                            val_hog_mni_f2f_fake, val_hog_mni_fshifter_fake, val_hog_mni_fswap_fake, val_hog_mni_nt_fake], axis=0)\n",
    "val_labels_ff = np.concatenate([val_ori_actor_labels_real, val_ori_youtube_labels_real, val_mni_dfd_labels_fake, val_mni_df_labels_fake,\n",
    "                            val_mni_f2f_labels_fake, val_mni_fshifter_labels_fake, val_mni_fswap_labels_fake, val_mni_nt_labels_fake], axis=0)\n",
    "# Concatenate all testing datasets into a single `test` variable\n",
    "test_ff = np.concatenate([ori_actor_test_real, ori_youtube_test_real, mni_dfd_test_fake,\n",
    "                           mni_df_test_fake, mni_f2f_test_fake, mni_fshifter_test_fake,\n",
    "                           mni_fswap_test_fake, mni_nt_test_fake], axis=0)\n",
    "test_labels_ff = np.concatenate([test_ori_actor_labels_real, test_ori_youtube_labels_real, test_mni_dfd_labels_fake, test_mni_df_labels_fake,\n",
    "                            test_mni_f2f_labels_fake, test_mni_fshifter_labels_fake, test_mni_fswap_labels_fake, test_mni_nt_labels_fake], axis=0)\n",
    "\n",
    "\n",
    "# Print the results for verification\n",
    "# Print the results for verification\n",
    "print(f\"Total train: {len(train_ff)} images, and shape:{train_ff.shape}\")\n",
    "print(f\"Total test: {len(test_ff)} images, and shape:{test_ff.shape}\")\n",
    "print(f\"Total val: {len(val_ff)} images, and shape:{val_ff.shape}\")\n",
    "\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"Train Labels: {len(train_labels_ff)} \")\n",
    "print(f\"Test Labels: {len(test_labels_ff)} \")\n",
    "print(f\"Val Labels: {len(val_labels_ff)} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d03ccb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data into PyTorch Dataset\n",
    "train_dataset = ImageDataset(train_ff, train_labels_ff, transform)\n",
    "val_dataset = ImageDataset(val_ff, val_labels_ff, transform)\n",
    "test_dataset = ImageDataset(test_ff, test_labels_ff, transform)\n",
    "\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bf4ddaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 706/706 [4:54:55<00:00, 25.06s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: LR = 3.40e-05, Loss = 0.6006, Acc = 70.92%\n",
      "Val Metrics: {'accuracy': 0.7285031847133758, 'precision': 0.6868948531749695, 'recall': 0.7285031847133758, 'f1': 0.6241261778774199}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 706/706 [5:02:47<00:00, 25.73s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: LR = 6.70e-05, Loss = 0.5022, Acc = 76.38%\n",
      "Val Metrics: {'accuracy': 0.7921974522292994, 'precision': 0.7827881904563015, 'recall': 0.7921974522292994, 'f1': 0.7851557910766196}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 706/706 [5:03:04<00:00, 25.76s/it]  \n",
      "c:\\Users\\aneek\\anaconda3\\envs\\tf_gpu_env\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: LR = 1.00e-04, Loss = 0.3893, Acc = 82.40%\n",
      "Val Metrics: {'accuracy': 0.8136942675159236, 'precision': 0.8178187779855818, 'recall': 0.8136942675159236, 'f1': 0.7884988707590022}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 706/706 [5:03:48<00:00, 25.82s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: LR = 9.50e-05, Loss = 0.2974, Acc = 87.16%\n",
      "Val Metrics: {'accuracy': 0.8431528662420382, 'precision': 0.8429013817429724, 'recall': 0.8431528662420382, 'f1': 0.8301648890918051}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 706/706 [5:01:06<00:00, 25.59s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: LR = 8.12e-05, Loss = 0.1785, Acc = 92.71%\n",
      "Val Metrics: {'accuracy': 0.8550955414012739, 'precision': 0.8524638800764691, 'recall': 0.8550955414012739, 'f1': 0.8534087952905665}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 706/706 [5:11:28<00:00, 26.47s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: LR = 6.11e-05, Loss = 0.0950, Acc = 96.40%\n",
      "Val Metrics: {'accuracy': 0.8710191082802548, 'precision': 0.867810478240048, 'recall': 0.8710191082802548, 'f1': 0.8678189989036557}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 706/706 [5:12:29<00:00, 26.56s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: LR = 3.89e-05, Loss = 0.0458, Acc = 98.30%\n",
      "Val Metrics: {'accuracy': 0.8527070063694268, 'precision': 0.8584358564925647, 'recall': 0.8527070063694268, 'f1': 0.8548428677581492}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 706/706 [5:13:46<00:00, 26.67s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: LR = 1.88e-05, Loss = 0.0222, Acc = 99.25%\n",
      "Val Metrics: {'accuracy': 0.8757961783439491, 'precision': 0.873217455737871, 'recall': 0.8757961783439491, 'f1': 0.8713516754984924}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 706/706 [4:54:29<00:00, 25.03s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: LR = 4.95e-06, Loss = 0.0051, Acc = 99.85%\n",
      "Val Metrics: {'accuracy': 0.8757961783439491, 'precision': 0.8730582605809842, 'recall': 0.8757961783439491, 'f1': 0.8716651597754506}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 706/706 [4:32:06<00:00, 23.12s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: LR = 0.00e+00, Loss = 0.0024, Acc = 99.96%\n",
      "Val Metrics: {'accuracy': 0.875, 'precision': 0.8725734309708305, 'recall': 0.875, 'f1': 0.8732183370461996}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 10  # Increase epochs for better accuracy\n",
    "train_model(model, train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "006d6259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n",
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 1.5%\n",
      "Time Usage: 477.2 s\n",
      "GPU Memory Used: 929.1 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor1.get_stats()\n",
    "# Final evaluation on test data\n",
    "test_metrics = evaluate_metrics(model, test_loader)\n",
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "#7.7 gpu\n",
    "\n",
    "end = monitor1.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")#7.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60e28622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics:\n",
      "- Accuracy: 0.8751\n",
      "- Precision: 0.8728\n",
      "- Recall: 0.8751\n",
      "- F1 Score: 0.8735\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test data\n",
    "test_metrics = evaluate_metrics(model, test_loader)\n",
    "print(f\"Test Metrics:\")\n",
    "print(f\"- Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"- Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"- Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"- F1 Score: {test_metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e35a7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Simulate loading time\u001b[39;00m\n\u001b[0;32m      4\u001b[0m end \u001b[38;5;241m=\u001b[39m monitor\u001b[38;5;241m.\u001b[39mget_stats()\n\u001b[1;32m----> 5\u001b[0m duration \u001b[38;5;241m=\u001b[39m end[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[43mstart\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== RESOURCE USAGE ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPU Usage: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'start' is not defined"
     ]
    }
   ],
   "source": [
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")#15%\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")#29GB\n",
    "print(f\"Time Usage: {duration:.1f} s\")#3143m+52m 191700s\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")#7.6\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "971a79e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of DFC on F++ ON CrossVit\n",
      "Test Metrics:\n",
      "- Accuracy: 0.5207\n",
      "- Precision: 0.5212\n",
      "- Recall: 0.5207\n",
      "- F1 Score: 0.5176\n"
     ]
    }
   ],
   "source": [
    "test_dataset = ImageDataset(test_hog, test_labels, transform)\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Test Accuracy of DFC on F++ ON CrossVit\")\n",
    "# Final evaluation on test data\n",
    "test_metrics = evaluate_metrics(model, test_loader)\n",
    "print(f\"Test Metrics:\")\n",
    "print(f\"- Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"- Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"- Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"- F1 Score: {test_metrics['f1']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73157385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of Celeb-DF(V2) on F++ ON CrossVit\n",
      "Test Metrics:\n",
      "- Accuracy: 0.7830\n",
      "- Precision: 0.7704\n",
      "- Recall: 0.7830\n",
      "- F1 Score: 0.7564\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_dataset = ImageDataset(test, test_labels, transform)\n",
    "# Dataloaders\n",
    "batch_size = 16\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Test Accuracy of Celeb-DF(V2) on F++ ON CrossVit\")\n",
    "# Final evaluation on test data\n",
    "test_metrics = evaluate_metrics(model, test_loader)\n",
    "print(f\"Test Metrics:\")\n",
    "print(f\"- Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"- Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"- Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"- F1 Score: {test_metrics['f1']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
