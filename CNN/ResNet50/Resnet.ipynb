{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a643551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import psutil\n",
    "\n",
    "class PowerMonitor:\n",
    "    def __init__(self):\n",
    "        self.gpu_available = tf.config.list_physical_devices('GPU')\n",
    "        \n",
    "        # Hardware power specifications (adjust these values for your system)\n",
    "        self.cpu_tdp = 65    # Typical TDP for desktop CPUs in watts\n",
    "        self.gpu_tdp = 250   # Typical TDP for desktop GPUs in watts\n",
    "        \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get system stats with power estimation\"\"\"\n",
    "        stats = {\n",
    "            'timestamp': time.time(),\n",
    "            'cpu_%': psutil.cpu_percent(interval=0.1),\n",
    "            'ram_mb': psutil.virtual_memory().used / (1024**2),\n",
    "            'gpu_mem_mb': 0,\n",
    "            'power_w': self.cpu_tdp * (psutil.cpu_percent()/100) * 0.85  # Base CPU power\n",
    "        }\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            try:\n",
    "                # TensorFlow GPU memory monitoring\n",
    "                mem_info = tf.config.experimental.get_memory_info('GPU:0')\n",
    "                stats.update({\n",
    "                    'gpu_mem_mb': mem_info['current'] / (1024**2),\n",
    "                    'power_w': self.cpu_tdp * (psutil.cpu_percent()/100) * 0.85 + \n",
    "                              self.gpu_tdp * 0.5 * 0.75  # Add GPU power estimate\n",
    "                })\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        return stats\n",
    "\n",
    "# Initialize monitor\n",
    "monitor = PowerMonitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a293c1",
   "metadata": {},
   "source": [
    "# Celeb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63683390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9870, 160, 160, 3), (11274, 160, 160, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import h5py\n",
    "\n",
    "# Open the HDF5 file for reading\n",
    "#with h5py.File(\"D:\\\\thesis\\dataset\\deepfake dataset\\images_celeb_224R_processed.h5\", \"r\") as h5f:\n",
    "with h5py.File(\"D:\\\\thesis\\dataset\\Celeb-Df-v2\\images_celeb_balanced_224R_processed.h5\", \"r\") as h5f:\n",
    "    # Load HOG features\n",
    "    real_frames_array1 = h5f[\"ori_actor\"][:]\n",
    "    fake_frames_array1 = h5f[\"ori_youtube\"][:]\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Function to resize images from (224, 224) to (160, 160)\n",
    "def resize_images(image_array, target_size=(160, 160)):\n",
    "    resized_images = np.array([cv2.resize(img, target_size) for img in image_array])\n",
    "    return resized_images\n",
    "\n",
    "\n",
    "# Resize the images\n",
    "real_frames_array1 = resize_images(real_frames_array1, target_size=(160, 160))\n",
    "fake_frames_array1 = resize_images(fake_frames_array1, target_size=(160, 160))\n",
    "\n",
    "# Checking the new shapes\n",
    "real_frames_array1.shape, fake_frames_array1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ed4a7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data real shape: (6909, 160, 160, 3)\n",
      "Testing real data shape: (2961, 160, 160, 3)\n",
      "Training fake data shape: (7891, 160, 160, 3)\n",
      "Testing  fake data shape: (3383, 160, 160, 3)\n",
      "train_hog_real: 6218 images, val_hog_real: 691 images\n",
      "train_hog_fake: 7101 images, val_hog_fake: 790 images\n",
      "Total train: 13319 images\n",
      "Total test: 10852 images\n",
      "Total val: 1481 images\n",
      "Train Labels: 13319 \n",
      "Test Labels: 10852 \n",
      "Val Labels: 1481 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the data into train (70%) and test (30%)\n",
    "X_train_real, X_test_real = train_test_split(real_frames_array1, test_size=0.3, random_state=42)\n",
    "X_train_fake, X_test_fake = train_test_split(fake_frames_array1, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Output the shape to confirm the split dimensions\n",
    "print(\"Training data real shape:\", X_train_real.shape)\n",
    "print(\"Testing real data shape:\", X_test_real.shape)\n",
    "print(\"Training fake data shape:\", X_train_fake.shape)\n",
    "print(\"Testing  fake data shape:\", X_test_fake.shape)\n",
    "########################################################################################################################################\n",
    "#######################################divide into 60,10 train and val\n",
    "#########################################################################################################################################\n",
    "def extract_validation(train_data):\n",
    "    \"\"\"\n",
    "    Extract every 10th sample from the training data and store it in a validation set.\n",
    "\n",
    "    Parameters:\n",
    "        train_data (list or np.array): The training dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated training dataset and validation dataset.\n",
    "    \"\"\"\n",
    "    # Select every 10th sample for the validation set\n",
    "    validation_data = train_data[::10]\n",
    "\n",
    "    # Remove the selected samples from the training dataset\n",
    "    updated_train_data = [train_data[i] for i in range(len(train_data)) if i % 10 != 0]\n",
    "\n",
    "    return np.array(updated_train_data), np.array(validation_data)\n",
    "\n",
    "\n",
    "# Perform the operation for each dataset\n",
    "train_hog_real, val_hog_real = extract_validation(X_train_real)\n",
    "train_hog_fake, val_hog_fake = extract_validation(X_train_fake)\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"train_hog_real: {len(train_hog_real)} images, val_hog_real: {len(val_hog_real)} images\")\n",
    "print(f\"train_hog_fake: {len(train_hog_fake)} images, val_hog_fake: {len(val_hog_fake)} images\")\n",
    "\n",
    "\n",
    "############################################################################################################################################################\n",
    "#################################################concatenate the labels 0,1 real and fake\n",
    "#############################################################################################################################################################\n",
    "\n",
    "\n",
    "train_labels_real = np.zeros(len(train_hog_real), dtype=int)\n",
    "train_labels_fake = np.ones(len(train_hog_fake), dtype=int)\n",
    "\n",
    "# Concatenate all training datasets into a single `train` variable\n",
    "train = np.concatenate([train_hog_real, train_hog_fake], axis=0)\n",
    "train_labels=np.concatenate([train_labels_real, train_labels_fake], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "test_labels_real = np.zeros(len(X_test_real), dtype=int)\n",
    "test_labels_fake = np.ones(len(X_train_fake), dtype=int)\n",
    "\n",
    "# Concatenate all testing datasets into a single `test` variable\n",
    "test = np.concatenate([X_test_real, X_train_fake], axis=0)\n",
    "test_labels = np.concatenate([test_labels_real, test_labels_fake], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "val_labels_real = np.zeros(len(val_hog_real), dtype=int)\n",
    "val_labels_fake = np.ones(len(val_hog_fake), dtype=int)\n",
    "\n",
    "# Concatenate all validation datasets into a single `val` variable\n",
    "val = np.concatenate([val_hog_real, val_hog_fake], axis=0)\n",
    "val_labels = np.concatenate([val_labels_real, val_labels_fake], axis=0)\n",
    "\n",
    "# Print the results for verification\n",
    "print(f\"Total train: {len(train)} images\")\n",
    "print(f\"Total test: {len(test)} images\")\n",
    "print(f\"Total val: {len(val)} images\")\n",
    "\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"Train Labels: {len(train_labels)} \")\n",
    "print(f\"Test Labels: {len(test_labels)} \")\n",
    "print(f\"Val Labels: {len(val_labels)} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3add8a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d4cc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 160, 160, 3)]     0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 160, 160, 3)       0         \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 160, 160, 3)       0         \n",
      "                                                                 \n",
      " resnet50 (Functional)       (None, 5, 5, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,112,513\n",
      "Trainable params: 524,801\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "def build_resnet_model(input_shape=(160, 160, 3)):\n",
    "    \"\"\"\n",
    "    Creates a ResNet50-based deepfake detection model\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Tuple specifying input dimensions (height, width, channels)\n",
    "    \n",
    "    Returns:\n",
    "        Compiled Keras model\n",
    "    \"\"\"\n",
    "    # Load pre-trained ResNet50 without top classification layer\n",
    "    base_model = ResNet50(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    \n",
    "    # Freeze the base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Create new model on top\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Rescaling(1./255)(inputs)  # Normalization\n",
    "    \n",
    "    # ResNet preprocessing (matches ImageNet normalization)\n",
    "    x = layers.Lambda(lambda img: (img * 255) - \n",
    "                      tf.constant([103.939, 116.779, 123.68]))(x)\n",
    "    \n",
    "    x = base_model(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Initialize model\n",
    "resnet_model = build_resnet_model(input_shape=(160, 160, 3))\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26c2e544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "417/417 [==============================] - 26s 47ms/step - loss: 0.7205 - accuracy: 0.5721 - val_loss: 0.6421 - val_accuracy: 0.6428\n",
      "Epoch 2/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.6395 - accuracy: 0.6338 - val_loss: 0.6113 - val_accuracy: 0.6759\n",
      "Epoch 3/100\n",
      "417/417 [==============================] - 18s 43ms/step - loss: 0.6050 - accuracy: 0.6725 - val_loss: 0.5981 - val_accuracy: 0.6779\n",
      "Epoch 4/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.5814 - accuracy: 0.6956 - val_loss: 0.5787 - val_accuracy: 0.7016\n",
      "Epoch 5/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.5558 - accuracy: 0.7204 - val_loss: 0.5588 - val_accuracy: 0.7157\n",
      "Epoch 6/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.5356 - accuracy: 0.7399 - val_loss: 0.5517 - val_accuracy: 0.7211\n",
      "Epoch 7/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.5122 - accuracy: 0.7494 - val_loss: 0.5291 - val_accuracy: 0.7306\n",
      "Epoch 8/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.4961 - accuracy: 0.7621 - val_loss: 0.5193 - val_accuracy: 0.7488\n",
      "Epoch 9/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.4729 - accuracy: 0.7808 - val_loss: 0.5020 - val_accuracy: 0.7576\n",
      "Epoch 10/100\n",
      "417/417 [==============================] - 19s 45ms/step - loss: 0.4582 - accuracy: 0.7878 - val_loss: 0.5010 - val_accuracy: 0.7535\n",
      "Epoch 11/100\n",
      "417/417 [==============================] - 19s 45ms/step - loss: 0.4440 - accuracy: 0.8001 - val_loss: 0.4901 - val_accuracy: 0.7603\n",
      "Epoch 12/100\n",
      "417/417 [==============================] - 19s 44ms/step - loss: 0.4278 - accuracy: 0.8123 - val_loss: 0.4956 - val_accuracy: 0.7508\n",
      "Epoch 13/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.4149 - accuracy: 0.8152 - val_loss: 0.4626 - val_accuracy: 0.7887\n",
      "Epoch 14/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.4031 - accuracy: 0.8252 - val_loss: 0.4531 - val_accuracy: 0.7941\n",
      "Epoch 15/100\n",
      "417/417 [==============================] - 19s 44ms/step - loss: 0.3880 - accuracy: 0.8340 - val_loss: 0.4460 - val_accuracy: 0.7954\n",
      "Epoch 16/100\n",
      "417/417 [==============================] - 19s 45ms/step - loss: 0.3713 - accuracy: 0.8431 - val_loss: 0.4378 - val_accuracy: 0.7920\n",
      "Epoch 17/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.3649 - accuracy: 0.8471 - val_loss: 0.4365 - val_accuracy: 0.7914\n",
      "Epoch 18/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.3486 - accuracy: 0.8553 - val_loss: 0.4208 - val_accuracy: 0.8123\n",
      "Epoch 19/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.3358 - accuracy: 0.8631 - val_loss: 0.4149 - val_accuracy: 0.8116\n",
      "Epoch 20/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.3265 - accuracy: 0.8667 - val_loss: 0.4501 - val_accuracy: 0.7846\n",
      "Epoch 21/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.3149 - accuracy: 0.8720 - val_loss: 0.4015 - val_accuracy: 0.8170\n",
      "Epoch 22/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.3026 - accuracy: 0.8803 - val_loss: 0.3940 - val_accuracy: 0.8312\n",
      "Epoch 23/100\n",
      "417/417 [==============================] - 18s 43ms/step - loss: 0.2956 - accuracy: 0.8829 - val_loss: 0.4026 - val_accuracy: 0.8170\n",
      "Epoch 24/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.2920 - accuracy: 0.8854 - val_loss: 0.3863 - val_accuracy: 0.8271\n",
      "Epoch 25/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.2821 - accuracy: 0.8882 - val_loss: 0.3837 - val_accuracy: 0.8265\n",
      "Epoch 26/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.2733 - accuracy: 0.8908 - val_loss: 0.3739 - val_accuracy: 0.8379\n",
      "Epoch 27/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.2604 - accuracy: 0.8984 - val_loss: 0.3689 - val_accuracy: 0.8386\n",
      "Epoch 28/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.2557 - accuracy: 0.9004 - val_loss: 0.3806 - val_accuracy: 0.8285\n",
      "Epoch 29/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.2502 - accuracy: 0.9059 - val_loss: 0.3494 - val_accuracy: 0.8515\n",
      "Epoch 30/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.2434 - accuracy: 0.9069 - val_loss: 0.3554 - val_accuracy: 0.8454\n",
      "Epoch 31/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.2350 - accuracy: 0.9108 - val_loss: 0.3568 - val_accuracy: 0.8460\n",
      "Epoch 32/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.2289 - accuracy: 0.9146 - val_loss: 0.3638 - val_accuracy: 0.8373\n",
      "Epoch 33/100\n",
      "417/417 [==============================] - 19s 44ms/step - loss: 0.2231 - accuracy: 0.9160 - val_loss: 0.3454 - val_accuracy: 0.8521\n",
      "Epoch 34/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.2180 - accuracy: 0.9179 - val_loss: 0.3573 - val_accuracy: 0.8386\n",
      "Epoch 35/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.2129 - accuracy: 0.9224 - val_loss: 0.3371 - val_accuracy: 0.8616\n",
      "Epoch 36/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.2055 - accuracy: 0.9247 - val_loss: 0.3415 - val_accuracy: 0.8569\n",
      "Epoch 37/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.2039 - accuracy: 0.9251 - val_loss: 0.3314 - val_accuracy: 0.8602\n",
      "Epoch 38/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1896 - accuracy: 0.9328 - val_loss: 0.3312 - val_accuracy: 0.8589\n",
      "Epoch 39/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1887 - accuracy: 0.9317 - val_loss: 0.3277 - val_accuracy: 0.8683\n",
      "Epoch 40/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1837 - accuracy: 0.9369 - val_loss: 0.3249 - val_accuracy: 0.8636\n",
      "Epoch 41/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1833 - accuracy: 0.9339 - val_loss: 0.3292 - val_accuracy: 0.8670\n",
      "Epoch 42/100\n",
      "417/417 [==============================] - 18s 43ms/step - loss: 0.1773 - accuracy: 0.9372 - val_loss: 0.3263 - val_accuracy: 0.8683\n",
      "Epoch 43/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1717 - accuracy: 0.9378 - val_loss: 0.3210 - val_accuracy: 0.8670\n",
      "Epoch 44/100\n",
      "417/417 [==============================] - 19s 44ms/step - loss: 0.1667 - accuracy: 0.9399 - val_loss: 0.3139 - val_accuracy: 0.8690\n",
      "Epoch 45/100\n",
      "417/417 [==============================] - 19s 45ms/step - loss: 0.1636 - accuracy: 0.9416 - val_loss: 0.3122 - val_accuracy: 0.8744\n",
      "Epoch 46/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1590 - accuracy: 0.9449 - val_loss: 0.3185 - val_accuracy: 0.8737\n",
      "Epoch 47/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1518 - accuracy: 0.9472 - val_loss: 0.3346 - val_accuracy: 0.8656\n",
      "Epoch 48/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1520 - accuracy: 0.9476 - val_loss: 0.3047 - val_accuracy: 0.8758\n",
      "Epoch 49/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1470 - accuracy: 0.9479 - val_loss: 0.3670 - val_accuracy: 0.8481\n",
      "Epoch 50/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1452 - accuracy: 0.9507 - val_loss: 0.3041 - val_accuracy: 0.8771\n",
      "Epoch 51/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1456 - accuracy: 0.9489 - val_loss: 0.3369 - val_accuracy: 0.8697\n",
      "Epoch 52/100\n",
      "417/417 [==============================] - 19s 44ms/step - loss: 0.1372 - accuracy: 0.9528 - val_loss: 0.3080 - val_accuracy: 0.8704\n",
      "Epoch 53/100\n",
      "417/417 [==============================] - 19s 45ms/step - loss: 0.1345 - accuracy: 0.9550 - val_loss: 0.3003 - val_accuracy: 0.8785\n",
      "Epoch 54/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1343 - accuracy: 0.9555 - val_loss: 0.3121 - val_accuracy: 0.8751\n",
      "Epoch 55/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1263 - accuracy: 0.9592 - val_loss: 0.3110 - val_accuracy: 0.8758\n",
      "Epoch 56/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1229 - accuracy: 0.9604 - val_loss: 0.2965 - val_accuracy: 0.8771\n",
      "Epoch 57/100\n",
      "417/417 [==============================] - 18s 43ms/step - loss: 0.1271 - accuracy: 0.9577 - val_loss: 0.3117 - val_accuracy: 0.8825\n",
      "Epoch 58/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1189 - accuracy: 0.9606 - val_loss: 0.2946 - val_accuracy: 0.8798\n",
      "Epoch 59/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1141 - accuracy: 0.9605 - val_loss: 0.3068 - val_accuracy: 0.8764\n",
      "Epoch 60/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1158 - accuracy: 0.9621 - val_loss: 0.3006 - val_accuracy: 0.8866\n",
      "Epoch 61/100\n",
      "417/417 [==============================] - 18s 43ms/step - loss: 0.1141 - accuracy: 0.9622 - val_loss: 0.3155 - val_accuracy: 0.8751\n",
      "Epoch 62/100\n",
      "417/417 [==============================] - 18s 43ms/step - loss: 0.1100 - accuracy: 0.9640 - val_loss: 0.2995 - val_accuracy: 0.8879\n",
      "Epoch 63/100\n",
      "417/417 [==============================] - 19s 45ms/step - loss: 0.1069 - accuracy: 0.9649 - val_loss: 0.2907 - val_accuracy: 0.8886\n",
      "Epoch 64/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1059 - accuracy: 0.9653 - val_loss: 0.3089 - val_accuracy: 0.8751\n",
      "Epoch 65/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.1052 - accuracy: 0.9650 - val_loss: 0.3082 - val_accuracy: 0.8825\n",
      "Epoch 66/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.0999 - accuracy: 0.9679 - val_loss: 0.3049 - val_accuracy: 0.8805\n",
      "Epoch 67/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.0953 - accuracy: 0.9688 - val_loss: 0.3212 - val_accuracy: 0.8798\n",
      "Epoch 68/100\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.0991 - accuracy: 0.9666 - val_loss: 0.2928 - val_accuracy: 0.8926\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have these from your Xception pipeline\n",
    "# train, train_labels, val, val_labels\n",
    "\n",
    "# Add early stopping\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = resnet_model.fit(\n",
    "    train, train_labels,\n",
    "    validation_data=(val, val_labels),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be6944e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 13s 40ms/step - loss: 0.1517 - accuracy: 0.9545\n",
      "\n",
      "Test Accuracy of Celeb-DF on ResNet50: 95.45%\n",
      "340/340 [==============================] - 13s 36ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91      2961\n",
      "           1       0.96      0.98      0.97      7891\n",
      "\n",
      "    accuracy                           0.95     10852\n",
      "   macro avg       0.95      0.93      0.94     10852\n",
      "weighted avg       0.95      0.95      0.95     10852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = resnet_model.evaluate(test, test_labels)\n",
    "print(f'\\nTest Accuracy of Celeb-DF on ResNet50: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = resnet_model.predict(test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3466dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# After training the model\n",
    "resnet_model.save('resnet(50)_160_celeb.h5')  # Saves the entire model to a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7862e8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 7.1%\n",
      "RAM Used: 3697.5 MB\n",
      "Time Usage: 1296.7 s\n",
      "GPU Memory Used: 1996.4 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2edf283d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n",
      "340/340 [==============================] - 21s 43ms/step - loss: 0.1517 - accuracy: 0.9545\n",
      "\n",
      "Test Accuracy of Celeb-DF on ResNet50: 95.45%\n",
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 12.3%\n",
      "RAM Used: -3407.2 MB\n",
      "Time Usage: 28.6 s\n",
      "GPU Memory Used: 916.9 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor.get_stats()\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('resnet(50)_160_celeb.h5')\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test, test_labels)\n",
    "print(f'\\nTest Accuracy of Celeb-DF on ResNet50: {test_acc*100:.2f}%')\n",
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e7a37bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 4s 38ms/step - loss: 3.2989 - accuracy: 0.5213\n",
      "\n",
      "Test Accuracy of DFC on Resnet50 from Celebdf: 52.13%\n",
      "94/94 [==============================] - 4s 36ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.86      0.64      1500\n",
      "           1       0.57      0.18      0.27      1500\n",
      "\n",
      "    accuracy                           0.52      3000\n",
      "   macro avg       0.54      0.52      0.46      3000\n",
      "weighted avg       0.54      0.52      0.46      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('resnet(50)_160_celeb.h5')\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc= model.evaluate(test_hog, test_labels)\n",
    "print(f'\\nTest Accuracy of DFC on Resnet50 from Celebdf: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test_hog)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a363743d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 7s 37ms/step - loss: 3.3815 - accuracy: 0.3923\n",
      "\n",
      "Test Accuracy of FF++ on Resnet50 from Celebdf: 39.23%\n",
      "169/169 [==============================] - 6s 35ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.83      0.43      1468\n",
      "           1       0.78      0.23      0.35      3911\n",
      "\n",
      "    accuracy                           0.39      5379\n",
      "   macro avg       0.53      0.53      0.39      5379\n",
      "weighted avg       0.65      0.39      0.37      5379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('resnet(50)_160_celeb.h5')\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test_ff, test_labels_ff)\n",
    "print(f'\\nTest Accuracy of FF++ on Resnet50 from Celebdf: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test_ff)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels_ff, y_pred_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a768d8ae",
   "metadata": {},
   "source": [
    "# DFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5493048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celeb shape: (5000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (5000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "celeb shape: (2500, 160, 160, 3), dtype: uint8\n",
      "ffhq shape: (2500, 160, 160, 3), dtype: uint8\n",
      "gdwct shape: (1000, 160, 160, 3), dtype: uint8\n",
      "attagan shape: (1000, 160, 160, 3), dtype: uint8\n",
      "stargan shape: (1000, 160, 160, 3), dtype: uint8\n",
      "stylegan2 shape: (1000, 160, 160, 3), dtype: uint8\n",
      "stylegan shape: (1000, 160, 160, 3), dtype: uint8\n",
      "celeb_train: 1750 images, celeb_test: 750 images\n",
      "ffhq_train: 1750 images, ffhq_test: 750 images\n",
      "attgan_train: 700 images, attgan_test: 300 images\n",
      "stargan_train: 700 images, stargan_test: 300 images\n",
      "gdwct_train: 700 images, gdwct_test: 300 images\n",
      "stylegan2_train: 700 images, stylegan2_test: 300 images\n",
      "stylegan_train: 700 images, stylegan_test: 300 images\n",
      "celeb_train: 1575 images, celeb_val: 175 images\n",
      "ffhq_train: 1575 images, ffhq_val: 175 images\n",
      "attgan_train: 630 images, attgan_val: 70 images\n",
      "stargan_train: 630 images, stargan_val: 70 images\n",
      "gdwct_train: 630 images, gdwct_val: 70 images\n",
      "stylegan2_train: 630 images, stylegan2_val: 70 images\n",
      "stylegan_train: 630 images, stylegan_val: 70 images\n",
      "Total train: 6300 images\n",
      "Total test: 3000 images\n",
      "Total val: 700 images\n",
      "Train Labels: 6300 \n",
      "Test Labels: 3000 \n",
      "Val Labels: 700 \n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "# Open the HDF5 file in read mode\n",
    "with h5py.File('D://thesis//dataset//deepfake dataset//resized_images.h5', 'r') as h5f:\n",
    "    # Access each dataset\n",
    "    celeb = np.array(h5f['celeb'])\n",
    "    ffhq = np.array(h5f['ffhq'])\n",
    "    gdwct = np.array(h5f['gdwct'])\n",
    "    attgan = np.array(h5f['attgan'])\n",
    "    stargan = np.array(h5f['stargan'])\n",
    "    stylegan2 = np.array(h5f['stylegan2'])\n",
    "    stylegan = np.array(h5f['stylegan'])\n",
    "\n",
    "# Now, 'celeb', 'ffhq', etc., are NumPy arrays containing your datasets\n",
    "print(f\"celeb shape: {celeb.shape}, dtype: {celeb.dtype}\")\n",
    "print(f\"ffhq shape: {ffhq.shape}, dtype: {ffhq.dtype}\")\n",
    "print(f\"ffhq shape: {gdwct.shape}, dtype: {gdwct.dtype}\")\n",
    "print(f\"ffhq shape: {attgan.shape}, dtype: {attgan.dtype}\")\n",
    "print(f\"ffhq shape: {stargan.shape}, dtype: {stargan.dtype}\")\n",
    "print(f\"ffhq shape: {stylegan2.shape}, dtype: {stylegan2.dtype}\")\n",
    "print(f\"ffhq shape: {stylegan.shape}, dtype: {stylegan.dtype}\")\n",
    "# Repeat for other datasets as needed\n",
    "import cv2\n",
    "# Function to resize images from (224, 224) to (160, 160)\n",
    "def resize_images(image_array, target_size=(160, 160)):\n",
    "    resized_images = np.array([cv2.resize(img, target_size) for img in image_array])\n",
    "    return resized_images\n",
    "\n",
    "celeb = resize_images(celeb, target_size=(160, 160))\n",
    "ffhq = resize_images(ffhq, target_size=(160, 160))\n",
    "gdwct = resize_images(gdwct, target_size=(160, 160))\n",
    "attgan = resize_images(attgan, target_size=(160, 160))\n",
    "stargan = resize_images(stargan, target_size=(160, 160))\n",
    "stylegan = resize_images(stargan, target_size=(160, 160))\n",
    "stylegan2 = resize_images(stylegan2, target_size=(160, 160))\n",
    "import random\n",
    "# Randomly select 2500 distinct images\n",
    "random_indices = random.sample(range(len(celeb)), 2500)  # Get 2500 random indices\n",
    "celeb = celeb[random_indices]  # Select the random subse\n",
    "\n",
    "import random\n",
    "# Randomly select 2500 distinct images\n",
    "random_indices = random.sample(range(len(ffhq)), 2500)  # Get 2500 random indices\n",
    "ffhq = ffhq[random_indices]  # Select the random subse\n",
    "print(f\"celeb shape: {celeb.shape}, dtype: {celeb.dtype}\")\n",
    "print(f\"ffhq shape: {ffhq.shape}, dtype: {ffhq.dtype}\")\n",
    "print(f\"gdwct shape: {gdwct.shape}, dtype: {gdwct.dtype}\")\n",
    "print(f\"attagan shape: {attgan.shape}, dtype: {attgan.dtype}\")\n",
    "print(f\"stargan shape: {stargan.shape}, dtype: {stargan.dtype}\")\n",
    "print(f\"stylegan2 shape: {stylegan2.shape}, dtype: {stylegan2.dtype}\")\n",
    "print(f\"stylegan shape: {stylegan.shape}, dtype: {stylegan.dtype}\")\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def split_data(data, train_ratio=0.7):\n",
    "    \"\"\"\n",
    "    Splits data into training and testing sets based on the specified ratio.\n",
    "\n",
    "    Parameters:\n",
    "        data (list or np.array): The dataset to split.\n",
    "        train_ratio (float): The ratio of the data to include in the training set.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two datasets - train and test.\n",
    "    \"\"\"\n",
    "    # Shuffle the data\n",
    "    random.shuffle(data)\n",
    "\n",
    "    # Calculate the split index\n",
    "    split_index = int(len(data) * train_ratio)\n",
    "\n",
    "    # Split the data\n",
    "    train_data = data[:split_index]\n",
    "    test_data = data[split_index:]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "# Split `celeb` into 70% train and 30% test\n",
    "celeb_train_hog, celeb_test_hog = split_data(celeb, train_ratio=0.7)\n",
    "\n",
    "# Split `ffhq` into 70% train and 30% test\n",
    "ffhq_train_hog, ffhq_test_hog = split_data(ffhq, train_ratio=0.7)\n",
    "\n",
    "# Split `attgan` into 70% train and 30% test\n",
    "attgan_train_hog, attgan_test_hog = split_data(attgan, train_ratio=0.7)\n",
    "\n",
    "# Split `stargan` into 70% train and 30% test\n",
    "stargan_train_hog, stargan_test_hog = split_data(stargan, train_ratio=0.7)\n",
    "\n",
    "# Split `gdwct` into 70% train and 30% test\n",
    "gdwct_train_hog, gdwct_test_hog = split_data(gdwct, train_ratio=0.7)\n",
    "\n",
    "# Split `stylegan2` into 70% train and 30% test_hog\n",
    "stylegan2_train_hog, stylegan2_test_hog = split_data(stylegan2, train_ratio=0.7)\n",
    "\n",
    "# Split `stylegan` into 70% train and 30% test_hog\n",
    "stylegan_train_hog, stylegan_test_hog = split_data(stylegan, train_ratio=0.7)\n",
    "\n",
    "# Convert to NumPy arrays if needed\n",
    "celeb_train_hog, celeb_test_hog = np.array(celeb_train_hog), np.array(celeb_test_hog)\n",
    "ffhq_train_hog, ffhq_test_hog = np.array(ffhq_train_hog), np.array(ffhq_test_hog)\n",
    "attgan_train_hog, attgan_test_hog = np.array(attgan_train_hog), np.array(attgan_test_hog)\n",
    "stargan_train_hog, stargan_test_hog = np.array(stargan_train_hog), np.array(stargan_test_hog)\n",
    "gdwct_train_hog, gdwct_test_hog = np.array(gdwct_train_hog), np.array(gdwct_test_hog)\n",
    "stylegan2_train_hog, stylegan2_test_hog = np.array(stylegan2_train_hog), np.array(stylegan2_test_hog)\n",
    "stylegan_train_hog, stylegan_test_hog = np.array(stylegan_train_hog), np.array(stylegan_test_hog)\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"celeb_train: {len(celeb_train_hog)} images, celeb_test: {len(celeb_test_hog)} images\")\n",
    "print(f\"ffhq_train: {len(ffhq_train_hog)} images, ffhq_test: {len(ffhq_test_hog)} images\")\n",
    "print(f\"attgan_train: {len(attgan_train_hog)} images, attgan_test: {len(attgan_test_hog)} images\")\n",
    "print(f\"stargan_train: {len(stargan_train_hog)} images, stargan_test: {len(stargan_test_hog)} images\")\n",
    "print(f\"gdwct_train: {len(gdwct_train_hog)} images, gdwct_test: {len(gdwct_test_hog)} images\")\n",
    "print(f\"stylegan2_train: {len(stylegan2_train_hog)} images, stylegan2_test: {len(stylegan2_test_hog)} images\")\n",
    "print(f\"stylegan_train: {len(stylegan_train_hog)} images, stylegan_test: {len(stylegan_test_hog)} images\")\n",
    "\n",
    "########################################################################################################################################\n",
    "#######################################divide into 60,10 train and val\n",
    "#########################################################################################################################################\n",
    "def extract_validation(train_data):\n",
    "    \"\"\"\n",
    "    Extract every 10th sample from the training data and store it in a validation set.\n",
    "\n",
    "    Parameters:\n",
    "        train_data (list or np.array): The training dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated training dataset and validation dataset.\n",
    "    \"\"\"\n",
    "    # Select every 10th sample for the validation set\n",
    "    validation_data = train_data[::10]\n",
    "\n",
    "    # Remove the selected samples from the training dataset\n",
    "    updated_train_data = [train_data[i] for i in range(len(train_data)) if i % 10 != 0]\n",
    "\n",
    "    return np.array(updated_train_data), np.array(validation_data)\n",
    "\n",
    "\n",
    "# Perform the operation for each dataset\n",
    "celeb_train_hog, celeb_val_hog = extract_validation(celeb_train_hog)\n",
    "ffhq_train_hog, ffhq_val_hog = extract_validation(ffhq_train_hog)\n",
    "attgan_train_hog, attgan_val_hog = extract_validation(attgan_train_hog)\n",
    "stargan_train_hog, stargan_val_hog = extract_validation(stargan_train_hog)\n",
    "gdwct_train_hog, gdwct_val_hog = extract_validation(gdwct_train_hog)\n",
    "stylegan2_train_hog, stylegan2_val_hog = extract_validation(stylegan2_train_hog)\n",
    "stylegan_train_hog, stylegan_val_hog = extract_validation(stylegan_train_hog)\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"celeb_train: {len(celeb_train_hog)} images, celeb_val: {len(celeb_val_hog)} images\")\n",
    "print(f\"ffhq_train: {len(ffhq_train_hog)} images, ffhq_val: {len(ffhq_val_hog)} images\")\n",
    "print(f\"attgan_train: {len(attgan_train_hog)} images, attgan_val: {len(attgan_val_hog)} images\")\n",
    "print(f\"stargan_train: {len(stargan_train_hog)} images, stargan_val: {len(stargan_val_hog)} images\")\n",
    "print(f\"gdwct_train: {len(gdwct_train_hog)} images, gdwct_val: {len(gdwct_val_hog)} images\")\n",
    "print(f\"stylegan2_train: {len(stylegan2_train_hog)} images, stylegan2_val: {len(stylegan2_val_hog)} images\")\n",
    "print(f\"stylegan_train: {len(stylegan_train_hog)} images, stylegan_val: {len(stylegan_val_hog)} images\")\n",
    "############################################################################################################################################################\n",
    "#################################################concatenate the labels 0,1 real and fake\n",
    "#############################################################################################################################################################\n",
    "\n",
    "\n",
    "celeb_train_labels = np.zeros(len(celeb_train_hog), dtype=int)\n",
    "ffhq_train_labels = np.zeros(len(ffhq_train_hog), dtype=int)\n",
    "atta_train_labels = np.ones(len(attgan_train_hog), dtype=int)\n",
    "star_train_labels = np.ones(len(stargan_train_hog), dtype=int)\n",
    "gdwct_train_labels = np.ones(len(gdwct_train_hog), dtype=int)\n",
    "stylegan2_train_labels = np.ones(len(stylegan2_train_hog), dtype=int)\n",
    "stylegan_train_labels = np.ones(len(stylegan_train_hog), dtype=int)\n",
    "\n",
    "# Concatenate all training datasets into a single `train` variable\n",
    "train_hog = np.concatenate([celeb_train_hog, ffhq_train_hog, attgan_train_hog, stargan_train_hog, gdwct_train_hog, stylegan2_train_hog, stylegan_train_hog], axis=0)\n",
    "train_labels=np.concatenate([celeb_train_labels, ffhq_train_labels, atta_train_labels, star_train_labels, gdwct_train_labels, stylegan2_train_labels,\n",
    "                              stylegan_train_labels], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "celeb_test_labels = np.zeros(len(celeb_test_hog), dtype=int)\n",
    "ffhq_test_labels = np.zeros(len(ffhq_test_hog), dtype=int)\n",
    "atta_test_labels = np.ones(len(attgan_test_hog), dtype=int)\n",
    "star_test_labels = np.ones(len(stargan_test_hog), dtype=int)\n",
    "gdwct_test_labels = np.ones(len(gdwct_test_hog), dtype=int)\n",
    "stylegan2_test_labels = np.ones(len(stylegan2_test_hog), dtype=int)\n",
    "stylegan_test_labels = np.ones(len(stylegan_test_hog), dtype=int)\n",
    "\n",
    "# Concatenate all testing datasets into a single `test` variable\n",
    "test_hog = np.concatenate([celeb_test_hog, ffhq_test_hog, attgan_test_hog, stargan_test_hog, gdwct_test_hog, stylegan2_test_hog, stylegan_test_hog], axis=0)\n",
    "test_labels = np.concatenate([celeb_test_labels, ffhq_test_labels, atta_test_labels, star_test_labels, gdwct_test_labels, stylegan2_test_labels,\n",
    "                        stylegan_test_labels], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "celeb_val_labels = np.zeros(len(celeb_val_hog), dtype=int)\n",
    "ffhq_val_labels = np.zeros(len(ffhq_val_hog), dtype=int)\n",
    "atta_val_labels = np.ones(len(attgan_val_hog), dtype=int)\n",
    "star_val_labels = np.ones(len(stargan_val_hog), dtype=int)\n",
    "gdwct_val_labels = np.ones(len(gdwct_val_hog), dtype=int)\n",
    "stylegan2_val_labels = np.ones(len(stylegan2_val_hog), dtype=int)\n",
    "stylegan_val_labels = np.ones(len(stylegan_val_hog), dtype=int)\n",
    "\n",
    "# Concatenate all validation datasets into a single `val` variable\n",
    "val_hog = np.concatenate([celeb_val_hog, ffhq_val_hog, attgan_val_hog, stargan_val_hog, gdwct_val_hog, stylegan2_val_hog, stylegan_val_hog], axis=0)\n",
    "val_labels = np.concatenate([celeb_val_labels, ffhq_val_labels, atta_val_labels, star_val_labels, gdwct_val_labels, stylegan2_val_labels,\n",
    "                       stylegan_val_labels], axis=0)\n",
    "\n",
    "# Print the results for verification\n",
    "print(f\"Total train: {len(train_hog)} images\")\n",
    "print(f\"Total test: {len(test_hog)} images\")\n",
    "print(f\"Total val: {len(val_hog)} images\")\n",
    "\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"Train Labels: {len(train_labels)} \")\n",
    "print(f\"Test Labels: {len(test_labels)} \")\n",
    "print(f\"Val Labels: {len(val_labels)} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c9a640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "197/197 [==============================] - 16s 49ms/step - loss: 0.4817 - accuracy: 0.7725 - val_loss: 0.2858 - val_accuracy: 0.9014\n",
      "Epoch 2/100\n",
      "197/197 [==============================] - 12s 59ms/step - loss: 0.2877 - accuracy: 0.8865 - val_loss: 0.2180 - val_accuracy: 0.9300\n",
      "Epoch 3/100\n",
      "197/197 [==============================] - 12s 63ms/step - loss: 0.2167 - accuracy: 0.9205 - val_loss: 0.1853 - val_accuracy: 0.9514\n",
      "Epoch 4/100\n",
      "197/197 [==============================] - 11s 54ms/step - loss: 0.1823 - accuracy: 0.9305 - val_loss: 0.1583 - val_accuracy: 0.9557\n",
      "Epoch 5/100\n",
      "197/197 [==============================] - 11s 58ms/step - loss: 0.1403 - accuracy: 0.9546 - val_loss: 0.1419 - val_accuracy: 0.9643\n",
      "Epoch 6/100\n",
      "197/197 [==============================] - 13s 65ms/step - loss: 0.1218 - accuracy: 0.9592 - val_loss: 0.1214 - val_accuracy: 0.9671\n",
      "Epoch 7/100\n",
      "197/197 [==============================] - 13s 64ms/step - loss: 0.0990 - accuracy: 0.9708 - val_loss: 0.1080 - val_accuracy: 0.9686\n",
      "Epoch 8/100\n",
      "197/197 [==============================] - 12s 63ms/step - loss: 0.0908 - accuracy: 0.9710 - val_loss: 0.0997 - val_accuracy: 0.9657\n",
      "Epoch 9/100\n",
      "197/197 [==============================] - 13s 64ms/step - loss: 0.0763 - accuracy: 0.9790 - val_loss: 0.0931 - val_accuracy: 0.9729\n",
      "Epoch 10/100\n",
      "197/197 [==============================] - 12s 63ms/step - loss: 0.0693 - accuracy: 0.9813 - val_loss: 0.0823 - val_accuracy: 0.9729\n",
      "Epoch 11/100\n",
      "197/197 [==============================] - 13s 66ms/step - loss: 0.0612 - accuracy: 0.9840 - val_loss: 0.0787 - val_accuracy: 0.9771\n",
      "Epoch 12/100\n",
      "197/197 [==============================] - 12s 61ms/step - loss: 0.0504 - accuracy: 0.9883 - val_loss: 0.0787 - val_accuracy: 0.9743\n",
      "Epoch 13/100\n",
      "197/197 [==============================] - 13s 65ms/step - loss: 0.0461 - accuracy: 0.9883 - val_loss: 0.0721 - val_accuracy: 0.9771\n",
      "Epoch 14/100\n",
      "197/197 [==============================] - 13s 65ms/step - loss: 0.0408 - accuracy: 0.9913 - val_loss: 0.0637 - val_accuracy: 0.9843\n",
      "Epoch 15/100\n",
      "197/197 [==============================] - 12s 63ms/step - loss: 0.0399 - accuracy: 0.9903 - val_loss: 0.0620 - val_accuracy: 0.9814\n",
      "Epoch 16/100\n",
      "197/197 [==============================] - 9s 44ms/step - loss: 0.0330 - accuracy: 0.9929 - val_loss: 0.0673 - val_accuracy: 0.9800\n",
      "Epoch 17/100\n",
      "197/197 [==============================] - 9s 44ms/step - loss: 0.0294 - accuracy: 0.9944 - val_loss: 0.0625 - val_accuracy: 0.9843\n",
      "Epoch 18/100\n",
      "197/197 [==============================] - 9s 44ms/step - loss: 0.0283 - accuracy: 0.9948 - val_loss: 0.0661 - val_accuracy: 0.9829\n",
      "Epoch 19/100\n",
      "197/197 [==============================] - 9s 45ms/step - loss: 0.0223 - accuracy: 0.9967 - val_loss: 0.0603 - val_accuracy: 0.9843\n",
      "Epoch 20/100\n",
      "197/197 [==============================] - 9s 44ms/step - loss: 0.0230 - accuracy: 0.9957 - val_loss: 0.0642 - val_accuracy: 0.9829\n",
      "Epoch 21/100\n",
      "197/197 [==============================] - 9s 44ms/step - loss: 0.0207 - accuracy: 0.9954 - val_loss: 0.0570 - val_accuracy: 0.9843\n",
      "Epoch 22/100\n",
      "197/197 [==============================] - 9s 44ms/step - loss: 0.0175 - accuracy: 0.9975 - val_loss: 0.0628 - val_accuracy: 0.9814\n",
      "Epoch 23/100\n",
      "197/197 [==============================] - 9s 45ms/step - loss: 0.0178 - accuracy: 0.9962 - val_loss: 0.0657 - val_accuracy: 0.9814\n",
      "Epoch 24/100\n",
      "197/197 [==============================] - 9s 45ms/step - loss: 0.0150 - accuracy: 0.9978 - val_loss: 0.0591 - val_accuracy: 0.9843\n",
      "Epoch 25/100\n",
      "197/197 [==============================] - 9s 45ms/step - loss: 0.0128 - accuracy: 0.9983 - val_loss: 0.0560 - val_accuracy: 0.9829\n",
      "Epoch 26/100\n",
      "197/197 [==============================] - 9s 45ms/step - loss: 0.0120 - accuracy: 0.9986 - val_loss: 0.0524 - val_accuracy: 0.9829\n",
      "Epoch 27/100\n",
      "197/197 [==============================] - 9s 45ms/step - loss: 0.0124 - accuracy: 0.9983 - val_loss: 0.0539 - val_accuracy: 0.9843\n",
      "Epoch 28/100\n",
      "197/197 [==============================] - 9s 44ms/step - loss: 0.0106 - accuracy: 0.9984 - val_loss: 0.0556 - val_accuracy: 0.9829\n",
      "Epoch 29/100\n",
      "197/197 [==============================] - 9s 44ms/step - loss: 0.0094 - accuracy: 0.9989 - val_loss: 0.0594 - val_accuracy: 0.9814\n",
      "Epoch 30/100\n",
      "197/197 [==============================] - 9s 44ms/step - loss: 0.0095 - accuracy: 0.9986 - val_loss: 0.0573 - val_accuracy: 0.9857\n",
      "Epoch 31/100\n",
      "197/197 [==============================] - 9s 45ms/step - loss: 0.0081 - accuracy: 0.9995 - val_loss: 0.0588 - val_accuracy: 0.9857\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have these from your Xception pipeline\n",
    "# train, train_labels, val, val_labels\n",
    "\n",
    "# Add early stopping\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = resnet_model.fit(\n",
    "    train_hog, train_labels,\n",
    "    validation_data=(val_hog, val_labels),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57f67017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 4s 39ms/step - loss: 0.1292 - accuracy: 0.9610\n",
      "\n",
      "Test Accuracy of DFC on ResNet50: 96.10%\n",
      "94/94 [==============================] - 4s 36ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      1500\n",
      "           1       0.96      0.96      0.96      1500\n",
      "\n",
      "    accuracy                           0.96      3000\n",
      "   macro avg       0.96      0.96      0.96      3000\n",
      "weighted avg       0.96      0.96      0.96      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = resnet_model.evaluate(test_hog, test_labels)\n",
    "print(f'\\nTest Accuracy of DFC on ResNet50: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = resnet_model.predict(test_hog)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b46fb48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# After training the model\n",
    "resnet_model.save('resnet(50)_160_dfc.h5')  # Saves the entire model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37c23af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 12.6%\n",
      "RAM Used: 4294.0 MB\n",
      "Time Usage: 569.5 s\n",
      "GPU Memory Used: 117.6 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f07a68fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n",
      "94/94 [==============================] - 8s 42ms/step - loss: 0.1416 - accuracy: 0.9480\n",
      "\n",
      "Test Accuracy of Celeb-DF on ResNet50: 94.80%\n",
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 3.5%\n",
      "RAM Used: 4052.1 MB\n",
      "Time Usage: 13.2 s\n",
      "GPU Memory Used: 341.8 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor.get_stats()\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('resnet(50)_160_dfc.h5')\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test_hog, test_labels)\n",
    "print(f'\\nTest Accuracy of Celeb-DF on ResNet50: {test_acc*100:.2f}%')\n",
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3c1caf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 4s 40ms/step - loss: 0.1292 - accuracy: 0.9610\n",
      "Test Accuracy of DFC on RESNET: 96.10%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('resnet(50)_160_dfc.h5')\n",
    "test_loss, test_acc = model.evaluate(test_hog, test_labels)\n",
    "print(f'Test Accuracy of DFC on RESNET: {test_acc * 100:.2f}%')\n",
    "# You can now use the model for testing or inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba8acb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 14s 39ms/step - loss: 1.3625 - accuracy: 0.6456\n",
      "\n",
      "Test Accuracy of Celeb-df dataset on Resnet50 for DFC: 64.56%\n",
      "340/340 [==============================] - 13s 37ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.20      0.24      2961\n",
      "           1       0.73      0.81      0.77      7891\n",
      "\n",
      "    accuracy                           0.65     10852\n",
      "   macro avg       0.51      0.51      0.50     10852\n",
      "weighted avg       0.61      0.65      0.62     10852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('resnet(50)_160_dfc.h5')\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test, test_labels)\n",
    "print(f'\\nTest Accuracy of Celeb-df dataset on Resnet50 for DFC: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, y_pred_binary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a834009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 7s 41ms/step - loss: 1.7480 - accuracy: 0.5635\n",
      "\n",
      "Test Accuracy of FF++ on Resnet50t from DFC: 56.35%\n",
      "169/169 [==============================] - 7s 38ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.53      0.40      1468\n",
      "           1       0.77      0.58      0.66      3911\n",
      "\n",
      "    accuracy                           0.56      5379\n",
      "   macro avg       0.54      0.55      0.53      5379\n",
      "weighted avg       0.64      0.56      0.59      5379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('resnet(50)_160_dfc.h5')\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test_ff, test_labels_ff)\n",
    "print(f'\\nTest Accuracy of FF++ on Resnet50t from DFC: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test_ff)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels_ff, y_pred_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4709c6",
   "metadata": {},
   "source": [
    "# FF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca9f7307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from the HDF5 file.\n",
      "Data loaded successfully from the HDF5 file.\n",
      "Data loaded successfully from the HDF5 file.\n",
      "Data loaded successfully from the HDF5 file.\n",
      "Shape of the concatenated array: (2808, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (3299, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (1742, 160, 160, 3)\n",
      "Shape of the concatenated array: (1742, 160, 160, 3)\n",
      "Training data ACTOR real shape: (1965, 160, 160, 3) Testing real data shape: (843, 160, 160, 3)\n",
      "Training data Youtube real shape: (1458, 160, 160, 3) Testing real data shape: (625, 160, 160, 3)\n",
      "Training data DFD fake shape: (2309, 160, 160, 3) Testing fake data shape: (990, 160, 160, 3)\n",
      "Training data DF fake shape: (1458, 160, 160, 3) Testing fake data shape: (625, 160, 160, 3)\n",
      "Training data f2f fake shape: (1458, 160, 160, 3) Testing fake data shape: (625, 160, 160, 3)\n",
      "Training data fshifter fake shape: (1458, 160, 160, 3) Testing fake data shape: (625, 160, 160, 3)\n",
      "Training data fswap fake shape: (1219, 160, 160, 3) Testing fake data shape: (523, 160, 160, 3)\n",
      "Training data nt fake shape: (1219, 160, 160, 3) Testing fake data shape: (523, 160, 160, 3)\n",
      "train_ori_actor hog_real: 1768 images, val_ori_actor hog_real: 197 images\n",
      "train_ ori_youtube hog_real: 1312 images, val_ ori_youtube hog_real: 146 images\n",
      "train_hog_mni_dfd_fake: 2078 images, val_hog_mni_dfd_fake: 231 images\n",
      "train_hog_mni_df_fake: 1312 images, val_hog_mni_df_fake: 146 images\n",
      "train_hog_mni_f2f_fake: 1312 images, val_hog_mni_f2f_fake: 146 images\n",
      "train_hog_mni_fshifter_fake: 1312 images, val_hog_mni_fshifter_fake: 146 images\n",
      "train_hog_mni_fswap_fake: 1097 images, val_hog_mni_fswap_fake: 122 images\n",
      "train_hog_mni_nt_fake: 1097 images, val_hog_mni_nt_fake: 122 images\n",
      "Total train: 11288 images, and shape:(11288, 160, 160, 3)\n",
      "Total test: 5379 images, and shape:(5379, 160, 160, 3)\n",
      "Total val: 1256 images, and shape:(1256, 160, 160, 3)\n",
      "Train Labels: 11288 \n",
      "Test Labels: 5379 \n",
      "Val Labels: 1256 \n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the HDF5 file for reading\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_orignal_processed.h5\", \"r\") as h5f:\n",
    "    org_seq_actor_array = h5f[\"ori_actor\"][:]\n",
    "    org_seq_youtube_array = h5f[\"ori_youtube\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_fake1_processed.h5\", \"r\") as h5f:\n",
    "    meni_seq_dfd_array = h5f[\"mni_dfd\"][:]\n",
    "    meni_seq_df_array = h5f[\"mni_df\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_fake2_processed.h5\", \"r\") as h5f:\n",
    "    meni_seq_f2f_array = h5f[\"mni_f2f\"][:]\n",
    "    meni_seq_fshifter_array = h5f[\"mni_fshifter\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_fake3_processed.h5\", \"r\") as h5f:\n",
    "    meni_seq_fswap_array = h5f[\"mni_fswap\"][:]\n",
    "    meni_seq_nt_array = h5f[\"mni_nt\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "# Output the shape of the resulting array\n",
    "print(f\"Shape of the concatenated array: {org_seq_actor_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {org_seq_youtube_array.shape}\")\n",
    "\n",
    "print(f\"Shape of the concatenated array: {meni_seq_dfd_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_df_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_fshifter_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_f2f_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_fswap_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_nt_array.shape}\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ori_actor_train_real, ori_actor_test_real = train_test_split(org_seq_actor_array, test_size=0.3, random_state=42)\n",
    "ori_youtube_train_real, ori_youtube_test_real = train_test_split(org_seq_youtube_array, test_size=0.3, random_state=42)\n",
    "# Split the data into train (70%) and test (30%)\n",
    "mni_dfd_train_fake, mni_dfd_test_fake = train_test_split(meni_seq_dfd_array, test_size=0.3, random_state=42)\n",
    "mni_df_train_fake, mni_df_test_fake = train_test_split(meni_seq_df_array, test_size=0.3, random_state=42)\n",
    "mni_f2f_train_fake, mni_f2f_test_fake = train_test_split(meni_seq_f2f_array, test_size=0.3, random_state=42)\n",
    "mni_fshifter_train_fake, mni_fshifter_test_fake = train_test_split(meni_seq_fshifter_array, test_size=0.3, random_state=42)\n",
    "mni_fswap_train_fake, mni_fswap_test_fake = train_test_split(meni_seq_fswap_array, test_size=0.3, random_state=42)\n",
    "mni_nt_train_fake, mni_nt_test_fake = train_test_split(meni_seq_nt_array, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Output the shape to confirm the split dimensions\n",
    "print(\"Training data ACTOR real shape:\", ori_actor_train_real.shape, \"Testing real data shape:\", ori_actor_test_real.shape)\n",
    "print(\"Training data Youtube real shape:\", ori_youtube_train_real.shape, \"Testing real data shape:\", ori_youtube_test_real.shape)\n",
    "\n",
    "print(\"Training data DFD fake shape:\", mni_dfd_train_fake.shape, \"Testing fake data shape:\", mni_dfd_test_fake.shape)\n",
    "print(\"Training data DF fake shape:\", mni_df_train_fake.shape, \"Testing fake data shape:\", mni_df_test_fake.shape)\n",
    "print(\"Training data f2f fake shape:\", mni_f2f_train_fake.shape, \"Testing fake data shape:\", mni_f2f_test_fake.shape)\n",
    "print(\"Training data fshifter fake shape:\", mni_fshifter_train_fake.shape, \"Testing fake data shape:\", mni_fshifter_test_fake.shape)\n",
    "print(\"Training data fswap fake shape:\", mni_fswap_train_fake.shape, \"Testing fake data shape:\", mni_fswap_test_fake.shape)\n",
    "print(\"Training data nt fake shape:\", mni_nt_train_fake.shape, \"Testing fake data shape:\", mni_nt_test_fake.shape)\n",
    "########################################################################################################################################\n",
    "#######################################divide into 60,10 train and val\n",
    "#########################################################################################################################################\n",
    "def extract_validation(train_data):\n",
    "    \"\"\"\n",
    "    Extract every 10th sample from the training data and store it in a validation set.\n",
    "\n",
    "    Parameters:\n",
    "        train_data (list or np.array): The training dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated training dataset and validation dataset.\n",
    "    \"\"\"\n",
    "    # Select every 10th sample for the validation set\n",
    "    validation_data = train_data[::10]\n",
    "\n",
    "    # Remove the selected samples from the training dataset\n",
    "    updated_train_data = [train_data[i] for i in range(len(train_data)) if i % 10 != 0]\n",
    "\n",
    "    return np.array(updated_train_data), np.array(validation_data)\n",
    "\n",
    "\n",
    "# Perform the operation for each dataset\n",
    "train_hog_ori_actor_real, val_hog_ori_actor_real = extract_validation(ori_actor_train_real)\n",
    "train_hog_ori_youtube_real, val_hog_ori_youtube_real = extract_validation(ori_youtube_train_real)\n",
    "train_hog_mni_dfd_fake, val_hog_mni_dfd_fake = extract_validation(mni_dfd_train_fake)\n",
    "train_hog_mni_df_fake, val_hog_mni_df_fake = extract_validation(mni_df_train_fake)\n",
    "train_hog_mni_f2f_fake, val_hog_mni_f2f_fake = extract_validation(mni_f2f_train_fake)\n",
    "train_hog_mni_fshifter_fake, val_hog_mni_fshifter_fake = extract_validation(mni_fshifter_train_fake)\n",
    "train_hog_mni_fswap_fake, val_hog_mni_fswap_fake = extract_validation(mni_fswap_train_fake)\n",
    "train_hog_mni_nt_fake, val_hog_mni_nt_fake = extract_validation(mni_nt_train_fake)\n",
    "# Print results for verification\n",
    "print(f\"train_ori_actor hog_real: {len(train_hog_ori_actor_real)} images, val_ori_actor hog_real: {len(val_hog_ori_actor_real)} images\")\n",
    "print(f\"train_ ori_youtube hog_real: {len(train_hog_ori_youtube_real)} images, val_ ori_youtube hog_real: {len(val_hog_ori_youtube_real)} images\")\n",
    "print(f\"train_hog_mni_dfd_fake: {len(train_hog_mni_dfd_fake)} images, val_hog_mni_dfd_fake: {len(val_hog_mni_dfd_fake)} images\")\n",
    "print(f\"train_hog_mni_df_fake: {len(train_hog_mni_df_fake)} images, val_hog_mni_df_fake: {len(val_hog_mni_df_fake)} images\")\n",
    "print(f\"train_hog_mni_f2f_fake: {len(train_hog_mni_f2f_fake)} images, val_hog_mni_f2f_fake: {len(val_hog_mni_f2f_fake)} images\")\n",
    "print(f\"train_hog_mni_fshifter_fake: {len(train_hog_mni_fshifter_fake)} images, val_hog_mni_fshifter_fake: {len(val_hog_mni_fshifter_fake)} images\")\n",
    "print(f\"train_hog_mni_fswap_fake: {len(train_hog_mni_fswap_fake)} images, val_hog_mni_fswap_fake: {len(val_hog_mni_fswap_fake)} images\")\n",
    "print(f\"train_hog_mni_nt_fake: {len(train_hog_mni_nt_fake)} images, val_hog_mni_nt_fake: {len(val_hog_mni_nt_fake)} images\")\n",
    "############################################################################################################################################################\n",
    "#################################################concatenate the labels 0,1 real and fake\n",
    "#############################################################################################################################################################\n",
    "\n",
    "\n",
    "train_ori_actor_labels_real = np.zeros(len(train_hog_ori_actor_real), dtype=int)\n",
    "train_ori_youtube_labels_real = np.zeros(len(train_hog_ori_youtube_real), dtype=int)\n",
    "train_mni_dfd_labels_fake = np.ones(len(train_hog_mni_dfd_fake), dtype=int)\n",
    "train_mni_df_labels_fake = np.ones(len(train_hog_mni_df_fake), dtype=int)\n",
    "train_mni_f2f_labels_fake = np.ones(len(train_hog_mni_f2f_fake), dtype=int)\n",
    "train_mni_fshifter_labels_fake = np.ones(len(train_hog_mni_fshifter_fake), dtype=int)\n",
    "train_mni_fswap_labels_fake = np.ones(len(train_hog_mni_fswap_fake), dtype=int)\n",
    "train_mni_nt_labels_fake = np.ones(len(train_hog_mni_nt_fake), dtype=int)\n",
    "\n",
    "test_ori_actor_labels_real = np.zeros(len(ori_actor_test_real), dtype=int)\n",
    "test_ori_youtube_labels_real = np.zeros(len(ori_youtube_test_real), dtype=int)\n",
    "test_mni_dfd_labels_fake = np.ones(len(mni_dfd_test_fake), dtype=int)\n",
    "test_mni_df_labels_fake = np.ones(len(mni_df_test_fake), dtype=int)\n",
    "test_mni_f2f_labels_fake = np.ones(len(mni_f2f_test_fake), dtype=int)\n",
    "test_mni_fshifter_labels_fake = np.ones(len(mni_fshifter_test_fake), dtype=int)\n",
    "test_mni_fswap_labels_fake = np.ones(len(mni_fswap_test_fake), dtype=int)\n",
    "test_mni_nt_labels_fake = np.ones(len(mni_nt_test_fake), dtype=int)\n",
    "\n",
    "\n",
    "val_ori_actor_labels_real = np.zeros(len(val_hog_ori_actor_real), dtype=int)\n",
    "val_ori_youtube_labels_real = np.zeros(len(val_hog_ori_youtube_real), dtype=int)\n",
    "val_mni_dfd_labels_fake = np.ones(len(val_hog_mni_dfd_fake), dtype=int)\n",
    "val_mni_df_labels_fake = np.ones(len(val_hog_mni_df_fake), dtype=int)\n",
    "val_mni_f2f_labels_fake = np.ones(len(val_hog_mni_f2f_fake), dtype=int)\n",
    "val_mni_fshifter_labels_fake = np.ones(len(val_hog_mni_fshifter_fake), dtype=int)\n",
    "val_mni_fswap_labels_fake = np.ones(len(val_hog_mni_fswap_fake), dtype=int)\n",
    "val_mni_nt_labels_fake = np.ones(len(val_hog_mni_nt_fake), dtype=int)\n",
    "##################################################################################################################\n",
    "\n",
    "# Concatenate all training datasets into a single `train` variable\n",
    "train_ff = np.concatenate([train_hog_ori_actor_real, train_hog_ori_youtube_real,train_hog_mni_dfd_fake,train_hog_mni_df_fake,\n",
    "                            train_hog_mni_f2f_fake,train_hog_mni_fshifter_fake,train_hog_mni_fswap_fake,train_hog_mni_nt_fake], axis=0)\n",
    "\n",
    "train_labels_ff = np.concatenate([train_ori_actor_labels_real, train_ori_youtube_labels_real,train_mni_dfd_labels_fake,train_mni_df_labels_fake,\n",
    "                            train_mni_f2f_labels_fake,train_mni_fshifter_labels_fake,train_mni_fswap_labels_fake,train_mni_nt_labels_fake], axis=0)\n",
    "\n",
    "# Concatenate all validation datasets into a single `val` variable\n",
    "val_ff = np.concatenate([val_hog_ori_actor_real, val_hog_ori_youtube_real, val_hog_mni_dfd_fake, val_hog_mni_df_fake,\n",
    "                            val_hog_mni_f2f_fake, val_hog_mni_fshifter_fake, val_hog_mni_fswap_fake, val_hog_mni_nt_fake], axis=0)\n",
    "val_labels_ff = np.concatenate([val_ori_actor_labels_real, val_ori_youtube_labels_real, val_mni_dfd_labels_fake, val_mni_df_labels_fake,\n",
    "                            val_mni_f2f_labels_fake, val_mni_fshifter_labels_fake, val_mni_fswap_labels_fake, val_mni_nt_labels_fake], axis=0)\n",
    "# Concatenate all testing datasets into a single `test` variable\n",
    "test_ff = np.concatenate([ori_actor_test_real, ori_youtube_test_real, mni_dfd_test_fake,\n",
    "                           mni_df_test_fake, mni_f2f_test_fake, mni_fshifter_test_fake,\n",
    "                           mni_fswap_test_fake, mni_nt_test_fake], axis=0)\n",
    "test_labels_ff = np.concatenate([test_ori_actor_labels_real, test_ori_youtube_labels_real, test_mni_dfd_labels_fake, test_mni_df_labels_fake,\n",
    "                            test_mni_f2f_labels_fake, test_mni_fshifter_labels_fake, test_mni_fswap_labels_fake, test_mni_nt_labels_fake], axis=0)\n",
    "\n",
    "\n",
    "# Print the results for verification\n",
    "# Print the results for verification\n",
    "print(f\"Total train: {len(train_ff)} images, and shape:{train_ff.shape}\")\n",
    "print(f\"Total test: {len(test_ff)} images, and shape:{test_ff.shape}\")\n",
    "print(f\"Total val: {len(val_ff)} images, and shape:{val_ff.shape}\")\n",
    "\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"Train Labels: {len(train_labels_ff)} \")\n",
    "print(f\"Test Labels: {len(test_labels_ff)} \")\n",
    "print(f\"Val Labels: {len(val_labels_ff)} \")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe7a4081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.4788 - accuracy: 0.7893 - val_loss: 0.5273 - val_accuracy: 0.7651\n",
      "Epoch 2/100\n",
      "353/353 [==============================] - 15s 44ms/step - loss: 0.4739 - accuracy: 0.7942 - val_loss: 0.5308 - val_accuracy: 0.7659\n",
      "Epoch 3/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.4701 - accuracy: 0.7935 - val_loss: 0.5257 - val_accuracy: 0.7715\n",
      "Epoch 4/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.4639 - accuracy: 0.7995 - val_loss: 0.5235 - val_accuracy: 0.7651\n",
      "Epoch 5/100\n",
      "353/353 [==============================] - 15s 44ms/step - loss: 0.4573 - accuracy: 0.8029 - val_loss: 0.5306 - val_accuracy: 0.7611\n",
      "Epoch 6/100\n",
      "353/353 [==============================] - 15s 44ms/step - loss: 0.4526 - accuracy: 0.8039 - val_loss: 0.5309 - val_accuracy: 0.7723\n",
      "Epoch 7/100\n",
      "353/353 [==============================] - 15s 44ms/step - loss: 0.4464 - accuracy: 0.8078 - val_loss: 0.5293 - val_accuracy: 0.7611\n",
      "Epoch 8/100\n",
      "353/353 [==============================] - 15s 44ms/step - loss: 0.4435 - accuracy: 0.8065 - val_loss: 0.5297 - val_accuracy: 0.7699\n",
      "Epoch 9/100\n",
      "353/353 [==============================] - 15s 44ms/step - loss: 0.4443 - accuracy: 0.8060 - val_loss: 0.5262 - val_accuracy: 0.7691\n",
      "Epoch 10/100\n",
      "353/353 [==============================] - 15s 44ms/step - loss: 0.4274 - accuracy: 0.8169 - val_loss: 0.5347 - val_accuracy: 0.7596\n",
      "Epoch 11/100\n",
      "353/353 [==============================] - 17s 47ms/step - loss: 0.4264 - accuracy: 0.8189 - val_loss: 0.5325 - val_accuracy: 0.7643\n",
      "Epoch 12/100\n",
      "353/353 [==============================] - 21s 59ms/step - loss: 0.4223 - accuracy: 0.8182 - val_loss: 0.5349 - val_accuracy: 0.7667\n",
      "Epoch 13/100\n",
      "353/353 [==============================] - 20s 58ms/step - loss: 0.4212 - accuracy: 0.8189 - val_loss: 0.5331 - val_accuracy: 0.7731\n",
      "Epoch 14/100\n",
      "353/353 [==============================] - 20s 56ms/step - loss: 0.4144 - accuracy: 0.8203 - val_loss: 0.5323 - val_accuracy: 0.7651\n",
      "Epoch 15/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.4117 - accuracy: 0.8257 - val_loss: 0.5400 - val_accuracy: 0.7731\n",
      "Epoch 16/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.4040 - accuracy: 0.8265 - val_loss: 0.5363 - val_accuracy: 0.7715\n",
      "Epoch 17/100\n",
      "353/353 [==============================] - 21s 59ms/step - loss: 0.4043 - accuracy: 0.8281 - val_loss: 0.5292 - val_accuracy: 0.7707\n",
      "Epoch 18/100\n",
      "353/353 [==============================] - 20s 58ms/step - loss: 0.3917 - accuracy: 0.8327 - val_loss: 0.5330 - val_accuracy: 0.7747\n",
      "Epoch 19/100\n",
      "353/353 [==============================] - 20s 56ms/step - loss: 0.3882 - accuracy: 0.8351 - val_loss: 0.5426 - val_accuracy: 0.7699\n",
      "Epoch 20/100\n",
      "353/353 [==============================] - 21s 60ms/step - loss: 0.3794 - accuracy: 0.8374 - val_loss: 0.5531 - val_accuracy: 0.7747\n",
      "Epoch 21/100\n",
      "353/353 [==============================] - 20s 58ms/step - loss: 0.3793 - accuracy: 0.8373 - val_loss: 0.5394 - val_accuracy: 0.7723\n",
      "Epoch 22/100\n",
      "353/353 [==============================] - 20s 56ms/step - loss: 0.3732 - accuracy: 0.8405 - val_loss: 0.5659 - val_accuracy: 0.7715\n",
      "Epoch 23/100\n",
      "353/353 [==============================] - 20s 56ms/step - loss: 0.3710 - accuracy: 0.8410 - val_loss: 0.5463 - val_accuracy: 0.7691\n",
      "Epoch 24/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.3667 - accuracy: 0.8431 - val_loss: 0.5581 - val_accuracy: 0.7691\n",
      "Epoch 25/100\n",
      "353/353 [==============================] - 20s 58ms/step - loss: 0.3586 - accuracy: 0.8490 - val_loss: 0.5540 - val_accuracy: 0.7588\n",
      "Epoch 26/100\n",
      "353/353 [==============================] - 20s 58ms/step - loss: 0.3574 - accuracy: 0.8474 - val_loss: 0.5504 - val_accuracy: 0.7675\n",
      "Epoch 27/100\n",
      "353/353 [==============================] - 21s 59ms/step - loss: 0.3547 - accuracy: 0.8469 - val_loss: 0.5466 - val_accuracy: 0.7691\n",
      "Epoch 28/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.3470 - accuracy: 0.8537 - val_loss: 0.5606 - val_accuracy: 0.7627\n",
      "Epoch 29/100\n",
      "353/353 [==============================] - 21s 59ms/step - loss: 0.3456 - accuracy: 0.8534 - val_loss: 0.5551 - val_accuracy: 0.7659\n",
      "Epoch 30/100\n",
      "353/353 [==============================] - 20s 58ms/step - loss: 0.3376 - accuracy: 0.8558 - val_loss: 0.5604 - val_accuracy: 0.7675\n",
      "Epoch 31/100\n",
      "353/353 [==============================] - 20s 58ms/step - loss: 0.3321 - accuracy: 0.8609 - val_loss: 0.5675 - val_accuracy: 0.7667\n",
      "Epoch 32/100\n",
      "353/353 [==============================] - 21s 59ms/step - loss: 0.3322 - accuracy: 0.8583 - val_loss: 0.5725 - val_accuracy: 0.7667\n",
      "Epoch 33/100\n",
      "353/353 [==============================] - 21s 59ms/step - loss: 0.3196 - accuracy: 0.8671 - val_loss: 0.5724 - val_accuracy: 0.7611\n",
      "Epoch 34/100\n",
      "353/353 [==============================] - 20s 58ms/step - loss: 0.3207 - accuracy: 0.8653 - val_loss: 0.5620 - val_accuracy: 0.7651\n",
      "Epoch 35/100\n",
      "353/353 [==============================] - 21s 58ms/step - loss: 0.3192 - accuracy: 0.8672 - val_loss: 0.5663 - val_accuracy: 0.7556\n",
      "Epoch 36/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.3146 - accuracy: 0.8681 - val_loss: 0.5855 - val_accuracy: 0.7667\n",
      "Epoch 37/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.3062 - accuracy: 0.8730 - val_loss: 0.5946 - val_accuracy: 0.7683\n",
      "Epoch 38/100\n",
      "353/353 [==============================] - 17s 49ms/step - loss: 0.3071 - accuracy: 0.8746 - val_loss: 0.5928 - val_accuracy: 0.7604\n",
      "Epoch 39/100\n",
      "353/353 [==============================] - 16s 45ms/step - loss: 0.3007 - accuracy: 0.8740 - val_loss: 0.5922 - val_accuracy: 0.7675\n",
      "Epoch 40/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2946 - accuracy: 0.8779 - val_loss: 0.6043 - val_accuracy: 0.7715\n",
      "Epoch 41/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2859 - accuracy: 0.8812 - val_loss: 0.6322 - val_accuracy: 0.7707\n",
      "Epoch 42/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2926 - accuracy: 0.8768 - val_loss: 0.5893 - val_accuracy: 0.7691\n",
      "Epoch 43/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2825 - accuracy: 0.8818 - val_loss: 0.5940 - val_accuracy: 0.7611\n",
      "Epoch 44/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2803 - accuracy: 0.8850 - val_loss: 0.5988 - val_accuracy: 0.7460\n",
      "Epoch 45/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2773 - accuracy: 0.8871 - val_loss: 0.6104 - val_accuracy: 0.7596\n",
      "Epoch 46/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2719 - accuracy: 0.8866 - val_loss: 0.6096 - val_accuracy: 0.7651\n",
      "Epoch 47/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2645 - accuracy: 0.8957 - val_loss: 0.6316 - val_accuracy: 0.7596\n",
      "Epoch 48/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2652 - accuracy: 0.8923 - val_loss: 0.6137 - val_accuracy: 0.7691\n",
      "Epoch 49/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2605 - accuracy: 0.8943 - val_loss: 0.6168 - val_accuracy: 0.7524\n",
      "Epoch 50/100\n",
      "353/353 [==============================] - 15s 44ms/step - loss: 0.2576 - accuracy: 0.8977 - val_loss: 0.6289 - val_accuracy: 0.7532\n",
      "Epoch 51/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2531 - accuracy: 0.8995 - val_loss: 0.6389 - val_accuracy: 0.7675\n",
      "Epoch 52/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2487 - accuracy: 0.8963 - val_loss: 0.6304 - val_accuracy: 0.7580\n",
      "Epoch 53/100\n",
      "353/353 [==============================] - 15s 44ms/step - loss: 0.2470 - accuracy: 0.9002 - val_loss: 0.6295 - val_accuracy: 0.7532\n",
      "Epoch 54/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2442 - accuracy: 0.9013 - val_loss: 0.6383 - val_accuracy: 0.7564\n",
      "Epoch 55/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2372 - accuracy: 0.9050 - val_loss: 0.6181 - val_accuracy: 0.7452\n",
      "Epoch 56/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2320 - accuracy: 0.9093 - val_loss: 0.6360 - val_accuracy: 0.7604\n",
      "Epoch 57/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2318 - accuracy: 0.9095 - val_loss: 0.6319 - val_accuracy: 0.7619\n",
      "Epoch 58/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2307 - accuracy: 0.9065 - val_loss: 0.6504 - val_accuracy: 0.7540\n",
      "Epoch 59/100\n",
      "353/353 [==============================] - 16s 44ms/step - loss: 0.2256 - accuracy: 0.9116 - val_loss: 0.6684 - val_accuracy: 0.7596\n",
      "Epoch 60/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2220 - accuracy: 0.9125 - val_loss: 0.6437 - val_accuracy: 0.7452\n",
      "Epoch 61/100\n",
      "353/353 [==============================] - 15s 44ms/step - loss: 0.2215 - accuracy: 0.9089 - val_loss: 0.6509 - val_accuracy: 0.7524\n",
      "Epoch 62/100\n",
      "353/353 [==============================] - 15s 44ms/step - loss: 0.2190 - accuracy: 0.9112 - val_loss: 0.6684 - val_accuracy: 0.7556\n",
      "Epoch 63/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2094 - accuracy: 0.9213 - val_loss: 0.6620 - val_accuracy: 0.7500\n",
      "Epoch 64/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2107 - accuracy: 0.9175 - val_loss: 0.6832 - val_accuracy: 0.7412\n",
      "Epoch 65/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2053 - accuracy: 0.9216 - val_loss: 0.6683 - val_accuracy: 0.7444\n",
      "Epoch 66/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.2088 - accuracy: 0.9174 - val_loss: 0.6729 - val_accuracy: 0.7484\n",
      "Epoch 67/100\n",
      "353/353 [==============================] - 15s 44ms/step - loss: 0.2037 - accuracy: 0.9181 - val_loss: 0.6711 - val_accuracy: 0.7500\n",
      "Epoch 68/100\n",
      "353/353 [==============================] - 15s 44ms/step - loss: 0.2003 - accuracy: 0.9212 - val_loss: 0.6964 - val_accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.1937 - accuracy: 0.9260 - val_loss: 0.6733 - val_accuracy: 0.7492\n",
      "Epoch 70/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.1931 - accuracy: 0.9230 - val_loss: 0.6915 - val_accuracy: 0.7564\n",
      "Epoch 71/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.1889 - accuracy: 0.9270 - val_loss: 0.6795 - val_accuracy: 0.7389\n",
      "Epoch 72/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.1861 - accuracy: 0.9296 - val_loss: 0.6946 - val_accuracy: 0.7436\n",
      "Epoch 73/100\n",
      "353/353 [==============================] - 16s 44ms/step - loss: 0.1822 - accuracy: 0.9302 - val_loss: 0.7081 - val_accuracy: 0.7484\n",
      "Epoch 74/100\n",
      "353/353 [==============================] - 16s 44ms/step - loss: 0.1885 - accuracy: 0.9264 - val_loss: 0.7093 - val_accuracy: 0.7532\n",
      "Epoch 75/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.1806 - accuracy: 0.9296 - val_loss: 0.7143 - val_accuracy: 0.7428\n",
      "Epoch 76/100\n",
      "353/353 [==============================] - 16s 44ms/step - loss: 0.1782 - accuracy: 0.9337 - val_loss: 0.7251 - val_accuracy: 0.7619\n",
      "Epoch 77/100\n",
      "353/353 [==============================] - 19s 55ms/step - loss: 0.1725 - accuracy: 0.9344 - val_loss: 0.7157 - val_accuracy: 0.7532\n",
      "Epoch 78/100\n",
      "353/353 [==============================] - 21s 60ms/step - loss: 0.1687 - accuracy: 0.9349 - val_loss: 0.7198 - val_accuracy: 0.7492\n",
      "Epoch 79/100\n",
      "353/353 [==============================] - 21s 60ms/step - loss: 0.1733 - accuracy: 0.9319 - val_loss: 0.7539 - val_accuracy: 0.7524\n",
      "Epoch 80/100\n",
      "353/353 [==============================] - 21s 61ms/step - loss: 0.1673 - accuracy: 0.9375 - val_loss: 0.7323 - val_accuracy: 0.7500\n",
      "Epoch 81/100\n",
      "353/353 [==============================] - 21s 59ms/step - loss: 0.1646 - accuracy: 0.9396 - val_loss: 0.7211 - val_accuracy: 0.7420\n",
      "Epoch 82/100\n",
      "353/353 [==============================] - 21s 59ms/step - loss: 0.1646 - accuracy: 0.9378 - val_loss: 0.7774 - val_accuracy: 0.7588\n",
      "Epoch 83/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.1580 - accuracy: 0.9393 - val_loss: 0.7556 - val_accuracy: 0.7548\n",
      "Epoch 84/100\n",
      "353/353 [==============================] - 21s 59ms/step - loss: 0.1598 - accuracy: 0.9389 - val_loss: 0.7529 - val_accuracy: 0.7444\n",
      "Epoch 85/100\n",
      "353/353 [==============================] - 20s 58ms/step - loss: 0.1573 - accuracy: 0.9413 - val_loss: 0.7596 - val_accuracy: 0.7492\n",
      "Epoch 86/100\n",
      "353/353 [==============================] - 21s 58ms/step - loss: 0.1523 - accuracy: 0.9449 - val_loss: 0.7791 - val_accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "353/353 [==============================] - 21s 58ms/step - loss: 0.1532 - accuracy: 0.9421 - val_loss: 0.7700 - val_accuracy: 0.7556\n",
      "Epoch 88/100\n",
      "353/353 [==============================] - 21s 59ms/step - loss: 0.1521 - accuracy: 0.9438 - val_loss: 0.7587 - val_accuracy: 0.7444\n",
      "Epoch 89/100\n",
      "353/353 [==============================] - 20s 56ms/step - loss: 0.1456 - accuracy: 0.9462 - val_loss: 0.7985 - val_accuracy: 0.7436\n",
      "Epoch 90/100\n",
      "353/353 [==============================] - 20s 56ms/step - loss: 0.1440 - accuracy: 0.9492 - val_loss: 0.7831 - val_accuracy: 0.7373\n",
      "Epoch 91/100\n",
      "353/353 [==============================] - 19s 55ms/step - loss: 0.1427 - accuracy: 0.9458 - val_loss: 0.8096 - val_accuracy: 0.7389\n",
      "Epoch 92/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.1417 - accuracy: 0.9482 - val_loss: 0.8147 - val_accuracy: 0.7476\n",
      "Epoch 93/100\n",
      "353/353 [==============================] - 19s 55ms/step - loss: 0.1407 - accuracy: 0.9476 - val_loss: 0.8164 - val_accuracy: 0.7444\n",
      "Epoch 94/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.1329 - accuracy: 0.9537 - val_loss: 0.8009 - val_accuracy: 0.7412\n",
      "Epoch 95/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.1392 - accuracy: 0.9483 - val_loss: 0.8016 - val_accuracy: 0.7492\n",
      "Epoch 96/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.1341 - accuracy: 0.9512 - val_loss: 0.8423 - val_accuracy: 0.7508\n",
      "Epoch 97/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.1328 - accuracy: 0.9515 - val_loss: 0.8257 - val_accuracy: 0.7619\n",
      "Epoch 98/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.1338 - accuracy: 0.9534 - val_loss: 0.8263 - val_accuracy: 0.7396\n",
      "Epoch 99/100\n",
      "353/353 [==============================] - 16s 44ms/step - loss: 0.1303 - accuracy: 0.9535 - val_loss: 0.8316 - val_accuracy: 0.7412\n",
      "Epoch 100/100\n",
      "353/353 [==============================] - 15s 43ms/step - loss: 0.1251 - accuracy: 0.9561 - val_loss: 0.8663 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have these from your Xception pipeline\n",
    "# train, train_labels, val, val_labels\n",
    "\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = resnet_model.fit(\n",
    "    train_ff, train_labels_ff,\n",
    "    validation_data=(val_ff, val_labels_ff),\n",
    "    epochs=100,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59aa49e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 6s 38ms/step - loss: 0.8502 - accuracy: 0.7620\n",
      "\n",
      "Test Accuracy of FF++ on ResNet50: 76.20%\n",
      "169/169 [==============================] - 6s 36ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.37      0.46      1468\n",
      "           1       0.79      0.91      0.85      3911\n",
      "\n",
      "    accuracy                           0.76      5379\n",
      "   macro avg       0.70      0.64      0.65      5379\n",
      "weighted avg       0.74      0.76      0.74      5379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = resnet_model.evaluate(test_ff, test_labels_ff)\n",
    "print(f'\\nTest Accuracy of FF++ on ResNet50: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = resnet_model.predict(test_ff)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels_ff, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d84a37fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# After training the model\n",
    "resnet_model.save('resnet(50)_160_ff.h5')  # Saves the entire model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "907ed965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 11.1%\n",
      "RAM Used: -564.3 MB\n",
      "Time Usage: 1863.4 s\n",
      "GPU Memory Used: 1863.2 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c667401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 7s 38ms/step - loss: 0.8502 - accuracy: 0.7620\n",
      "Test Accuracy of DFC on RESNET: 76.20%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('resnet(50)_160_ff.h5')\n",
    "test_loss, test_acc = model.evaluate(test_hog, test_labels)\n",
    "print(f'Test Accuracy of DFC on RESNET from FF++: {test_acc * 100:.2f}%')\n",
    "# You can now use the model for testing or inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8432dc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 5s 39ms/step - loss: 2.7653 - accuracy: 0.5313\n",
      "Test Accuracy of DFC on Resnet50 from FF++: 53.13%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('resnet(50)_160_ff.h5')\n",
    "test_loss, test_acc = model.evaluate(test_hog, test_labels)\n",
    "print(f'Test Accuracy of DFC on Resnet50 from FF++: {test_acc * 100:.2f}%')\n",
    "# You can now use the model for testing or inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1a79cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 23s 41ms/step - loss: 1.2038 - accuracy: 0.7033\n",
      "\n",
      "Test Accuracy of Celeb-df dataset on Inceptionnet for FF++: 70.33%\n",
      "340/340 [==============================] - 13s 37ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.10      0.15      2961\n",
      "           1       0.73      0.93      0.82      7891\n",
      "\n",
      "    accuracy                           0.70     10852\n",
      "   macro avg       0.54      0.51      0.49     10852\n",
      "weighted avg       0.63      0.70      0.64     10852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('resnet(50)_160_ff.h5')\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test, test_labels)\n",
    "print(f'\\nTest Accuracy of Celeb-df dataset on Inceptionnet for FF++: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, y_pred_binary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8d5556a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n",
      "169/169 [==============================] - 12s 41ms/step - loss: 0.8502 - accuracy: 0.7622\n",
      "\n",
      "Test Accuracy of Celeb-DF on ResNet50: 76.22%\n",
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 4.7%\n",
      "RAM Used: 4094.4 MB\n",
      "Time Usage: 17.6 s\n",
      "GPU Memory Used: 516.0 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor.get_stats()\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('resnet(50)_160_ff.h5')\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test_ff, test_labels_ff)\n",
    "print(f'\\nTest Accuracy of Celeb-DF on ResNet50: {test_acc*100:.2f}%')\n",
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
