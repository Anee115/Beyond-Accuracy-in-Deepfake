{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a643551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import psutil\n",
    "\n",
    "class PowerMonitor:\n",
    "    def __init__(self):\n",
    "        self.gpu_available = tf.config.list_physical_devices('GPU')\n",
    "        \n",
    "        # Hardware power specifications (adjust these values for your system)\n",
    "        self.cpu_tdp = 65    # Typical TDP for desktop CPUs in watts\n",
    "        self.gpu_tdp = 250   # Typical TDP for desktop GPUs in watts\n",
    "        \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get system stats with power estimation\"\"\"\n",
    "        stats = {\n",
    "            'timestamp': time.time(),\n",
    "            'cpu_%': psutil.cpu_percent(interval=0.1),\n",
    "            'ram_mb': psutil.virtual_memory().used / (1024**2),\n",
    "            'gpu_mem_mb': 0,\n",
    "            'power_w': self.cpu_tdp * (psutil.cpu_percent()/100) * 0.85  # Base CPU power\n",
    "        }\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            try:\n",
    "                # TensorFlow GPU memory monitoring\n",
    "                mem_info = tf.config.experimental.get_memory_info('GPU:0')\n",
    "                stats.update({\n",
    "                    'gpu_mem_mb': mem_info['current'] / (1024**2),\n",
    "                    'power_w': self.cpu_tdp * (psutil.cpu_percent()/100) * 0.85 + \n",
    "                              self.gpu_tdp * 0.5 * 0.75  # Add GPU power estimate\n",
    "                })\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        return stats\n",
    "\n",
    "# Initialize monitor\n",
    "monitor = PowerMonitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a293c1",
   "metadata": {},
   "source": [
    "# Celeb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63683390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9870, 160, 160, 3), (11274, 160, 160, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import h5py\n",
    "\n",
    "# Open the HDF5 file for reading\n",
    "#with h5py.File(\"D:\\\\thesis\\dataset\\deepfake dataset\\images_celeb_224R_processed.h5\", \"r\") as h5f:\n",
    "with h5py.File(\"D:\\\\thesis\\dataset\\Celeb-Df-v2\\images_celeb_balanced_224R_processed.h5\", \"r\") as h5f:\n",
    "    # Load HOG features\n",
    "    real_frames_array1 = h5f[\"ori_actor\"][:]\n",
    "    fake_frames_array1 = h5f[\"ori_youtube\"][:]\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Function to resize images from (224, 224) to (160, 160)\n",
    "def resize_images(image_array, target_size=(160, 160)):\n",
    "    resized_images = np.array([cv2.resize(img, target_size) for img in image_array])\n",
    "    return resized_images\n",
    "\n",
    "\n",
    "# Resize the images\n",
    "real_frames_array1 = resize_images(real_frames_array1, target_size=(160, 160))\n",
    "fake_frames_array1 = resize_images(fake_frames_array1, target_size=(160, 160))\n",
    "\n",
    "# Checking the new shapes\n",
    "real_frames_array1.shape, fake_frames_array1.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed4a7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data real shape: (6909, 160, 160, 3)\n",
      "Testing real data shape: (2961, 160, 160, 3)\n",
      "Training fake data shape: (7891, 160, 160, 3)\n",
      "Testing  fake data shape: (3383, 160, 160, 3)\n",
      "train_hog_real: 6218 images, val_hog_real: 691 images\n",
      "train_hog_fake: 7101 images, val_hog_fake: 790 images\n",
      "Total train: 13319 images\n",
      "Total test: 10852 images\n",
      "Total val: 1481 images\n",
      "Train Labels: 13319 \n",
      "Test Labels: 10852 \n",
      "Val Labels: 1481 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the data into train (70%) and test (30%)\n",
    "X_train_real, X_test_real = train_test_split(real_frames_array1, test_size=0.3, random_state=42)\n",
    "X_train_fake, X_test_fake = train_test_split(fake_frames_array1, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Output the shape to confirm the split dimensions\n",
    "print(\"Training data real shape:\", X_train_real.shape)\n",
    "print(\"Testing real data shape:\", X_test_real.shape)\n",
    "print(\"Training fake data shape:\", X_train_fake.shape)\n",
    "print(\"Testing  fake data shape:\", X_test_fake.shape)\n",
    "########################################################################################################################################\n",
    "#######################################divide into 60,10 train and val\n",
    "#########################################################################################################################################\n",
    "def extract_validation(train_data):\n",
    "    \"\"\"\n",
    "    Extract every 10th sample from the training data and store it in a validation set.\n",
    "\n",
    "    Parameters:\n",
    "        train_data (list or np.array): The training dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated training dataset and validation dataset.\n",
    "    \"\"\"\n",
    "    # Select every 10th sample for the validation set\n",
    "    validation_data = train_data[::10]\n",
    "\n",
    "    # Remove the selected samples from the training dataset\n",
    "    updated_train_data = [train_data[i] for i in range(len(train_data)) if i % 10 != 0]\n",
    "\n",
    "    return np.array(updated_train_data), np.array(validation_data)\n",
    "\n",
    "\n",
    "# Perform the operation for each dataset\n",
    "train_hog_real, val_hog_real = extract_validation(X_train_real)\n",
    "train_hog_fake, val_hog_fake = extract_validation(X_train_fake)\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"train_hog_real: {len(train_hog_real)} images, val_hog_real: {len(val_hog_real)} images\")\n",
    "print(f\"train_hog_fake: {len(train_hog_fake)} images, val_hog_fake: {len(val_hog_fake)} images\")\n",
    "\n",
    "\n",
    "############################################################################################################################################################\n",
    "#################################################concatenate the labels 0,1 real and fake\n",
    "#############################################################################################################################################################\n",
    "\n",
    "\n",
    "train_labels_real = np.zeros(len(train_hog_real), dtype=int)\n",
    "train_labels_fake = np.ones(len(train_hog_fake), dtype=int)\n",
    "\n",
    "# Concatenate all training datasets into a single `train` variable\n",
    "train = np.concatenate([train_hog_real, train_hog_fake], axis=0)\n",
    "train_labels=np.concatenate([train_labels_real, train_labels_fake], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "test_labels_real = np.zeros(len(X_test_real), dtype=int)\n",
    "test_labels_fake = np.ones(len(X_train_fake), dtype=int)\n",
    "\n",
    "# Concatenate all testing datasets into a single `test` variable\n",
    "test = np.concatenate([X_test_real, X_train_fake], axis=0)\n",
    "test_labels = np.concatenate([test_labels_real, test_labels_fake], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "val_labels_real = np.zeros(len(val_hog_real), dtype=int)\n",
    "val_labels_fake = np.ones(len(val_hog_fake), dtype=int)\n",
    "\n",
    "# Concatenate all validation datasets into a single `val` variable\n",
    "val = np.concatenate([val_hog_real, val_hog_fake], axis=0)\n",
    "val_labels = np.concatenate([val_labels_real, val_labels_fake], axis=0)\n",
    "\n",
    "# Print the results for verification\n",
    "print(f\"Total train: {len(train)} images\")\n",
    "print(f\"Total test: {len(test)} images\")\n",
    "print(f\"Total val: {len(val)} images\")\n",
    "\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"Train Labels: {len(train_labels)} \")\n",
    "print(f\"Test Labels: {len(test_labels)} \")\n",
    "print(f\"Val Labels: {len(val_labels)} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3add8a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d4cc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 160, 160, 3)]     0         \n",
      "                                                                 \n",
      " efficientnetb0 (Functional)  (None, 5, 5, 1280)       4049571   \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               163968    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,213,668\n",
      "Trainable params: 164,097\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, optimizers, callbacks\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "# Configuration\n",
    "INPUT_SHAPE = (160, 160, 3)\n",
    "NUM_CLASSES = 1  # Binary classification (real=0, fake=1)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "\n",
    "# Load pre-trained EfficientNetB0 (excluding top layers)\n",
    "base_model = EfficientNetB0(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=INPUT_SHAPE\n",
    ")\n",
    "\n",
    "# Freeze base model layers (optional)\n",
    "base_model.trainable = False\n",
    "\n",
    "# Custom Head for Deepfake Detection\n",
    "inputs = layers.Input(shape=INPUT_SHAPE)\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(NUM_CLASSES, activation='sigmoid')(x)\n",
    "\n",
    "# Compile model\n",
    "model = Model(inputs, outputs)\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "\n",
    "\n",
    "# Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e11dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "417/417 [==============================] - 19s 25ms/step - loss: 0.6680 - accuracy: 0.5911 - auc: 0.6220 - val_loss: 0.6398 - val_accuracy: 0.6448 - val_auc: 0.6973\n",
      "Epoch 2/100\n",
      "417/417 [==============================] - 9s 23ms/step - loss: 0.6246 - accuracy: 0.6552 - auc: 0.7098 - val_loss: 0.6132 - val_accuracy: 0.6718 - val_auc: 0.7307\n",
      "Epoch 3/100\n",
      "417/417 [==============================] - 9s 23ms/step - loss: 0.5977 - accuracy: 0.6840 - auc: 0.7477 - val_loss: 0.5971 - val_accuracy: 0.7002 - val_auc: 0.7538\n",
      "Epoch 4/100\n",
      "417/417 [==============================] - 9s 23ms/step - loss: 0.5750 - accuracy: 0.7079 - auc: 0.7760 - val_loss: 0.5833 - val_accuracy: 0.7056 - val_auc: 0.7743\n",
      "Epoch 5/100\n",
      "417/417 [==============================] - 9s 23ms/step - loss: 0.5598 - accuracy: 0.7185 - auc: 0.7916 - val_loss: 0.5633 - val_accuracy: 0.7218 - val_auc: 0.7863\n",
      "Epoch 6/100\n",
      "417/417 [==============================] - 9s 22ms/step - loss: 0.5414 - accuracy: 0.7354 - auc: 0.8100 - val_loss: 0.5589 - val_accuracy: 0.7218 - val_auc: 0.7947\n",
      "Epoch 7/100\n",
      "417/417 [==============================] - 9s 22ms/step - loss: 0.5274 - accuracy: 0.7466 - auc: 0.8235 - val_loss: 0.5424 - val_accuracy: 0.7319 - val_auc: 0.8080\n",
      "Epoch 8/100\n",
      "417/417 [==============================] - 9s 22ms/step - loss: 0.5138 - accuracy: 0.7564 - auc: 0.8336 - val_loss: 0.5333 - val_accuracy: 0.7333 - val_auc: 0.8177\n",
      "Epoch 9/100\n",
      "417/417 [==============================] - 9s 22ms/step - loss: 0.5022 - accuracy: 0.7664 - auc: 0.8431 - val_loss: 0.5243 - val_accuracy: 0.7421 - val_auc: 0.8228\n",
      "Epoch 10/100\n",
      "417/417 [==============================] - 9s 22ms/step - loss: 0.4903 - accuracy: 0.7691 - auc: 0.8526 - val_loss: 0.5192 - val_accuracy: 0.7427 - val_auc: 0.8299\n",
      "Epoch 11/100\n",
      "417/417 [==============================] - 9s 23ms/step - loss: 0.4781 - accuracy: 0.7818 - auc: 0.8616 - val_loss: 0.5132 - val_accuracy: 0.7576 - val_auc: 0.8344\n",
      "Epoch 12/100\n",
      "417/417 [==============================] - 9s 23ms/step - loss: 0.4650 - accuracy: 0.7888 - auc: 0.8704 - val_loss: 0.5021 - val_accuracy: 0.7596 - val_auc: 0.8379\n",
      "Epoch 13/100\n",
      "417/417 [==============================] - 9s 23ms/step - loss: 0.4569 - accuracy: 0.7965 - auc: 0.8760 - val_loss: 0.4935 - val_accuracy: 0.7630 - val_auc: 0.8429\n",
      "Epoch 14/100\n",
      "417/417 [==============================] - 9s 23ms/step - loss: 0.4465 - accuracy: 0.8023 - auc: 0.8824 - val_loss: 0.4880 - val_accuracy: 0.7731 - val_auc: 0.8496\n",
      "Epoch 15/100\n",
      "417/417 [==============================] - 9s 23ms/step - loss: 0.4380 - accuracy: 0.8103 - auc: 0.8885 - val_loss: 0.4808 - val_accuracy: 0.7677 - val_auc: 0.8518\n",
      "Epoch 16/100\n",
      "417/417 [==============================] - 9s 23ms/step - loss: 0.4282 - accuracy: 0.8159 - auc: 0.8935 - val_loss: 0.4753 - val_accuracy: 0.7745 - val_auc: 0.8537\n",
      "Epoch 17/100\n",
      "417/417 [==============================] - 9s 22ms/step - loss: 0.4189 - accuracy: 0.8166 - auc: 0.8992 - val_loss: 0.4671 - val_accuracy: 0.7893 - val_auc: 0.8598\n",
      "Epoch 18/100\n",
      "417/417 [==============================] - 9s 22ms/step - loss: 0.4115 - accuracy: 0.8240 - auc: 0.9034 - val_loss: 0.4644 - val_accuracy: 0.7873 - val_auc: 0.8641\n",
      "Epoch 19/100\n",
      "417/417 [==============================] - 9s 22ms/step - loss: 0.4036 - accuracy: 0.8281 - auc: 0.9072 - val_loss: 0.4583 - val_accuracy: 0.7866 - val_auc: 0.8654\n",
      "Epoch 20/100\n",
      "417/417 [==============================] - 9s 22ms/step - loss: 0.3955 - accuracy: 0.8336 - auc: 0.9119 - val_loss: 0.4571 - val_accuracy: 0.7839 - val_auc: 0.8664\n",
      "Epoch 21/100\n",
      "417/417 [==============================] - 9s 22ms/step - loss: 0.3859 - accuracy: 0.8378 - auc: 0.9175 - val_loss: 0.4456 - val_accuracy: 0.7947 - val_auc: 0.8731\n",
      "Epoch 22/100\n",
      "417/417 [==============================] - 9s 22ms/step - loss: 0.3784 - accuracy: 0.8426 - auc: 0.9200 - val_loss: 0.4463 - val_accuracy: 0.7893 - val_auc: 0.8776\n",
      "Epoch 23/100\n",
      "417/417 [==============================] - 9s 22ms/step - loss: 0.3747 - accuracy: 0.8441 - auc: 0.9217 - val_loss: 0.4383 - val_accuracy: 0.7961 - val_auc: 0.8805\n",
      "Epoch 24/100\n",
      "417/417 [==============================] - 9s 22ms/step - loss: 0.3654 - accuracy: 0.8498 - auc: 0.9261 - val_loss: 0.4344 - val_accuracy: 0.7968 - val_auc: 0.8839\n",
      "Epoch 25/100\n",
      "417/417 [==============================] - 9s 22ms/step - loss: 0.3624 - accuracy: 0.8509 - auc: 0.9275 - val_loss: 0.4312 - val_accuracy: 0.8055 - val_auc: 0.8835\n",
      "Epoch 26/100\n",
      "417/417 [==============================] - 9s 22ms/step - loss: 0.3509 - accuracy: 0.8561 - auc: 0.9335 - val_loss: 0.4258 - val_accuracy: 0.8076 - val_auc: 0.8855\n",
      "Epoch 27/100\n",
      "417/417 [==============================] - 9s 22ms/step - loss: 0.3501 - accuracy: 0.8577 - auc: 0.9323 - val_loss: 0.4221 - val_accuracy: 0.8096 - val_auc: 0.8894\n",
      "Epoch 28/100\n",
      "417/417 [==============================] - 11s 27ms/step - loss: 0.3413 - accuracy: 0.8625 - auc: 0.9367 - val_loss: 0.4167 - val_accuracy: 0.8130 - val_auc: 0.8908\n",
      "Epoch 29/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.3341 - accuracy: 0.8631 - auc: 0.9395 - val_loss: 0.4280 - val_accuracy: 0.8022 - val_auc: 0.8942\n",
      "Epoch 30/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.3290 - accuracy: 0.8668 - auc: 0.9418 - val_loss: 0.4100 - val_accuracy: 0.8197 - val_auc: 0.8942\n",
      "Epoch 31/100\n",
      "417/417 [==============================] - 13s 31ms/step - loss: 0.3266 - accuracy: 0.8709 - auc: 0.9423 - val_loss: 0.4077 - val_accuracy: 0.8190 - val_auc: 0.8975\n",
      "Epoch 32/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.3185 - accuracy: 0.8730 - auc: 0.9459 - val_loss: 0.4036 - val_accuracy: 0.8204 - val_auc: 0.8990\n",
      "Epoch 33/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.3091 - accuracy: 0.8792 - auc: 0.9499 - val_loss: 0.3998 - val_accuracy: 0.8278 - val_auc: 0.9009\n",
      "Epoch 34/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.3088 - accuracy: 0.8810 - auc: 0.9496 - val_loss: 0.3969 - val_accuracy: 0.8211 - val_auc: 0.9023\n",
      "Epoch 35/100\n",
      "417/417 [==============================] - 12s 29ms/step - loss: 0.3009 - accuracy: 0.8821 - auc: 0.9522 - val_loss: 0.3970 - val_accuracy: 0.8190 - val_auc: 0.9039\n",
      "Epoch 36/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.2976 - accuracy: 0.8853 - auc: 0.9534 - val_loss: 0.4045 - val_accuracy: 0.8103 - val_auc: 0.9058\n",
      "Epoch 37/100\n",
      "417/417 [==============================] - 13s 31ms/step - loss: 0.2898 - accuracy: 0.8875 - auc: 0.9567 - val_loss: 0.3978 - val_accuracy: 0.8184 - val_auc: 0.9049\n",
      "Epoch 38/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.2887 - accuracy: 0.8881 - auc: 0.9567 - val_loss: 0.3845 - val_accuracy: 0.8319 - val_auc: 0.9082\n",
      "Epoch 39/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.2799 - accuracy: 0.8928 - auc: 0.9599 - val_loss: 0.3833 - val_accuracy: 0.8305 - val_auc: 0.9106\n",
      "Epoch 40/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.2784 - accuracy: 0.8932 - auc: 0.9605 - val_loss: 0.3801 - val_accuracy: 0.8319 - val_auc: 0.9113\n",
      "Epoch 41/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.2721 - accuracy: 0.8949 - auc: 0.9621 - val_loss: 0.3763 - val_accuracy: 0.8366 - val_auc: 0.9132\n",
      "Epoch 42/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.2690 - accuracy: 0.8983 - auc: 0.9634 - val_loss: 0.3726 - val_accuracy: 0.8339 - val_auc: 0.9141\n",
      "Epoch 43/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.2646 - accuracy: 0.9014 - auc: 0.9642 - val_loss: 0.3743 - val_accuracy: 0.8346 - val_auc: 0.9143\n",
      "Epoch 44/100\n",
      "417/417 [==============================] - 13s 31ms/step - loss: 0.2570 - accuracy: 0.9023 - auc: 0.9672 - val_loss: 0.3733 - val_accuracy: 0.8447 - val_auc: 0.9135\n",
      "Epoch 45/100\n",
      "417/417 [==============================] - 13s 31ms/step - loss: 0.2544 - accuracy: 0.9043 - auc: 0.9680 - val_loss: 0.3707 - val_accuracy: 0.8359 - val_auc: 0.9161\n",
      "Epoch 46/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.2494 - accuracy: 0.9062 - auc: 0.9694 - val_loss: 0.3740 - val_accuracy: 0.8352 - val_auc: 0.9156\n",
      "Epoch 47/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.2441 - accuracy: 0.9095 - auc: 0.9704 - val_loss: 0.3926 - val_accuracy: 0.8211 - val_auc: 0.9192\n",
      "Epoch 48/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.2421 - accuracy: 0.9083 - auc: 0.9709 - val_loss: 0.3633 - val_accuracy: 0.8406 - val_auc: 0.9185\n",
      "Epoch 49/100\n",
      "417/417 [==============================] - 12s 29ms/step - loss: 0.2408 - accuracy: 0.9091 - auc: 0.9711 - val_loss: 0.3565 - val_accuracy: 0.8535 - val_auc: 0.9210\n",
      "Epoch 50/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.2333 - accuracy: 0.9140 - auc: 0.9732 - val_loss: 0.3704 - val_accuracy: 0.8319 - val_auc: 0.9231\n",
      "Epoch 51/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.2326 - accuracy: 0.9109 - auc: 0.9731 - val_loss: 0.3486 - val_accuracy: 0.8535 - val_auc: 0.9250\n",
      "Epoch 52/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.2293 - accuracy: 0.9141 - auc: 0.9741 - val_loss: 0.3546 - val_accuracy: 0.8447 - val_auc: 0.9246\n",
      "Epoch 53/100\n",
      "417/417 [==============================] - 12s 29ms/step - loss: 0.2222 - accuracy: 0.9196 - auc: 0.9764 - val_loss: 0.3508 - val_accuracy: 0.8535 - val_auc: 0.9244\n",
      "Epoch 54/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.2206 - accuracy: 0.9197 - auc: 0.9764 - val_loss: 0.3485 - val_accuracy: 0.8596 - val_auc: 0.9246\n",
      "Epoch 55/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.2156 - accuracy: 0.9206 - auc: 0.9779 - val_loss: 0.3640 - val_accuracy: 0.8379 - val_auc: 0.9224\n",
      "Epoch 56/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.2166 - accuracy: 0.9198 - auc: 0.9772 - val_loss: 0.3481 - val_accuracy: 0.8528 - val_auc: 0.9261\n",
      "Epoch 57/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.2120 - accuracy: 0.9229 - auc: 0.9783 - val_loss: 0.3574 - val_accuracy: 0.8474 - val_auc: 0.9272\n",
      "Epoch 58/100\n",
      "417/417 [==============================] - 12s 29ms/step - loss: 0.2061 - accuracy: 0.9279 - auc: 0.9801 - val_loss: 0.3527 - val_accuracy: 0.8433 - val_auc: 0.9272\n",
      "Epoch 59/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.2069 - accuracy: 0.9251 - auc: 0.9800 - val_loss: 0.3444 - val_accuracy: 0.8528 - val_auc: 0.9292\n",
      "Epoch 60/100\n",
      "417/417 [==============================] - 11s 28ms/step - loss: 0.2039 - accuracy: 0.9270 - auc: 0.9802 - val_loss: 0.3404 - val_accuracy: 0.8575 - val_auc: 0.9293\n",
      "Epoch 61/100\n",
      "417/417 [==============================] - 12s 28ms/step - loss: 0.1963 - accuracy: 0.9316 - auc: 0.9821 - val_loss: 0.3549 - val_accuracy: 0.8488 - val_auc: 0.9273\n",
      "Epoch 62/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1954 - accuracy: 0.9291 - auc: 0.9820 - val_loss: 0.3460 - val_accuracy: 0.8481 - val_auc: 0.9282\n",
      "Epoch 63/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1891 - accuracy: 0.9336 - auc: 0.9837 - val_loss: 0.3668 - val_accuracy: 0.8420 - val_auc: 0.9302\n",
      "Epoch 64/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1868 - accuracy: 0.9368 - auc: 0.9843 - val_loss: 0.3372 - val_accuracy: 0.8629 - val_auc: 0.9293\n",
      "Epoch 65/100\n",
      "417/417 [==============================] - 13s 31ms/step - loss: 0.1848 - accuracy: 0.9369 - auc: 0.9844 - val_loss: 0.3478 - val_accuracy: 0.8535 - val_auc: 0.9319\n",
      "Epoch 66/100\n",
      "417/417 [==============================] - 13s 31ms/step - loss: 0.1850 - accuracy: 0.9323 - auc: 0.9843 - val_loss: 0.3692 - val_accuracy: 0.8366 - val_auc: 0.9294\n",
      "Epoch 67/100\n",
      "417/417 [==============================] - 12s 29ms/step - loss: 0.1773 - accuracy: 0.9408 - auc: 0.9860 - val_loss: 0.3529 - val_accuracy: 0.8521 - val_auc: 0.9342\n",
      "Epoch 68/100\n",
      "417/417 [==============================] - 12s 29ms/step - loss: 0.1797 - accuracy: 0.9372 - auc: 0.9854 - val_loss: 0.3418 - val_accuracy: 0.8589 - val_auc: 0.9310\n",
      "Epoch 69/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.1756 - accuracy: 0.9395 - auc: 0.9863 - val_loss: 0.3351 - val_accuracy: 0.8629 - val_auc: 0.9328\n",
      "Epoch 70/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1709 - accuracy: 0.9438 - auc: 0.9868 - val_loss: 0.3442 - val_accuracy: 0.8575 - val_auc: 0.9336\n",
      "Epoch 71/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.1679 - accuracy: 0.9466 - auc: 0.9877 - val_loss: 0.3277 - val_accuracy: 0.8677 - val_auc: 0.9338\n",
      "Epoch 72/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.1639 - accuracy: 0.9450 - auc: 0.9883 - val_loss: 0.3414 - val_accuracy: 0.8575 - val_auc: 0.9351\n",
      "Epoch 73/100\n",
      "417/417 [==============================] - 12s 29ms/step - loss: 0.1644 - accuracy: 0.9457 - auc: 0.9879 - val_loss: 0.3337 - val_accuracy: 0.8596 - val_auc: 0.9339\n",
      "Epoch 74/100\n",
      "417/417 [==============================] - 12s 29ms/step - loss: 0.1610 - accuracy: 0.9452 - auc: 0.9888 - val_loss: 0.3290 - val_accuracy: 0.8697 - val_auc: 0.9335\n",
      "Epoch 75/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.1581 - accuracy: 0.9471 - auc: 0.9894 - val_loss: 0.3398 - val_accuracy: 0.8582 - val_auc: 0.9331\n",
      "Epoch 76/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1540 - accuracy: 0.9503 - auc: 0.9901 - val_loss: 0.3303 - val_accuracy: 0.8656 - val_auc: 0.9357\n",
      "Epoch 77/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.1527 - accuracy: 0.9501 - auc: 0.9899 - val_loss: 0.3542 - val_accuracy: 0.8494 - val_auc: 0.9349\n",
      "Epoch 78/100\n",
      "417/417 [==============================] - 12s 29ms/step - loss: 0.1544 - accuracy: 0.9477 - auc: 0.9895 - val_loss: 0.3220 - val_accuracy: 0.8683 - val_auc: 0.9358\n",
      "Epoch 79/100\n",
      "417/417 [==============================] - 12s 29ms/step - loss: 0.1479 - accuracy: 0.9509 - auc: 0.9909 - val_loss: 0.3326 - val_accuracy: 0.8683 - val_auc: 0.9352\n",
      "Epoch 80/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1497 - accuracy: 0.9511 - auc: 0.9900 - val_loss: 0.3286 - val_accuracy: 0.8690 - val_auc: 0.9374\n",
      "Epoch 81/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.1469 - accuracy: 0.9531 - auc: 0.9906 - val_loss: 0.3274 - val_accuracy: 0.8697 - val_auc: 0.9360\n",
      "Epoch 82/100\n",
      "417/417 [==============================] - 13s 31ms/step - loss: 0.1427 - accuracy: 0.9552 - auc: 0.9912 - val_loss: 0.3186 - val_accuracy: 0.8697 - val_auc: 0.9381\n",
      "Epoch 83/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.1401 - accuracy: 0.9554 - auc: 0.9921 - val_loss: 0.3307 - val_accuracy: 0.8690 - val_auc: 0.9380\n",
      "Epoch 84/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.1409 - accuracy: 0.9533 - auc: 0.9916 - val_loss: 0.3207 - val_accuracy: 0.8731 - val_auc: 0.9376\n",
      "Epoch 85/100\n",
      "417/417 [==============================] - 12s 29ms/step - loss: 0.1367 - accuracy: 0.9538 - auc: 0.9924 - val_loss: 0.3151 - val_accuracy: 0.8751 - val_auc: 0.9388\n",
      "Epoch 86/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1357 - accuracy: 0.9558 - auc: 0.9922 - val_loss: 0.3175 - val_accuracy: 0.8764 - val_auc: 0.9390\n",
      "Epoch 87/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1358 - accuracy: 0.9565 - auc: 0.9919 - val_loss: 0.3271 - val_accuracy: 0.8677 - val_auc: 0.9384\n",
      "Epoch 88/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1280 - accuracy: 0.9602 - auc: 0.9935 - val_loss: 0.3337 - val_accuracy: 0.8690 - val_auc: 0.9370\n",
      "Epoch 89/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.1268 - accuracy: 0.9593 - auc: 0.9939 - val_loss: 0.3175 - val_accuracy: 0.8798 - val_auc: 0.9389\n",
      "Epoch 90/100\n",
      "417/417 [==============================] - 9s 23ms/step - loss: 0.1272 - accuracy: 0.9582 - auc: 0.9933 - val_loss: 0.3227 - val_accuracy: 0.8758 - val_auc: 0.9382\n",
      "Epoch 91/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1269 - accuracy: 0.9604 - auc: 0.9932 - val_loss: 0.3145 - val_accuracy: 0.8758 - val_auc: 0.9399\n",
      "Epoch 92/100\n",
      "417/417 [==============================] - 12s 28ms/step - loss: 0.1244 - accuracy: 0.9631 - auc: 0.9935 - val_loss: 0.3176 - val_accuracy: 0.8758 - val_auc: 0.9401\n",
      "Epoch 93/100\n",
      "417/417 [==============================] - 12s 29ms/step - loss: 0.1216 - accuracy: 0.9642 - auc: 0.9940 - val_loss: 0.3269 - val_accuracy: 0.8717 - val_auc: 0.9368\n",
      "Epoch 94/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.1249 - accuracy: 0.9607 - auc: 0.9934 - val_loss: 0.3302 - val_accuracy: 0.8731 - val_auc: 0.9382\n",
      "Epoch 95/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1196 - accuracy: 0.9623 - auc: 0.9943 - val_loss: 0.3349 - val_accuracy: 0.8737 - val_auc: 0.9394\n",
      "Epoch 96/100\n",
      "417/417 [==============================] - 12s 29ms/step - loss: 0.1177 - accuracy: 0.9637 - auc: 0.9945 - val_loss: 0.3109 - val_accuracy: 0.8785 - val_auc: 0.9424\n",
      "Epoch 97/100\n",
      "417/417 [==============================] - 12s 29ms/step - loss: 0.1154 - accuracy: 0.9641 - auc: 0.9946 - val_loss: 0.3217 - val_accuracy: 0.8744 - val_auc: 0.9404\n",
      "Epoch 98/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1123 - accuracy: 0.9663 - auc: 0.9952 - val_loss: 0.3150 - val_accuracy: 0.8805 - val_auc: 0.9416\n",
      "Epoch 99/100\n",
      "417/417 [==============================] - 13s 31ms/step - loss: 0.1096 - accuracy: 0.9668 - auc: 0.9954 - val_loss: 0.3182 - val_accuracy: 0.8771 - val_auc: 0.9414\n",
      "Epoch 100/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1126 - accuracy: 0.9649 - auc: 0.9948 - val_loss: 0.3205 - val_accuracy: 0.8751 - val_auc: 0.9421\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history = model.fit(\n",
    "    train, train_labels,\n",
    "    validation_data=(val, val_labels),\n",
    "    epochs=100,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7417d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "417/417 [==============================] - 19s 27ms/step - loss: 0.6644 - accuracy: 0.5969 - auc: 0.6313 - val_loss: 0.6413 - val_accuracy: 0.6374 - val_auc: 0.6942\n",
      "Epoch 2/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.6240 - accuracy: 0.6615 - auc: 0.7107 - val_loss: 0.6119 - val_accuracy: 0.6637 - val_auc: 0.7299\n",
      "Epoch 3/100\n",
      "417/417 [==============================] - 12s 29ms/step - loss: 0.5963 - accuracy: 0.6811 - auc: 0.7493 - val_loss: 0.5929 - val_accuracy: 0.6887 - val_auc: 0.7561\n",
      "Epoch 4/100\n",
      "417/417 [==============================] - 14s 35ms/step - loss: 0.5722 - accuracy: 0.7069 - auc: 0.7782 - val_loss: 0.5737 - val_accuracy: 0.7056 - val_auc: 0.7754\n",
      "Epoch 5/100\n",
      "417/417 [==============================] - 10s 24ms/step - loss: 0.5529 - accuracy: 0.7247 - auc: 0.7975 - val_loss: 0.5593 - val_accuracy: 0.7164 - val_auc: 0.7906\n",
      "Epoch 6/100\n",
      "417/417 [==============================] - 12s 29ms/step - loss: 0.5374 - accuracy: 0.7367 - auc: 0.8134 - val_loss: 0.5538 - val_accuracy: 0.7225 - val_auc: 0.8019\n",
      "Epoch 7/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.5245 - accuracy: 0.7448 - auc: 0.8240 - val_loss: 0.5402 - val_accuracy: 0.7319 - val_auc: 0.8100\n",
      "Epoch 8/100\n",
      "417/417 [==============================] - 14s 35ms/step - loss: 0.5096 - accuracy: 0.7603 - auc: 0.8380 - val_loss: 0.5256 - val_accuracy: 0.7454 - val_auc: 0.8206\n",
      "Epoch 9/100\n",
      "417/417 [==============================] - 14s 35ms/step - loss: 0.4940 - accuracy: 0.7721 - auc: 0.8505 - val_loss: 0.5197 - val_accuracy: 0.7481 - val_auc: 0.8238\n",
      "Epoch 10/100\n",
      "417/417 [==============================] - 12s 29ms/step - loss: 0.4833 - accuracy: 0.7772 - auc: 0.8573 - val_loss: 0.5188 - val_accuracy: 0.7475 - val_auc: 0.8333\n",
      "Epoch 11/100\n",
      "417/417 [==============================] - 10s 24ms/step - loss: 0.4717 - accuracy: 0.7831 - auc: 0.8661 - val_loss: 0.5014 - val_accuracy: 0.7643 - val_auc: 0.8391\n",
      "Epoch 12/100\n",
      "417/417 [==============================] - 14s 35ms/step - loss: 0.4593 - accuracy: 0.7915 - auc: 0.8750 - val_loss: 0.4960 - val_accuracy: 0.7589 - val_auc: 0.8430\n",
      "Epoch 13/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.4504 - accuracy: 0.7996 - auc: 0.8812 - val_loss: 0.5019 - val_accuracy: 0.7583 - val_auc: 0.8500\n",
      "Epoch 14/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.4399 - accuracy: 0.8044 - auc: 0.8875 - val_loss: 0.4782 - val_accuracy: 0.7738 - val_auc: 0.8553\n",
      "Epoch 15/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.4328 - accuracy: 0.8089 - auc: 0.8908 - val_loss: 0.4738 - val_accuracy: 0.7765 - val_auc: 0.8587\n",
      "Epoch 16/100\n",
      "417/417 [==============================] - 15s 35ms/step - loss: 0.4225 - accuracy: 0.8136 - auc: 0.8971 - val_loss: 0.4669 - val_accuracy: 0.7806 - val_auc: 0.8626\n",
      "Epoch 17/100\n",
      "417/417 [==============================] - 15s 35ms/step - loss: 0.4137 - accuracy: 0.8211 - auc: 0.9022 - val_loss: 0.4631 - val_accuracy: 0.7839 - val_auc: 0.8645\n",
      "Epoch 18/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.4065 - accuracy: 0.8241 - auc: 0.9063 - val_loss: 0.4552 - val_accuracy: 0.7900 - val_auc: 0.8707\n",
      "Epoch 19/100\n",
      "417/417 [==============================] - 10s 24ms/step - loss: 0.3990 - accuracy: 0.8310 - auc: 0.9097 - val_loss: 0.4492 - val_accuracy: 0.7988 - val_auc: 0.8743\n",
      "Epoch 20/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.3924 - accuracy: 0.8357 - auc: 0.9131 - val_loss: 0.4448 - val_accuracy: 0.7873 - val_auc: 0.8753\n",
      "Epoch 21/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.3833 - accuracy: 0.8417 - auc: 0.9177 - val_loss: 0.4421 - val_accuracy: 0.7860 - val_auc: 0.8771\n",
      "Epoch 22/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.3765 - accuracy: 0.8419 - auc: 0.9211 - val_loss: 0.4349 - val_accuracy: 0.7968 - val_auc: 0.8810\n",
      "Epoch 23/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.3682 - accuracy: 0.8485 - auc: 0.9254 - val_loss: 0.4350 - val_accuracy: 0.8022 - val_auc: 0.8829\n",
      "Epoch 24/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.3647 - accuracy: 0.8486 - auc: 0.9264 - val_loss: 0.4288 - val_accuracy: 0.8042 - val_auc: 0.8855\n",
      "Epoch 25/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.3541 - accuracy: 0.8573 - auc: 0.9316 - val_loss: 0.4251 - val_accuracy: 0.8130 - val_auc: 0.8857\n",
      "Epoch 26/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.3476 - accuracy: 0.8594 - auc: 0.9342 - val_loss: 0.4215 - val_accuracy: 0.8109 - val_auc: 0.8908\n",
      "Epoch 27/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.3406 - accuracy: 0.8635 - auc: 0.9378 - val_loss: 0.4157 - val_accuracy: 0.8130 - val_auc: 0.8915\n",
      "Epoch 28/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.3360 - accuracy: 0.8648 - auc: 0.9395 - val_loss: 0.4127 - val_accuracy: 0.8163 - val_auc: 0.8949\n",
      "Epoch 29/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.3289 - accuracy: 0.8685 - auc: 0.9424 - val_loss: 0.4054 - val_accuracy: 0.8096 - val_auc: 0.8975\n",
      "Epoch 30/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.3211 - accuracy: 0.8740 - auc: 0.9459 - val_loss: 0.4076 - val_accuracy: 0.8123 - val_auc: 0.8955\n",
      "Epoch 31/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.3161 - accuracy: 0.8758 - auc: 0.9471 - val_loss: 0.4008 - val_accuracy: 0.8244 - val_auc: 0.9016\n",
      "Epoch 32/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.3081 - accuracy: 0.8804 - auc: 0.9506 - val_loss: 0.4008 - val_accuracy: 0.8136 - val_auc: 0.8999\n",
      "Epoch 33/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.3045 - accuracy: 0.8812 - auc: 0.9514 - val_loss: 0.3944 - val_accuracy: 0.8197 - val_auc: 0.9026\n",
      "Epoch 34/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.3026 - accuracy: 0.8796 - auc: 0.9518 - val_loss: 0.3911 - val_accuracy: 0.8251 - val_auc: 0.9048\n",
      "Epoch 35/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.2974 - accuracy: 0.8853 - auc: 0.9539 - val_loss: 0.3877 - val_accuracy: 0.8285 - val_auc: 0.9075\n",
      "Epoch 36/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.2915 - accuracy: 0.8861 - auc: 0.9561 - val_loss: 0.3872 - val_accuracy: 0.8312 - val_auc: 0.9091\n",
      "Epoch 37/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.2847 - accuracy: 0.8889 - auc: 0.9583 - val_loss: 0.3811 - val_accuracy: 0.8319 - val_auc: 0.9109\n",
      "Epoch 38/100\n",
      "417/417 [==============================] - 17s 41ms/step - loss: 0.2808 - accuracy: 0.8938 - auc: 0.9598 - val_loss: 0.3931 - val_accuracy: 0.8244 - val_auc: 0.9098\n",
      "Epoch 39/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.2777 - accuracy: 0.8927 - auc: 0.9605 - val_loss: 0.3796 - val_accuracy: 0.8366 - val_auc: 0.9145\n",
      "Epoch 40/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.2703 - accuracy: 0.8972 - auc: 0.9628 - val_loss: 0.3754 - val_accuracy: 0.8373 - val_auc: 0.9151\n",
      "Epoch 41/100\n",
      "417/417 [==============================] - 15s 35ms/step - loss: 0.2686 - accuracy: 0.8956 - auc: 0.9634 - val_loss: 0.3719 - val_accuracy: 0.8393 - val_auc: 0.9149\n",
      "Epoch 42/100\n",
      "417/417 [==============================] - 15s 35ms/step - loss: 0.2624 - accuracy: 0.8983 - auc: 0.9654 - val_loss: 0.3635 - val_accuracy: 0.8494 - val_auc: 0.9194\n",
      "Epoch 43/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.2548 - accuracy: 0.9052 - auc: 0.9680 - val_loss: 0.3646 - val_accuracy: 0.8400 - val_auc: 0.9180\n",
      "Epoch 44/100\n",
      "417/417 [==============================] - 15s 35ms/step - loss: 0.2559 - accuracy: 0.9054 - auc: 0.9673 - val_loss: 0.3643 - val_accuracy: 0.8413 - val_auc: 0.9185\n",
      "Epoch 45/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.2493 - accuracy: 0.9080 - auc: 0.9696 - val_loss: 0.3616 - val_accuracy: 0.8427 - val_auc: 0.9207\n",
      "Epoch 46/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.2448 - accuracy: 0.9080 - auc: 0.9703 - val_loss: 0.3607 - val_accuracy: 0.8386 - val_auc: 0.9209\n",
      "Epoch 47/100\n",
      "417/417 [==============================] - 15s 35ms/step - loss: 0.2394 - accuracy: 0.9123 - auc: 0.9716 - val_loss: 0.3706 - val_accuracy: 0.8393 - val_auc: 0.9230\n",
      "Epoch 48/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.2361 - accuracy: 0.9119 - auc: 0.9731 - val_loss: 0.3657 - val_accuracy: 0.8488 - val_auc: 0.9225\n",
      "Epoch 49/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.2338 - accuracy: 0.9146 - auc: 0.9735 - val_loss: 0.3541 - val_accuracy: 0.8535 - val_auc: 0.9249\n",
      "Epoch 50/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.2336 - accuracy: 0.9143 - auc: 0.9733 - val_loss: 0.3625 - val_accuracy: 0.8420 - val_auc: 0.9254\n",
      "Epoch 51/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.2280 - accuracy: 0.9176 - auc: 0.9747 - val_loss: 0.3555 - val_accuracy: 0.8481 - val_auc: 0.9261\n",
      "Epoch 52/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.2234 - accuracy: 0.9215 - auc: 0.9756 - val_loss: 0.3518 - val_accuracy: 0.8535 - val_auc: 0.9259\n",
      "Epoch 53/100\n",
      "417/417 [==============================] - 19s 46ms/step - loss: 0.2183 - accuracy: 0.9213 - auc: 0.9771 - val_loss: 0.3488 - val_accuracy: 0.8501 - val_auc: 0.9252\n",
      "Epoch 54/100\n",
      "417/417 [==============================] - 15s 35ms/step - loss: 0.2193 - accuracy: 0.9195 - auc: 0.9771 - val_loss: 0.3430 - val_accuracy: 0.8562 - val_auc: 0.9275\n",
      "Epoch 55/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.2121 - accuracy: 0.9229 - auc: 0.9785 - val_loss: 0.3415 - val_accuracy: 0.8609 - val_auc: 0.9282\n",
      "Epoch 56/100\n",
      "417/417 [==============================] - 15s 35ms/step - loss: 0.2076 - accuracy: 0.9271 - auc: 0.9800 - val_loss: 0.3460 - val_accuracy: 0.8535 - val_auc: 0.9290\n",
      "Epoch 57/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.2064 - accuracy: 0.9271 - auc: 0.9799 - val_loss: 0.3418 - val_accuracy: 0.8636 - val_auc: 0.9298\n",
      "Epoch 58/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.2028 - accuracy: 0.9293 - auc: 0.9806 - val_loss: 0.3422 - val_accuracy: 0.8643 - val_auc: 0.9295\n",
      "Epoch 59/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.1977 - accuracy: 0.9310 - auc: 0.9816 - val_loss: 0.3335 - val_accuracy: 0.8650 - val_auc: 0.9316\n",
      "Epoch 60/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.1954 - accuracy: 0.9315 - auc: 0.9821 - val_loss: 0.3331 - val_accuracy: 0.8663 - val_auc: 0.9332\n",
      "Epoch 61/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.1918 - accuracy: 0.9326 - auc: 0.9832 - val_loss: 0.3358 - val_accuracy: 0.8663 - val_auc: 0.9315\n",
      "Epoch 62/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1885 - accuracy: 0.9337 - auc: 0.9838 - val_loss: 0.3281 - val_accuracy: 0.8704 - val_auc: 0.9351\n",
      "Epoch 63/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1855 - accuracy: 0.9364 - auc: 0.9842 - val_loss: 0.3416 - val_accuracy: 0.8609 - val_auc: 0.9340\n",
      "Epoch 64/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1853 - accuracy: 0.9340 - auc: 0.9842 - val_loss: 0.3313 - val_accuracy: 0.8670 - val_auc: 0.9333\n",
      "Epoch 65/100\n",
      "417/417 [==============================] - 15s 35ms/step - loss: 0.1812 - accuracy: 0.9387 - auc: 0.9851 - val_loss: 0.3249 - val_accuracy: 0.8737 - val_auc: 0.9351\n",
      "Epoch 66/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1783 - accuracy: 0.9388 - auc: 0.9854 - val_loss: 0.3267 - val_accuracy: 0.8697 - val_auc: 0.9343\n",
      "Epoch 67/100\n",
      "417/417 [==============================] - 15s 35ms/step - loss: 0.1736 - accuracy: 0.9397 - auc: 0.9867 - val_loss: 0.3250 - val_accuracy: 0.8670 - val_auc: 0.9356\n",
      "Epoch 68/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.1753 - accuracy: 0.9406 - auc: 0.9858 - val_loss: 0.3223 - val_accuracy: 0.8731 - val_auc: 0.9381\n",
      "Epoch 69/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.1729 - accuracy: 0.9412 - auc: 0.9867 - val_loss: 0.3351 - val_accuracy: 0.8663 - val_auc: 0.9366\n",
      "Epoch 70/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.1689 - accuracy: 0.9426 - auc: 0.9872 - val_loss: 0.3212 - val_accuracy: 0.8758 - val_auc: 0.9368\n",
      "Epoch 71/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.1661 - accuracy: 0.9448 - auc: 0.9875 - val_loss: 0.3297 - val_accuracy: 0.8656 - val_auc: 0.9357\n",
      "Epoch 72/100\n",
      "417/417 [==============================] - 15s 35ms/step - loss: 0.1632 - accuracy: 0.9456 - auc: 0.9879 - val_loss: 0.3165 - val_accuracy: 0.8778 - val_auc: 0.9383\n",
      "Epoch 73/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.1598 - accuracy: 0.9495 - auc: 0.9887 - val_loss: 0.3160 - val_accuracy: 0.8785 - val_auc: 0.9386\n",
      "Epoch 74/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1580 - accuracy: 0.9484 - auc: 0.9892 - val_loss: 0.3295 - val_accuracy: 0.8690 - val_auc: 0.9382\n",
      "Epoch 75/100\n",
      "417/417 [==============================] - 15s 35ms/step - loss: 0.1583 - accuracy: 0.9470 - auc: 0.9890 - val_loss: 0.3149 - val_accuracy: 0.8731 - val_auc: 0.9393\n",
      "Epoch 76/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.1569 - accuracy: 0.9484 - auc: 0.9890 - val_loss: 0.3171 - val_accuracy: 0.8744 - val_auc: 0.9393\n",
      "Epoch 77/100\n",
      "417/417 [==============================] - 11s 26ms/step - loss: 0.1529 - accuracy: 0.9503 - auc: 0.9898 - val_loss: 0.3396 - val_accuracy: 0.8623 - val_auc: 0.9387\n",
      "Epoch 78/100\n",
      "417/417 [==============================] - 15s 35ms/step - loss: 0.1498 - accuracy: 0.9489 - auc: 0.9903 - val_loss: 0.3341 - val_accuracy: 0.8724 - val_auc: 0.9387\n",
      "Epoch 79/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.1493 - accuracy: 0.9485 - auc: 0.9900 - val_loss: 0.3149 - val_accuracy: 0.8764 - val_auc: 0.9410\n",
      "Epoch 80/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.1449 - accuracy: 0.9516 - auc: 0.9908 - val_loss: 0.3299 - val_accuracy: 0.8758 - val_auc: 0.9413\n",
      "Epoch 81/100\n",
      "417/417 [==============================] - 15s 35ms/step - loss: 0.1419 - accuracy: 0.9537 - auc: 0.9913 - val_loss: 0.3127 - val_accuracy: 0.8825 - val_auc: 0.9404\n",
      "Epoch 82/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1408 - accuracy: 0.9549 - auc: 0.9915 - val_loss: 0.3153 - val_accuracy: 0.8764 - val_auc: 0.9398\n",
      "Epoch 83/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1395 - accuracy: 0.9545 - auc: 0.9914 - val_loss: 0.3122 - val_accuracy: 0.8758 - val_auc: 0.9405\n",
      "Epoch 84/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.1350 - accuracy: 0.9573 - auc: 0.9926 - val_loss: 0.3091 - val_accuracy: 0.8798 - val_auc: 0.9420\n",
      "Epoch 85/100\n",
      "417/417 [==============================] - 13s 30ms/step - loss: 0.1341 - accuracy: 0.9582 - auc: 0.9924 - val_loss: 0.3154 - val_accuracy: 0.8764 - val_auc: 0.9431\n",
      "Epoch 86/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.1326 - accuracy: 0.9584 - auc: 0.9927 - val_loss: 0.3116 - val_accuracy: 0.8812 - val_auc: 0.9414\n",
      "Epoch 87/100\n",
      "417/417 [==============================] - 13s 31ms/step - loss: 0.1293 - accuracy: 0.9589 - auc: 0.9932 - val_loss: 0.3146 - val_accuracy: 0.8791 - val_auc: 0.9406\n",
      "Epoch 88/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.1307 - accuracy: 0.9582 - auc: 0.9927 - val_loss: 0.3171 - val_accuracy: 0.8764 - val_auc: 0.9421\n",
      "Epoch 89/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.1264 - accuracy: 0.9598 - auc: 0.9937 - val_loss: 0.3126 - val_accuracy: 0.8845 - val_auc: 0.9437\n",
      "Epoch 90/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.1242 - accuracy: 0.9600 - auc: 0.9938 - val_loss: 0.3050 - val_accuracy: 0.8805 - val_auc: 0.9436\n",
      "Epoch 91/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.1242 - accuracy: 0.9619 - auc: 0.9938 - val_loss: 0.3129 - val_accuracy: 0.8832 - val_auc: 0.9439\n",
      "Epoch 92/100\n",
      "417/417 [==============================] - 12s 30ms/step - loss: 0.1194 - accuracy: 0.9640 - auc: 0.9944 - val_loss: 0.3102 - val_accuracy: 0.8845 - val_auc: 0.9432\n",
      "Epoch 93/100\n",
      "417/417 [==============================] - 10s 25ms/step - loss: 0.1190 - accuracy: 0.9636 - auc: 0.9940 - val_loss: 0.3132 - val_accuracy: 0.8832 - val_auc: 0.9454\n",
      "Epoch 94/100\n",
      "417/417 [==============================] - 11s 27ms/step - loss: 0.1173 - accuracy: 0.9644 - auc: 0.9944 - val_loss: 0.3177 - val_accuracy: 0.8812 - val_auc: 0.9445\n",
      "Epoch 95/100\n",
      "417/417 [==============================] - 39s 94ms/step - loss: 0.1187 - accuracy: 0.9619 - auc: 0.9943 - val_loss: 0.3116 - val_accuracy: 0.8832 - val_auc: 0.9441\n",
      "Epoch 96/100\n",
      "417/417 [==============================] - 9s 23ms/step - loss: 0.1152 - accuracy: 0.9652 - auc: 0.9946 - val_loss: 0.3165 - val_accuracy: 0.8825 - val_auc: 0.9450\n",
      "Epoch 97/100\n",
      "417/417 [==============================] - 9s 23ms/step - loss: 0.1140 - accuracy: 0.9661 - auc: 0.9951 - val_loss: 0.3116 - val_accuracy: 0.8893 - val_auc: 0.9434\n",
      "Epoch 98/100\n",
      "417/417 [==============================] - 9s 23ms/step - loss: 0.1137 - accuracy: 0.9670 - auc: 0.9947 - val_loss: 0.3036 - val_accuracy: 0.8886 - val_auc: 0.9443\n",
      "Epoch 99/100\n",
      "417/417 [==============================] - 10s 23ms/step - loss: 0.1134 - accuracy: 0.9646 - auc: 0.9947 - val_loss: 0.3082 - val_accuracy: 0.8845 - val_auc: 0.9452\n",
      "Epoch 100/100\n",
      "417/417 [==============================] - 10s 23ms/step - loss: 0.1083 - accuracy: 0.9652 - auc: 0.9954 - val_loss: 0.3025 - val_accuracy: 0.8879 - val_auc: 0.9445\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history = model.fit(\n",
    "    train, train_labels,\n",
    "    validation_data=(val, val_labels),\n",
    "    epochs=100,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be6944e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 7s 20ms/step - loss: 0.1632 - accuracy: 0.9443 - auc: 0.9749\n",
      "\n",
      "Test Accuracy of Celeb-DF on EfficientNetB0: 94.43%\n",
      "340/340 [==============================] - 7s 18ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.82      0.89      2961\n",
      "           1       0.94      0.99      0.96      7891\n",
      "\n",
      "    accuracy                           0.94     10852\n",
      "   macro avg       0.95      0.91      0.93     10852\n",
      "weighted avg       0.95      0.94      0.94     10852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_auc = model.evaluate(test, test_labels)\n",
    "print(f'\\nTest Accuracy of Celeb-DF on EfficientNetB0: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3466dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save just the weights (no architecture)\n",
    "model.save_weights('EfficientNetB0_160_celeb_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7862e8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 5.0%\n",
      "RAM Used: 3683.4 MB\n",
      "Time Usage: 1405.1 s\n",
      "GPU Memory Used: 1898.0 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e249861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 7s 20ms/step - loss: 0.1642 - accuracy: 0.9497 - auc: 0.9751\n",
      "\n",
      "Test Accuracy of Celeb-DF on EfficientNetB0: 94.97%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_auc = model.evaluate(test, test_labels)\n",
    "print(f'\\nTest Accuracy of Celeb-DF on EfficientNetB0: {test_acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25a4c294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n",
      "340/340 [==============================] - 7s 21ms/step - loss: 0.1642 - accuracy: 0.9497 - auc: 0.9751\n",
      "\n",
      "Test Accuracy of Celeb-DF on EfficientNetB0: 94.97%\n",
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 7.6%\n",
      "RAM Used: 762.9 MB\n",
      "Time Usage: 9.6 s\n",
      "GPU Memory Used: 1608.8 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor.get_stats()\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_auc = model.evaluate(test, test_labels)\n",
    "print(f'\\nTest Accuracy of Celeb-DF on EfficientNetB0: {test_acc*100:.2f}%')\n",
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47cc1c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 2s 21ms/step - loss: 3.1522 - accuracy: 0.4763 - auc: 0.4978\n",
      "\n",
      "Test Accuracy of DFC on EfficientNetB0 from Celebdf: 47.63%\n",
      "94/94 [==============================] - 2s 18ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.76      0.59      1500\n",
      "           1       0.45      0.19      0.27      1500\n",
      "\n",
      "    accuracy                           0.48      3000\n",
      "   macro avg       0.47      0.48      0.43      3000\n",
      "weighted avg       0.47      0.48      0.43      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_auc = model.evaluate(test_hog, test_labels)\n",
    "print(f'\\nTest Accuracy of DFC on EfficientNetB0 from Celebdf: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test_hog)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae35d848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 3s 20ms/step - loss: 2.2587 - accuracy: 0.4713 - auc: 0.5263\n",
      "\n",
      "Test Accuracy of FF++ on EfficientNetB0 from Celebdf: 47.13%\n",
      "169/169 [==============================] - 3s 19ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.63      0.39      1468\n",
      "           1       0.75      0.41      0.53      3911\n",
      "\n",
      "    accuracy                           0.47      5379\n",
      "   macro avg       0.52      0.52      0.46      5379\n",
      "weighted avg       0.62      0.47      0.49      5379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_auc = model.evaluate(test_ff, test_labels_ff)\n",
    "print(f'\\nTest Accuracy of FF++ on EfficientNetB0 from Celebdf: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test_ff)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels_ff, y_pred_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203cc889",
   "metadata": {},
   "source": [
    "#only for inteference time for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a768d8ae",
   "metadata": {},
   "source": [
    "# DFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5493048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celeb shape: (5000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (5000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "celeb shape: (2500, 160, 160, 3), dtype: uint8\n",
      "ffhq shape: (2500, 160, 160, 3), dtype: uint8\n",
      "gdwct shape: (1000, 160, 160, 3), dtype: uint8\n",
      "attagan shape: (1000, 160, 160, 3), dtype: uint8\n",
      "stargan shape: (1000, 160, 160, 3), dtype: uint8\n",
      "stylegan2 shape: (1000, 160, 160, 3), dtype: uint8\n",
      "stylegan shape: (1000, 160, 160, 3), dtype: uint8\n",
      "celeb_train: 1750 images, celeb_test: 750 images\n",
      "ffhq_train: 1750 images, ffhq_test: 750 images\n",
      "attgan_train: 700 images, attgan_test: 300 images\n",
      "stargan_train: 700 images, stargan_test: 300 images\n",
      "gdwct_train: 700 images, gdwct_test: 300 images\n",
      "stylegan2_train: 700 images, stylegan2_test: 300 images\n",
      "stylegan_train: 700 images, stylegan_test: 300 images\n",
      "celeb_train: 1575 images, celeb_val: 175 images\n",
      "ffhq_train: 1575 images, ffhq_val: 175 images\n",
      "attgan_train: 630 images, attgan_val: 70 images\n",
      "stargan_train: 630 images, stargan_val: 70 images\n",
      "gdwct_train: 630 images, gdwct_val: 70 images\n",
      "stylegan2_train: 630 images, stylegan2_val: 70 images\n",
      "stylegan_train: 630 images, stylegan_val: 70 images\n",
      "Total train: 6300 images\n",
      "Total test: 3000 images\n",
      "Total val: 700 images\n",
      "Train Labels: 6300 \n",
      "Test Labels: 3000 \n",
      "Val Labels: 700 \n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "# Open the HDF5 file in read mode\n",
    "with h5py.File('D://thesis//dataset//deepfake dataset//resized_images.h5', 'r') as h5f:\n",
    "    # Access each dataset\n",
    "    celeb = np.array(h5f['celeb'])\n",
    "    ffhq = np.array(h5f['ffhq'])\n",
    "    gdwct = np.array(h5f['gdwct'])\n",
    "    attgan = np.array(h5f['attgan'])\n",
    "    stargan = np.array(h5f['stargan'])\n",
    "    stylegan2 = np.array(h5f['stylegan2'])\n",
    "    stylegan = np.array(h5f['stylegan'])\n",
    "\n",
    "# Now, 'celeb', 'ffhq', etc., are NumPy arrays containing your datasets\n",
    "print(f\"celeb shape: {celeb.shape}, dtype: {celeb.dtype}\")\n",
    "print(f\"ffhq shape: {ffhq.shape}, dtype: {ffhq.dtype}\")\n",
    "print(f\"ffhq shape: {gdwct.shape}, dtype: {gdwct.dtype}\")\n",
    "print(f\"ffhq shape: {attgan.shape}, dtype: {attgan.dtype}\")\n",
    "print(f\"ffhq shape: {stargan.shape}, dtype: {stargan.dtype}\")\n",
    "print(f\"ffhq shape: {stylegan2.shape}, dtype: {stylegan2.dtype}\")\n",
    "print(f\"ffhq shape: {stylegan.shape}, dtype: {stylegan.dtype}\")\n",
    "# Repeat for other datasets as needed\n",
    "import cv2\n",
    "# Function to resize images from (224, 224) to (160, 160)\n",
    "def resize_images(image_array, target_size=(160, 160)):\n",
    "    resized_images = np.array([cv2.resize(img, target_size) for img in image_array])\n",
    "    return resized_images\n",
    "\n",
    "celeb = resize_images(celeb, target_size=(160, 160))\n",
    "ffhq = resize_images(ffhq, target_size=(160, 160))\n",
    "gdwct = resize_images(gdwct, target_size=(160, 160))\n",
    "attgan = resize_images(attgan, target_size=(160, 160))\n",
    "stargan = resize_images(stargan, target_size=(160, 160))\n",
    "stylegan = resize_images(stargan, target_size=(160, 160))\n",
    "stylegan2 = resize_images(stylegan2, target_size=(160, 160))\n",
    "import random\n",
    "# Randomly select 2500 distinct images\n",
    "random_indices = random.sample(range(len(celeb)), 2500)  # Get 2500 random indices\n",
    "celeb = celeb[random_indices]  # Select the random subse\n",
    "\n",
    "import random\n",
    "# Randomly select 2500 distinct images\n",
    "random_indices = random.sample(range(len(ffhq)), 2500)  # Get 2500 random indices\n",
    "ffhq = ffhq[random_indices]  # Select the random subse\n",
    "print(f\"celeb shape: {celeb.shape}, dtype: {celeb.dtype}\")\n",
    "print(f\"ffhq shape: {ffhq.shape}, dtype: {ffhq.dtype}\")\n",
    "print(f\"gdwct shape: {gdwct.shape}, dtype: {gdwct.dtype}\")\n",
    "print(f\"attagan shape: {attgan.shape}, dtype: {attgan.dtype}\")\n",
    "print(f\"stargan shape: {stargan.shape}, dtype: {stargan.dtype}\")\n",
    "print(f\"stylegan2 shape: {stylegan2.shape}, dtype: {stylegan2.dtype}\")\n",
    "print(f\"stylegan shape: {stylegan.shape}, dtype: {stylegan.dtype}\")\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def split_data(data, train_ratio=0.7):\n",
    "    \"\"\"\n",
    "    Splits data into training and testing sets based on the specified ratio.\n",
    "\n",
    "    Parameters:\n",
    "        data (list or np.array): The dataset to split.\n",
    "        train_ratio (float): The ratio of the data to include in the training set.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two datasets - train and test.\n",
    "    \"\"\"\n",
    "    # Shuffle the data\n",
    "    random.shuffle(data)\n",
    "\n",
    "    # Calculate the split index\n",
    "    split_index = int(len(data) * train_ratio)\n",
    "\n",
    "    # Split the data\n",
    "    train_data = data[:split_index]\n",
    "    test_data = data[split_index:]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "# Split `celeb` into 70% train and 30% test\n",
    "celeb_train_hog, celeb_test_hog = split_data(celeb, train_ratio=0.7)\n",
    "\n",
    "# Split `ffhq` into 70% train and 30% test\n",
    "ffhq_train_hog, ffhq_test_hog = split_data(ffhq, train_ratio=0.7)\n",
    "\n",
    "# Split `attgan` into 70% train and 30% test\n",
    "attgan_train_hog, attgan_test_hog = split_data(attgan, train_ratio=0.7)\n",
    "\n",
    "# Split `stargan` into 70% train and 30% test\n",
    "stargan_train_hog, stargan_test_hog = split_data(stargan, train_ratio=0.7)\n",
    "\n",
    "# Split `gdwct` into 70% train and 30% test\n",
    "gdwct_train_hog, gdwct_test_hog = split_data(gdwct, train_ratio=0.7)\n",
    "\n",
    "# Split `stylegan2` into 70% train and 30% test_hog\n",
    "stylegan2_train_hog, stylegan2_test_hog = split_data(stylegan2, train_ratio=0.7)\n",
    "\n",
    "# Split `stylegan` into 70% train and 30% test_hog\n",
    "stylegan_train_hog, stylegan_test_hog = split_data(stylegan, train_ratio=0.7)\n",
    "\n",
    "# Convert to NumPy arrays if needed\n",
    "celeb_train_hog, celeb_test_hog = np.array(celeb_train_hog), np.array(celeb_test_hog)\n",
    "ffhq_train_hog, ffhq_test_hog = np.array(ffhq_train_hog), np.array(ffhq_test_hog)\n",
    "attgan_train_hog, attgan_test_hog = np.array(attgan_train_hog), np.array(attgan_test_hog)\n",
    "stargan_train_hog, stargan_test_hog = np.array(stargan_train_hog), np.array(stargan_test_hog)\n",
    "gdwct_train_hog, gdwct_test_hog = np.array(gdwct_train_hog), np.array(gdwct_test_hog)\n",
    "stylegan2_train_hog, stylegan2_test_hog = np.array(stylegan2_train_hog), np.array(stylegan2_test_hog)\n",
    "stylegan_train_hog, stylegan_test_hog = np.array(stylegan_train_hog), np.array(stylegan_test_hog)\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"celeb_train: {len(celeb_train_hog)} images, celeb_test: {len(celeb_test_hog)} images\")\n",
    "print(f\"ffhq_train: {len(ffhq_train_hog)} images, ffhq_test: {len(ffhq_test_hog)} images\")\n",
    "print(f\"attgan_train: {len(attgan_train_hog)} images, attgan_test: {len(attgan_test_hog)} images\")\n",
    "print(f\"stargan_train: {len(stargan_train_hog)} images, stargan_test: {len(stargan_test_hog)} images\")\n",
    "print(f\"gdwct_train: {len(gdwct_train_hog)} images, gdwct_test: {len(gdwct_test_hog)} images\")\n",
    "print(f\"stylegan2_train: {len(stylegan2_train_hog)} images, stylegan2_test: {len(stylegan2_test_hog)} images\")\n",
    "print(f\"stylegan_train: {len(stylegan_train_hog)} images, stylegan_test: {len(stylegan_test_hog)} images\")\n",
    "\n",
    "########################################################################################################################################\n",
    "#######################################divide into 60,10 train and val\n",
    "#########################################################################################################################################\n",
    "def extract_validation(train_data):\n",
    "    \"\"\"\n",
    "    Extract every 10th sample from the training data and store it in a validation set.\n",
    "\n",
    "    Parameters:\n",
    "        train_data (list or np.array): The training dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated training dataset and validation dataset.\n",
    "    \"\"\"\n",
    "    # Select every 10th sample for the validation set\n",
    "    validation_data = train_data[::10]\n",
    "\n",
    "    # Remove the selected samples from the training dataset\n",
    "    updated_train_data = [train_data[i] for i in range(len(train_data)) if i % 10 != 0]\n",
    "\n",
    "    return np.array(updated_train_data), np.array(validation_data)\n",
    "\n",
    "\n",
    "# Perform the operation for each dataset\n",
    "celeb_train_hog, celeb_val_hog = extract_validation(celeb_train_hog)\n",
    "ffhq_train_hog, ffhq_val_hog = extract_validation(ffhq_train_hog)\n",
    "attgan_train_hog, attgan_val_hog = extract_validation(attgan_train_hog)\n",
    "stargan_train_hog, stargan_val_hog = extract_validation(stargan_train_hog)\n",
    "gdwct_train_hog, gdwct_val_hog = extract_validation(gdwct_train_hog)\n",
    "stylegan2_train_hog, stylegan2_val_hog = extract_validation(stylegan2_train_hog)\n",
    "stylegan_train_hog, stylegan_val_hog = extract_validation(stylegan_train_hog)\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"celeb_train: {len(celeb_train_hog)} images, celeb_val: {len(celeb_val_hog)} images\")\n",
    "print(f\"ffhq_train: {len(ffhq_train_hog)} images, ffhq_val: {len(ffhq_val_hog)} images\")\n",
    "print(f\"attgan_train: {len(attgan_train_hog)} images, attgan_val: {len(attgan_val_hog)} images\")\n",
    "print(f\"stargan_train: {len(stargan_train_hog)} images, stargan_val: {len(stargan_val_hog)} images\")\n",
    "print(f\"gdwct_train: {len(gdwct_train_hog)} images, gdwct_val: {len(gdwct_val_hog)} images\")\n",
    "print(f\"stylegan2_train: {len(stylegan2_train_hog)} images, stylegan2_val: {len(stylegan2_val_hog)} images\")\n",
    "print(f\"stylegan_train: {len(stylegan_train_hog)} images, stylegan_val: {len(stylegan_val_hog)} images\")\n",
    "############################################################################################################################################################\n",
    "#################################################concatenate the labels 0,1 real and fake\n",
    "#############################################################################################################################################################\n",
    "\n",
    "\n",
    "celeb_train_labels = np.zeros(len(celeb_train_hog), dtype=int)\n",
    "ffhq_train_labels = np.zeros(len(ffhq_train_hog), dtype=int)\n",
    "atta_train_labels = np.ones(len(attgan_train_hog), dtype=int)\n",
    "star_train_labels = np.ones(len(stargan_train_hog), dtype=int)\n",
    "gdwct_train_labels = np.ones(len(gdwct_train_hog), dtype=int)\n",
    "stylegan2_train_labels = np.ones(len(stylegan2_train_hog), dtype=int)\n",
    "stylegan_train_labels = np.ones(len(stylegan_train_hog), dtype=int)\n",
    "\n",
    "# Concatenate all training datasets into a single `train` variable\n",
    "train_hog = np.concatenate([celeb_train_hog, ffhq_train_hog, attgan_train_hog, stargan_train_hog, gdwct_train_hog, stylegan2_train_hog, stylegan_train_hog], axis=0)\n",
    "train_labels=np.concatenate([celeb_train_labels, ffhq_train_labels, atta_train_labels, star_train_labels, gdwct_train_labels, stylegan2_train_labels,\n",
    "                              stylegan_train_labels], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "celeb_test_labels = np.zeros(len(celeb_test_hog), dtype=int)\n",
    "ffhq_test_labels = np.zeros(len(ffhq_test_hog), dtype=int)\n",
    "atta_test_labels = np.ones(len(attgan_test_hog), dtype=int)\n",
    "star_test_labels = np.ones(len(stargan_test_hog), dtype=int)\n",
    "gdwct_test_labels = np.ones(len(gdwct_test_hog), dtype=int)\n",
    "stylegan2_test_labels = np.ones(len(stylegan2_test_hog), dtype=int)\n",
    "stylegan_test_labels = np.ones(len(stylegan_test_hog), dtype=int)\n",
    "\n",
    "# Concatenate all testing datasets into a single `test` variable\n",
    "test_hog = np.concatenate([celeb_test_hog, ffhq_test_hog, attgan_test_hog, stargan_test_hog, gdwct_test_hog, stylegan2_test_hog, stylegan_test_hog], axis=0)\n",
    "test_labels = np.concatenate([celeb_test_labels, ffhq_test_labels, atta_test_labels, star_test_labels, gdwct_test_labels, stylegan2_test_labels,\n",
    "                        stylegan_test_labels], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "celeb_val_labels = np.zeros(len(celeb_val_hog), dtype=int)\n",
    "ffhq_val_labels = np.zeros(len(ffhq_val_hog), dtype=int)\n",
    "atta_val_labels = np.ones(len(attgan_val_hog), dtype=int)\n",
    "star_val_labels = np.ones(len(stargan_val_hog), dtype=int)\n",
    "gdwct_val_labels = np.ones(len(gdwct_val_hog), dtype=int)\n",
    "stylegan2_val_labels = np.ones(len(stylegan2_val_hog), dtype=int)\n",
    "stylegan_val_labels = np.ones(len(stylegan_val_hog), dtype=int)\n",
    "\n",
    "# Concatenate all validation datasets into a single `val` variable\n",
    "val_hog = np.concatenate([celeb_val_hog, ffhq_val_hog, attgan_val_hog, stargan_val_hog, gdwct_val_hog, stylegan2_val_hog, stylegan_val_hog], axis=0)\n",
    "val_labels = np.concatenate([celeb_val_labels, ffhq_val_labels, atta_val_labels, star_val_labels, gdwct_val_labels, stylegan2_val_labels,\n",
    "                       stylegan_val_labels], axis=0)\n",
    "\n",
    "# Print the results for verification\n",
    "print(f\"Total train: {len(train_hog)} images\")\n",
    "print(f\"Total test: {len(test_hog)} images\")\n",
    "print(f\"Total val: {len(val_hog)} images\")\n",
    "\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"Train Labels: {len(train_labels)} \")\n",
    "print(f\"Test Labels: {len(test_labels)} \")\n",
    "print(f\"Val Labels: {len(val_labels)} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c9a640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "197/197 [==============================] - 14s 29ms/step - loss: 0.5318 - accuracy: 0.7435 - auc: 0.8293 - val_loss: 0.4253 - val_accuracy: 0.8229 - val_auc: 0.9073\n",
      "Epoch 2/100\n",
      "197/197 [==============================] - 6s 33ms/step - loss: 0.3792 - accuracy: 0.8497 - auc: 0.9266 - val_loss: 0.3376 - val_accuracy: 0.8671 - val_auc: 0.9444\n",
      "Epoch 3/100\n",
      "197/197 [==============================] - 11s 56ms/step - loss: 0.3137 - accuracy: 0.8762 - auc: 0.9504 - val_loss: 0.2911 - val_accuracy: 0.8900 - val_auc: 0.9580\n",
      "Epoch 4/100\n",
      "197/197 [==============================] - 11s 54ms/step - loss: 0.2736 - accuracy: 0.8994 - auc: 0.9632 - val_loss: 0.2589 - val_accuracy: 0.9057 - val_auc: 0.9658\n",
      "Epoch 5/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.2441 - accuracy: 0.9113 - auc: 0.9707 - val_loss: 0.2466 - val_accuracy: 0.9043 - val_auc: 0.9703\n",
      "Epoch 6/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.2171 - accuracy: 0.9252 - auc: 0.9779 - val_loss: 0.2224 - val_accuracy: 0.9186 - val_auc: 0.9741\n",
      "Epoch 7/100\n",
      "197/197 [==============================] - 11s 54ms/step - loss: 0.1986 - accuracy: 0.9343 - auc: 0.9817 - val_loss: 0.2088 - val_accuracy: 0.9171 - val_auc: 0.9774\n",
      "Epoch 8/100\n",
      "197/197 [==============================] - 6s 31ms/step - loss: 0.1792 - accuracy: 0.9402 - auc: 0.9858 - val_loss: 0.1929 - val_accuracy: 0.9271 - val_auc: 0.9811\n",
      "Epoch 9/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.1641 - accuracy: 0.9470 - auc: 0.9886 - val_loss: 0.1882 - val_accuracy: 0.9286 - val_auc: 0.9813\n",
      "Epoch 10/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.1530 - accuracy: 0.9519 - auc: 0.9897 - val_loss: 0.1785 - val_accuracy: 0.9329 - val_auc: 0.9846\n",
      "Epoch 11/100\n",
      "197/197 [==============================] - 7s 34ms/step - loss: 0.1432 - accuracy: 0.9556 - auc: 0.9910 - val_loss: 0.1651 - val_accuracy: 0.9429 - val_auc: 0.9858\n",
      "Epoch 12/100\n",
      "197/197 [==============================] - 10s 51ms/step - loss: 0.1330 - accuracy: 0.9584 - auc: 0.9927 - val_loss: 0.1563 - val_accuracy: 0.9443 - val_auc: 0.9876\n",
      "Epoch 13/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.1234 - accuracy: 0.9629 - auc: 0.9941 - val_loss: 0.1479 - val_accuracy: 0.9500 - val_auc: 0.9891\n",
      "Epoch 14/100\n",
      "197/197 [==============================] - 12s 59ms/step - loss: 0.1142 - accuracy: 0.9657 - auc: 0.9952 - val_loss: 0.1413 - val_accuracy: 0.9514 - val_auc: 0.9894\n",
      "Epoch 15/100\n",
      "197/197 [==============================] - 12s 61ms/step - loss: 0.1068 - accuracy: 0.9681 - auc: 0.9957 - val_loss: 0.1393 - val_accuracy: 0.9514 - val_auc: 0.9902\n",
      "Epoch 16/100\n",
      "197/197 [==============================] - 12s 62ms/step - loss: 0.0984 - accuracy: 0.9721 - auc: 0.9966 - val_loss: 0.1327 - val_accuracy: 0.9543 - val_auc: 0.9907\n",
      "Epoch 17/100\n",
      "197/197 [==============================] - 12s 60ms/step - loss: 0.0935 - accuracy: 0.9732 - auc: 0.9968 - val_loss: 0.1268 - val_accuracy: 0.9529 - val_auc: 0.9911\n",
      "Epoch 18/100\n",
      "197/197 [==============================] - 10s 53ms/step - loss: 0.0884 - accuracy: 0.9759 - auc: 0.9973 - val_loss: 0.1224 - val_accuracy: 0.9571 - val_auc: 0.9918\n",
      "Epoch 19/100\n",
      "197/197 [==============================] - 11s 57ms/step - loss: 0.0844 - accuracy: 0.9781 - auc: 0.9976 - val_loss: 0.1196 - val_accuracy: 0.9557 - val_auc: 0.9926\n",
      "Epoch 20/100\n",
      "197/197 [==============================] - 11s 54ms/step - loss: 0.0759 - accuracy: 0.9827 - auc: 0.9983 - val_loss: 0.1138 - val_accuracy: 0.9600 - val_auc: 0.9924\n",
      "Epoch 21/100\n",
      "197/197 [==============================] - 10s 51ms/step - loss: 0.0728 - accuracy: 0.9824 - auc: 0.9984 - val_loss: 0.1169 - val_accuracy: 0.9586 - val_auc: 0.9935\n",
      "Epoch 22/100\n",
      "197/197 [==============================] - 9s 48ms/step - loss: 0.0665 - accuracy: 0.9843 - auc: 0.9988 - val_loss: 0.1096 - val_accuracy: 0.9586 - val_auc: 0.9931\n",
      "Epoch 23/100\n",
      "197/197 [==============================] - 8s 42ms/step - loss: 0.0630 - accuracy: 0.9860 - auc: 0.9990 - val_loss: 0.1065 - val_accuracy: 0.9600 - val_auc: 0.9931\n",
      "Epoch 24/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0598 - accuracy: 0.9870 - auc: 0.9989 - val_loss: 0.1024 - val_accuracy: 0.9614 - val_auc: 0.9937\n",
      "Epoch 25/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0567 - accuracy: 0.9862 - auc: 0.9991 - val_loss: 0.1012 - val_accuracy: 0.9657 - val_auc: 0.9935\n",
      "Epoch 26/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0522 - accuracy: 0.9892 - auc: 0.9993 - val_loss: 0.0979 - val_accuracy: 0.9700 - val_auc: 0.9939\n",
      "Epoch 27/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0505 - accuracy: 0.9894 - auc: 0.9993 - val_loss: 0.0959 - val_accuracy: 0.9671 - val_auc: 0.9942\n",
      "Epoch 28/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0476 - accuracy: 0.9914 - auc: 0.9994 - val_loss: 0.0979 - val_accuracy: 0.9700 - val_auc: 0.9940\n",
      "Epoch 29/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0452 - accuracy: 0.9925 - auc: 0.9994 - val_loss: 0.0928 - val_accuracy: 0.9729 - val_auc: 0.9941\n",
      "Epoch 30/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0410 - accuracy: 0.9929 - auc: 0.9995 - val_loss: 0.0948 - val_accuracy: 0.9714 - val_auc: 0.9941\n",
      "Epoch 31/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0401 - accuracy: 0.9932 - auc: 0.9995 - val_loss: 0.0921 - val_accuracy: 0.9686 - val_auc: 0.9945\n",
      "Epoch 32/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0387 - accuracy: 0.9929 - auc: 0.9995 - val_loss: 0.0926 - val_accuracy: 0.9700 - val_auc: 0.9945\n",
      "Epoch 33/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0348 - accuracy: 0.9952 - auc: 0.9996 - val_loss: 0.0884 - val_accuracy: 0.9686 - val_auc: 0.9946\n",
      "Epoch 34/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0349 - accuracy: 0.9933 - auc: 0.9996 - val_loss: 0.0895 - val_accuracy: 0.9743 - val_auc: 0.9936\n",
      "Epoch 35/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0317 - accuracy: 0.9951 - auc: 0.9998 - val_loss: 0.0881 - val_accuracy: 0.9700 - val_auc: 0.9939\n",
      "Epoch 36/100\n",
      "197/197 [==============================] - 10s 50ms/step - loss: 0.0286 - accuracy: 0.9962 - auc: 0.9998 - val_loss: 0.0893 - val_accuracy: 0.9714 - val_auc: 0.9919\n",
      "Epoch 37/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0262 - accuracy: 0.9962 - auc: 0.9998 - val_loss: 0.0887 - val_accuracy: 0.9743 - val_auc: 0.9931\n",
      "Epoch 38/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0263 - accuracy: 0.9963 - auc: 0.9999 - val_loss: 0.0897 - val_accuracy: 0.9743 - val_auc: 0.9920\n",
      "Epoch 39/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0235 - accuracy: 0.9978 - auc: 0.9999 - val_loss: 0.0875 - val_accuracy: 0.9743 - val_auc: 0.9928\n",
      "Epoch 40/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0227 - accuracy: 0.9973 - auc: 0.9999 - val_loss: 0.0845 - val_accuracy: 0.9771 - val_auc: 0.9923\n",
      "Epoch 41/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0230 - accuracy: 0.9971 - auc: 0.9999 - val_loss: 0.0861 - val_accuracy: 0.9786 - val_auc: 0.9923\n",
      "Epoch 42/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0221 - accuracy: 0.9968 - auc: 0.9999 - val_loss: 0.0884 - val_accuracy: 0.9729 - val_auc: 0.9922\n",
      "Epoch 43/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0193 - accuracy: 0.9978 - auc: 0.9999 - val_loss: 0.0873 - val_accuracy: 0.9714 - val_auc: 0.9925\n",
      "Epoch 44/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0175 - accuracy: 0.9992 - auc: 0.9999 - val_loss: 0.0850 - val_accuracy: 0.9729 - val_auc: 0.9924\n",
      "Epoch 45/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0183 - accuracy: 0.9979 - auc: 0.9999 - val_loss: 0.0845 - val_accuracy: 0.9771 - val_auc: 0.9925\n",
      "Epoch 46/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0167 - accuracy: 0.9989 - auc: 0.9999 - val_loss: 0.0900 - val_accuracy: 0.9757 - val_auc: 0.9923\n",
      "Epoch 47/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0161 - accuracy: 0.9983 - auc: 0.9999 - val_loss: 0.0833 - val_accuracy: 0.9743 - val_auc: 0.9926\n",
      "Epoch 48/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0148 - accuracy: 0.9986 - auc: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9757 - val_auc: 0.9926\n",
      "Epoch 49/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0156 - accuracy: 0.9984 - auc: 0.9999 - val_loss: 0.0845 - val_accuracy: 0.9771 - val_auc: 0.9930\n",
      "Epoch 50/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0140 - accuracy: 0.9986 - auc: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9757 - val_auc: 0.9927\n",
      "Epoch 51/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0125 - accuracy: 0.9992 - auc: 0.9999 - val_loss: 0.0866 - val_accuracy: 0.9771 - val_auc: 0.9929\n",
      "Epoch 52/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0120 - accuracy: 0.9989 - auc: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9743 - val_auc: 0.9925\n",
      "Epoch 53/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0117 - accuracy: 0.9987 - auc: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9757 - val_auc: 0.9930\n",
      "Epoch 54/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0113 - accuracy: 0.9990 - auc: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9757 - val_auc: 0.9929\n",
      "Epoch 55/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0104 - accuracy: 0.9995 - auc: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9729 - val_auc: 0.9930\n",
      "Epoch 56/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0104 - accuracy: 0.9990 - auc: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9757 - val_auc: 0.9931\n",
      "Epoch 57/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0099 - accuracy: 0.9987 - auc: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9771 - val_auc: 0.9933\n",
      "Epoch 58/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0083 - accuracy: 0.9995 - auc: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9743 - val_auc: 0.9932\n",
      "Epoch 59/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0086 - accuracy: 0.9990 - auc: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9743 - val_auc: 0.9929\n",
      "Epoch 60/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0083 - accuracy: 0.9992 - auc: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9771 - val_auc: 0.9934\n",
      "Epoch 61/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0080 - accuracy: 0.9994 - auc: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9786 - val_auc: 0.9933\n",
      "Epoch 62/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0071 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9757 - val_auc: 0.9933\n",
      "Epoch 63/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0070 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9786 - val_auc: 0.9932\n",
      "Epoch 64/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0066 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9757 - val_auc: 0.9934\n",
      "Epoch 65/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0068 - accuracy: 0.9994 - auc: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9757 - val_auc: 0.9938\n",
      "Epoch 66/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0059 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9757 - val_auc: 0.9934\n",
      "Epoch 67/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0053 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9757 - val_auc: 0.9935\n",
      "Epoch 68/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0057 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9771 - val_auc: 0.9922\n",
      "Epoch 69/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0060 - accuracy: 0.9994 - auc: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9757 - val_auc: 0.9936\n",
      "Epoch 70/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0045 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.0990 - val_accuracy: 0.9771 - val_auc: 0.9934\n",
      "Epoch 71/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0050 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9786 - val_auc: 0.9934\n",
      "Epoch 72/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0043 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9771 - val_auc: 0.9936\n",
      "Epoch 73/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0040 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9743 - val_auc: 0.9935\n",
      "Epoch 74/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0041 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9729 - val_auc: 0.9934\n",
      "Epoch 75/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0033 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9729 - val_auc: 0.9935\n",
      "Epoch 76/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0034 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9729 - val_auc: 0.9936\n",
      "Epoch 77/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0032 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9743 - val_auc: 0.9898\n",
      "Epoch 78/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0029 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9771 - val_auc: 0.9934\n",
      "Epoch 79/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0033 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9786 - val_auc: 0.9926\n",
      "Epoch 80/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0031 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9771 - val_auc: 0.9938\n",
      "Epoch 81/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0028 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9757 - val_auc: 0.9911\n",
      "Epoch 82/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0028 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9771 - val_auc: 0.9899\n",
      "Epoch 83/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0026 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1076 - val_accuracy: 0.9771 - val_auc: 0.9899\n",
      "Epoch 84/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9771 - val_auc: 0.9898\n",
      "Epoch 85/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0026 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9800 - val_auc: 0.9899\n",
      "Epoch 86/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0023 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9757 - val_auc: 0.9900\n",
      "Epoch 87/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0020 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1106 - val_accuracy: 0.9757 - val_auc: 0.9912\n",
      "Epoch 88/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9786 - val_auc: 0.9911\n",
      "Epoch 89/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1159 - val_accuracy: 0.9771 - val_auc: 0.9887\n",
      "Epoch 90/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0019 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1173 - val_accuracy: 0.9743 - val_auc: 0.9885\n",
      "Epoch 91/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0019 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1126 - val_accuracy: 0.9757 - val_auc: 0.9925\n",
      "Epoch 92/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1161 - val_accuracy: 0.9771 - val_auc: 0.9887\n",
      "Epoch 93/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0020 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9786 - val_auc: 0.9885\n",
      "Epoch 94/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0018 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9771 - val_auc: 0.9913\n",
      "Epoch 95/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9786 - val_auc: 0.9913\n",
      "Epoch 96/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1192 - val_accuracy: 0.9771 - val_auc: 0.9900\n",
      "Epoch 97/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9786 - val_auc: 0.9899\n",
      "Epoch 98/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0026 - accuracy: 0.9995 - auc: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9786 - val_auc: 0.9925\n",
      "Epoch 99/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1208 - val_accuracy: 0.9771 - val_auc: 0.9912\n",
      "Epoch 100/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0012 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1200 - val_accuracy: 0.9771 - val_auc: 0.9913\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_hog, train_labels,\n",
    "    validation_data=(val_hog, val_labels),\n",
    "    epochs=100,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "070ae418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "197/197 [==============================] - 11s 29ms/step - loss: 0.5291 - accuracy: 0.7517 - auc: 0.8301 - val_loss: 0.4329 - val_accuracy: 0.8043 - val_auc: 0.9054\n",
      "Epoch 2/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.3856 - accuracy: 0.8430 - auc: 0.9207 - val_loss: 0.3494 - val_accuracy: 0.8643 - val_auc: 0.9386\n",
      "Epoch 3/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.3227 - accuracy: 0.8783 - auc: 0.9463 - val_loss: 0.3024 - val_accuracy: 0.8857 - val_auc: 0.9537\n",
      "Epoch 4/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.2808 - accuracy: 0.8987 - auc: 0.9598 - val_loss: 0.2721 - val_accuracy: 0.9057 - val_auc: 0.9618\n",
      "Epoch 5/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.2489 - accuracy: 0.9143 - auc: 0.9689 - val_loss: 0.2499 - val_accuracy: 0.9086 - val_auc: 0.9668\n",
      "Epoch 6/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.2245 - accuracy: 0.9238 - auc: 0.9751 - val_loss: 0.2330 - val_accuracy: 0.9200 - val_auc: 0.9713\n",
      "Epoch 7/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.2055 - accuracy: 0.9341 - auc: 0.9794 - val_loss: 0.2186 - val_accuracy: 0.9257 - val_auc: 0.9736\n",
      "Epoch 8/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.1860 - accuracy: 0.9417 - auc: 0.9838 - val_loss: 0.2045 - val_accuracy: 0.9314 - val_auc: 0.9767\n",
      "Epoch 9/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.1694 - accuracy: 0.9492 - auc: 0.9865 - val_loss: 0.1948 - val_accuracy: 0.9357 - val_auc: 0.9790\n",
      "Epoch 10/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.1603 - accuracy: 0.9522 - auc: 0.9877 - val_loss: 0.1847 - val_accuracy: 0.9429 - val_auc: 0.9804\n",
      "Epoch 11/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.1479 - accuracy: 0.9559 - auc: 0.9899 - val_loss: 0.1783 - val_accuracy: 0.9371 - val_auc: 0.9815\n",
      "Epoch 12/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.1349 - accuracy: 0.9617 - auc: 0.9917 - val_loss: 0.1706 - val_accuracy: 0.9443 - val_auc: 0.9831\n",
      "Epoch 13/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.1285 - accuracy: 0.9630 - auc: 0.9928 - val_loss: 0.1597 - val_accuracy: 0.9471 - val_auc: 0.9849\n",
      "Epoch 14/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.1182 - accuracy: 0.9665 - auc: 0.9940 - val_loss: 0.1571 - val_accuracy: 0.9457 - val_auc: 0.9849\n",
      "Epoch 15/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.1108 - accuracy: 0.9690 - auc: 0.9947 - val_loss: 0.1512 - val_accuracy: 0.9543 - val_auc: 0.9857\n",
      "Epoch 16/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.1041 - accuracy: 0.9722 - auc: 0.9955 - val_loss: 0.1452 - val_accuracy: 0.9500 - val_auc: 0.9868\n",
      "Epoch 17/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0989 - accuracy: 0.9741 - auc: 0.9957 - val_loss: 0.1394 - val_accuracy: 0.9529 - val_auc: 0.9878\n",
      "Epoch 18/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0908 - accuracy: 0.9778 - auc: 0.9965 - val_loss: 0.1340 - val_accuracy: 0.9557 - val_auc: 0.9884\n",
      "Epoch 19/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0862 - accuracy: 0.9779 - auc: 0.9970 - val_loss: 0.1292 - val_accuracy: 0.9600 - val_auc: 0.9884\n",
      "Epoch 20/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0827 - accuracy: 0.9773 - auc: 0.9974 - val_loss: 0.1282 - val_accuracy: 0.9557 - val_auc: 0.9885\n",
      "Epoch 21/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0774 - accuracy: 0.9810 - auc: 0.9976 - val_loss: 0.1245 - val_accuracy: 0.9600 - val_auc: 0.9891\n",
      "Epoch 22/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0735 - accuracy: 0.9829 - auc: 0.9979 - val_loss: 0.1206 - val_accuracy: 0.9571 - val_auc: 0.9892\n",
      "Epoch 23/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0682 - accuracy: 0.9827 - auc: 0.9981 - val_loss: 0.1160 - val_accuracy: 0.9614 - val_auc: 0.9896\n",
      "Epoch 24/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0635 - accuracy: 0.9852 - auc: 0.9987 - val_loss: 0.1139 - val_accuracy: 0.9629 - val_auc: 0.9900\n",
      "Epoch 25/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0592 - accuracy: 0.9856 - auc: 0.9989 - val_loss: 0.1115 - val_accuracy: 0.9629 - val_auc: 0.9903\n",
      "Epoch 26/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0581 - accuracy: 0.9863 - auc: 0.9988 - val_loss: 0.1110 - val_accuracy: 0.9629 - val_auc: 0.9899\n",
      "Epoch 27/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0530 - accuracy: 0.9887 - auc: 0.9991 - val_loss: 0.1126 - val_accuracy: 0.9657 - val_auc: 0.9901\n",
      "Epoch 28/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0509 - accuracy: 0.9890 - auc: 0.9993 - val_loss: 0.1094 - val_accuracy: 0.9657 - val_auc: 0.9900\n",
      "Epoch 29/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0487 - accuracy: 0.9900 - auc: 0.9991 - val_loss: 0.1055 - val_accuracy: 0.9686 - val_auc: 0.9904\n",
      "Epoch 30/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0454 - accuracy: 0.9908 - auc: 0.9994 - val_loss: 0.1037 - val_accuracy: 0.9629 - val_auc: 0.9907\n",
      "Epoch 31/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0430 - accuracy: 0.9919 - auc: 0.9995 - val_loss: 0.1017 - val_accuracy: 0.9700 - val_auc: 0.9907\n",
      "Epoch 32/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0407 - accuracy: 0.9919 - auc: 0.9995 - val_loss: 0.1032 - val_accuracy: 0.9700 - val_auc: 0.9911\n",
      "Epoch 33/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0376 - accuracy: 0.9925 - auc: 0.9997 - val_loss: 0.0990 - val_accuracy: 0.9686 - val_auc: 0.9911\n",
      "Epoch 34/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0363 - accuracy: 0.9933 - auc: 0.9996 - val_loss: 0.0990 - val_accuracy: 0.9700 - val_auc: 0.9906\n",
      "Epoch 35/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0337 - accuracy: 0.9941 - auc: 0.9999 - val_loss: 0.0969 - val_accuracy: 0.9729 - val_auc: 0.9903\n",
      "Epoch 36/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0318 - accuracy: 0.9946 - auc: 0.9998 - val_loss: 0.1002 - val_accuracy: 0.9729 - val_auc: 0.9905\n",
      "Epoch 37/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0311 - accuracy: 0.9940 - auc: 0.9998 - val_loss: 0.0963 - val_accuracy: 0.9743 - val_auc: 0.9906\n",
      "Epoch 38/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0293 - accuracy: 0.9952 - auc: 0.9998 - val_loss: 0.1021 - val_accuracy: 0.9714 - val_auc: 0.9905\n",
      "Epoch 39/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0277 - accuracy: 0.9965 - auc: 0.9998 - val_loss: 0.0974 - val_accuracy: 0.9743 - val_auc: 0.9906\n",
      "Epoch 40/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0251 - accuracy: 0.9967 - auc: 0.9999 - val_loss: 0.0967 - val_accuracy: 0.9757 - val_auc: 0.9907\n",
      "Epoch 41/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0253 - accuracy: 0.9956 - auc: 0.9999 - val_loss: 0.0958 - val_accuracy: 0.9757 - val_auc: 0.9909\n",
      "Epoch 42/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0221 - accuracy: 0.9976 - auc: 0.9999 - val_loss: 0.0967 - val_accuracy: 0.9729 - val_auc: 0.9913\n",
      "Epoch 43/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0220 - accuracy: 0.9967 - auc: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9743 - val_auc: 0.9912\n",
      "Epoch 44/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0218 - accuracy: 0.9962 - auc: 0.9999 - val_loss: 0.0944 - val_accuracy: 0.9729 - val_auc: 0.9905\n",
      "Epoch 45/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0200 - accuracy: 0.9973 - auc: 1.0000 - val_loss: 0.0926 - val_accuracy: 0.9757 - val_auc: 0.9915\n",
      "Epoch 46/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0196 - accuracy: 0.9973 - auc: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9757 - val_auc: 0.9915\n",
      "Epoch 47/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0176 - accuracy: 0.9975 - auc: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9743 - val_auc: 0.9904\n",
      "Epoch 48/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0163 - accuracy: 0.9976 - auc: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9757 - val_auc: 0.9906\n",
      "Epoch 49/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0163 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9757 - val_auc: 0.9905\n",
      "Epoch 50/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0157 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9729 - val_auc: 0.9905\n",
      "Epoch 51/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0142 - accuracy: 0.9986 - auc: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9743 - val_auc: 0.9908\n",
      "Epoch 52/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0129 - accuracy: 0.9992 - auc: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9743 - val_auc: 0.9910\n",
      "Epoch 53/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0125 - accuracy: 0.9989 - auc: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9743 - val_auc: 0.9912\n",
      "Epoch 54/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0120 - accuracy: 0.9990 - auc: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9757 - val_auc: 0.9898\n",
      "Epoch 55/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0118 - accuracy: 0.9989 - auc: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9743 - val_auc: 0.9911\n",
      "Epoch 56/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0110 - accuracy: 0.9987 - auc: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9757 - val_auc: 0.9913\n",
      "Epoch 57/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0109 - accuracy: 0.9990 - auc: 1.0000 - val_loss: 0.0985 - val_accuracy: 0.9757 - val_auc: 0.9912\n",
      "Epoch 58/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0096 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9743 - val_auc: 0.9912\n",
      "Epoch 59/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0089 - accuracy: 0.9992 - auc: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9729 - val_auc: 0.9914\n",
      "Epoch 60/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0082 - accuracy: 0.9995 - auc: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9729 - val_auc: 0.9913\n",
      "Epoch 61/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0080 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9729 - val_auc: 0.9913\n",
      "Epoch 62/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0083 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9743 - val_auc: 0.9901\n",
      "Epoch 63/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0073 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9743 - val_auc: 0.9903\n",
      "Epoch 64/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0072 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9743 - val_auc: 0.9904\n",
      "Epoch 65/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0067 - accuracy: 0.9995 - auc: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9729 - val_auc: 0.9917\n",
      "Epoch 66/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0063 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9757 - val_auc: 0.9906\n",
      "Epoch 67/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0059 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9729 - val_auc: 0.9906\n",
      "Epoch 68/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0059 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9729 - val_auc: 0.9919\n",
      "Epoch 69/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0054 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9714 - val_auc: 0.9907\n",
      "Epoch 70/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0057 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9743 - val_auc: 0.9907\n",
      "Epoch 71/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0049 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1123 - val_accuracy: 0.9729 - val_auc: 0.9908\n",
      "Epoch 72/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0060 - accuracy: 0.9992 - auc: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9743 - val_auc: 0.9907\n",
      "Epoch 73/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0044 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1092 - val_accuracy: 0.9729 - val_auc: 0.9908\n",
      "Epoch 74/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0043 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1109 - val_accuracy: 0.9729 - val_auc: 0.9909\n",
      "Epoch 75/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0045 - accuracy: 0.9997 - auc: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9729 - val_auc: 0.9910\n",
      "Epoch 76/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0038 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9743 - val_auc: 0.9909\n",
      "Epoch 77/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0039 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9743 - val_auc: 0.9909\n",
      "Epoch 78/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0036 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1126 - val_accuracy: 0.9729 - val_auc: 0.9910\n",
      "Epoch 79/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0036 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9729 - val_auc: 0.9910\n",
      "Epoch 80/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0040 - accuracy: 0.9994 - auc: 1.0000 - val_loss: 0.1123 - val_accuracy: 0.9757 - val_auc: 0.9909\n",
      "Epoch 81/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0030 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9729 - val_auc: 0.9912\n",
      "Epoch 82/100\n",
      "197/197 [==============================] - 5s 25ms/step - loss: 0.0030 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9729 - val_auc: 0.9911\n",
      "Epoch 83/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0037 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1111 - val_accuracy: 0.9743 - val_auc: 0.9912\n",
      "Epoch 84/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0031 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1179 - val_accuracy: 0.9729 - val_auc: 0.9911\n",
      "Epoch 85/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0028 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.9729 - val_auc: 0.9912\n",
      "Epoch 86/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9729 - val_auc: 0.9912\n",
      "Epoch 87/100\n",
      "197/197 [==============================] - 5s 24ms/step - loss: 0.0023 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9729 - val_auc: 0.9913\n",
      "Epoch 88/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9729 - val_auc: 0.9912\n",
      "Epoch 89/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1253 - val_accuracy: 0.9743 - val_auc: 0.9911\n",
      "Epoch 90/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0023 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9743 - val_auc: 0.9913\n",
      "Epoch 91/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0021 - accuracy: 0.9998 - auc: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9743 - val_auc: 0.9913\n",
      "Epoch 92/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0022 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1245 - val_accuracy: 0.9729 - val_auc: 0.9913\n",
      "Epoch 93/100\n",
      "197/197 [==============================] - 4s 23ms/step - loss: 0.0018 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9743 - val_auc: 0.9914\n",
      "Epoch 94/100\n",
      "197/197 [==============================] - 4s 23ms/step - loss: 0.0015 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1233 - val_accuracy: 0.9729 - val_auc: 0.9915\n",
      "Epoch 95/100\n",
      "197/197 [==============================] - 4s 23ms/step - loss: 0.0018 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1209 - val_accuracy: 0.9771 - val_auc: 0.9914\n",
      "Epoch 96/100\n",
      "197/197 [==============================] - 4s 23ms/step - loss: 0.0019 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1276 - val_accuracy: 0.9729 - val_auc: 0.9913\n",
      "Epoch 97/100\n",
      "197/197 [==============================] - 4s 23ms/step - loss: 0.0016 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1259 - val_accuracy: 0.9729 - val_auc: 0.9915\n",
      "Epoch 98/100\n",
      "197/197 [==============================] - 4s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1248 - val_accuracy: 0.9757 - val_auc: 0.9914\n",
      "Epoch 99/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0014 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9771 - val_auc: 0.9901\n",
      "Epoch 100/100\n",
      "197/197 [==============================] - 5s 23ms/step - loss: 0.0013 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9729 - val_auc: 0.9913\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_hog, train_labels,\n",
    "    validation_data=(val_hog, val_labels),\n",
    "    epochs=100,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57f67017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 2s 22ms/step - loss: 0.2972 - accuracy: 0.9373 - auc: 0.9739\n",
      "\n",
      "Test Accuracy of DFC on Efficent net: 93.73%\n",
      "94/94 [==============================] - 3s 19ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      1500\n",
      "           1       0.95      0.92      0.94      1500\n",
      "\n",
      "    accuracy                           0.94      3000\n",
      "   macro avg       0.94      0.94      0.94      3000\n",
      "weighted avg       0.94      0.94      0.94      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_auc = model.evaluate(test_hog, test_labels)\n",
    "print(f'\\nTest Accuracy of DFC on Efficent net: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test_hog)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47979ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n",
      "94/94 [==============================] - 2s 20ms/step - loss: 0.2556 - accuracy: 0.9453 - auc: 0.9768\n",
      "\n",
      "Test Accuracy of DFC on EfficientNetB0: 94.53%\n",
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 6.1%\n",
      "RAM Used: 262.6 MB\n",
      "Time Usage: 4.1 s\n",
      "GPU Memory Used: 751.6 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor.get_stats()\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_auc = model.evaluate(test_hog, test_labels)\n",
    "print(f'\\nTest Accuracy of DFC on EfficientNetB0: {test_acc*100:.2f}%')\n",
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c23af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 12.0%\n",
      "RAM Used: 4325.0 MB\n",
      "Time Usage: 1423.8 s\n",
      "GPU Memory Used: 19.2 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d4cd4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 7s 21ms/step - loss: 2.6444 - accuracy: 0.6719 - auc: 0.4901\n",
      "\n",
      "Test Accuracy of Celeb-df dataset on Efficentnet for DFC: 67.19%\n",
      "340/340 [==============================] - 6s 18ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.12      0.16      2961\n",
      "           1       0.73      0.88      0.80      7891\n",
      "\n",
      "    accuracy                           0.67     10852\n",
      "   macro avg       0.50      0.50      0.48     10852\n",
      "weighted avg       0.60      0.67      0.62     10852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_auc = model.evaluate(test, test_labels)\n",
    "print(f'\\nTest Accuracy of Celeb-df dataset on Efficentnet for DFC: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfbfab7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 4s 21ms/step - loss: 2.6739 - accuracy: 0.6142 - auc: 0.5226\n",
      "\n",
      "Test Accuracy of FF++ dataset on Efficentnet for DFC: 61.42%\n",
      "169/169 [==============================] - 3s 19ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.29      0.29      1468\n",
      "           1       0.74      0.73      0.73      3911\n",
      "\n",
      "    accuracy                           0.61      5379\n",
      "   macro avg       0.51      0.51      0.51      5379\n",
      "weighted avg       0.61      0.61      0.61      5379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_auc = model.evaluate(test_ff, test_labels_ff)\n",
    "print(f'\\nTest Accuracy of FF++ dataset on Efficentnet for DFC: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test_ff)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels_ff, y_pred_binary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4709c6",
   "metadata": {},
   "source": [
    "# FF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca9f7307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from the HDF5 file.\n",
      "Data loaded successfully from the HDF5 file.\n",
      "Data loaded successfully from the HDF5 file.\n",
      "Data loaded successfully from the HDF5 file.\n",
      "Shape of the concatenated array: (2808, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (3299, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (1742, 160, 160, 3)\n",
      "Shape of the concatenated array: (1742, 160, 160, 3)\n",
      "Training data ACTOR real shape: (1965, 160, 160, 3) Testing real data shape: (843, 160, 160, 3)\n",
      "Training data Youtube real shape: (1458, 160, 160, 3) Testing real data shape: (625, 160, 160, 3)\n",
      "Training data DFD fake shape: (2309, 160, 160, 3) Testing fake data shape: (990, 160, 160, 3)\n",
      "Training data DF fake shape: (1458, 160, 160, 3) Testing fake data shape: (625, 160, 160, 3)\n",
      "Training data f2f fake shape: (1458, 160, 160, 3) Testing fake data shape: (625, 160, 160, 3)\n",
      "Training data fshifter fake shape: (1458, 160, 160, 3) Testing fake data shape: (625, 160, 160, 3)\n",
      "Training data fswap fake shape: (1219, 160, 160, 3) Testing fake data shape: (523, 160, 160, 3)\n",
      "Training data nt fake shape: (1219, 160, 160, 3) Testing fake data shape: (523, 160, 160, 3)\n",
      "train_ori_actor hog_real: 1768 images, val_ori_actor hog_real: 197 images\n",
      "train_ ori_youtube hog_real: 1312 images, val_ ori_youtube hog_real: 146 images\n",
      "train_hog_mni_dfd_fake: 2078 images, val_hog_mni_dfd_fake: 231 images\n",
      "train_hog_mni_df_fake: 1312 images, val_hog_mni_df_fake: 146 images\n",
      "train_hog_mni_f2f_fake: 1312 images, val_hog_mni_f2f_fake: 146 images\n",
      "train_hog_mni_fshifter_fake: 1312 images, val_hog_mni_fshifter_fake: 146 images\n",
      "train_hog_mni_fswap_fake: 1097 images, val_hog_mni_fswap_fake: 122 images\n",
      "train_hog_mni_nt_fake: 1097 images, val_hog_mni_nt_fake: 122 images\n",
      "Total train: 11288 images, and shape:(11288, 160, 160, 3)\n",
      "Total test: 5379 images, and shape:(5379, 160, 160, 3)\n",
      "Total val: 1256 images, and shape:(1256, 160, 160, 3)\n",
      "Train Labels: 11288 \n",
      "Test Labels: 5379 \n",
      "Val Labels: 1256 \n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the HDF5 file for reading\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_orignal_processed.h5\", \"r\") as h5f:\n",
    "    org_seq_actor_array = h5f[\"ori_actor\"][:]\n",
    "    org_seq_youtube_array = h5f[\"ori_youtube\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_fake1_processed.h5\", \"r\") as h5f:\n",
    "    meni_seq_dfd_array = h5f[\"mni_dfd\"][:]\n",
    "    meni_seq_df_array = h5f[\"mni_df\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_fake2_processed.h5\", \"r\") as h5f:\n",
    "    meni_seq_f2f_array = h5f[\"mni_f2f\"][:]\n",
    "    meni_seq_fshifter_array = h5f[\"mni_fshifter\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_fake3_processed.h5\", \"r\") as h5f:\n",
    "    meni_seq_fswap_array = h5f[\"mni_fswap\"][:]\n",
    "    meni_seq_nt_array = h5f[\"mni_nt\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "# Output the shape of the resulting array\n",
    "print(f\"Shape of the concatenated array: {org_seq_actor_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {org_seq_youtube_array.shape}\")\n",
    "\n",
    "print(f\"Shape of the concatenated array: {meni_seq_dfd_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_df_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_fshifter_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_f2f_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_fswap_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_nt_array.shape}\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ori_actor_train_real, ori_actor_test_real = train_test_split(org_seq_actor_array, test_size=0.3, random_state=42)\n",
    "ori_youtube_train_real, ori_youtube_test_real = train_test_split(org_seq_youtube_array, test_size=0.3, random_state=42)\n",
    "# Split the data into train (70%) and test (30%)\n",
    "mni_dfd_train_fake, mni_dfd_test_fake = train_test_split(meni_seq_dfd_array, test_size=0.3, random_state=42)\n",
    "mni_df_train_fake, mni_df_test_fake = train_test_split(meni_seq_df_array, test_size=0.3, random_state=42)\n",
    "mni_f2f_train_fake, mni_f2f_test_fake = train_test_split(meni_seq_f2f_array, test_size=0.3, random_state=42)\n",
    "mni_fshifter_train_fake, mni_fshifter_test_fake = train_test_split(meni_seq_fshifter_array, test_size=0.3, random_state=42)\n",
    "mni_fswap_train_fake, mni_fswap_test_fake = train_test_split(meni_seq_fswap_array, test_size=0.3, random_state=42)\n",
    "mni_nt_train_fake, mni_nt_test_fake = train_test_split(meni_seq_nt_array, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Output the shape to confirm the split dimensions\n",
    "print(\"Training data ACTOR real shape:\", ori_actor_train_real.shape, \"Testing real data shape:\", ori_actor_test_real.shape)\n",
    "print(\"Training data Youtube real shape:\", ori_youtube_train_real.shape, \"Testing real data shape:\", ori_youtube_test_real.shape)\n",
    "\n",
    "print(\"Training data DFD fake shape:\", mni_dfd_train_fake.shape, \"Testing fake data shape:\", mni_dfd_test_fake.shape)\n",
    "print(\"Training data DF fake shape:\", mni_df_train_fake.shape, \"Testing fake data shape:\", mni_df_test_fake.shape)\n",
    "print(\"Training data f2f fake shape:\", mni_f2f_train_fake.shape, \"Testing fake data shape:\", mni_f2f_test_fake.shape)\n",
    "print(\"Training data fshifter fake shape:\", mni_fshifter_train_fake.shape, \"Testing fake data shape:\", mni_fshifter_test_fake.shape)\n",
    "print(\"Training data fswap fake shape:\", mni_fswap_train_fake.shape, \"Testing fake data shape:\", mni_fswap_test_fake.shape)\n",
    "print(\"Training data nt fake shape:\", mni_nt_train_fake.shape, \"Testing fake data shape:\", mni_nt_test_fake.shape)\n",
    "########################################################################################################################################\n",
    "#######################################divide into 60,10 train and val\n",
    "#########################################################################################################################################\n",
    "def extract_validation(train_data):\n",
    "    \"\"\"\n",
    "    Extract every 10th sample from the training data and store it in a validation set.\n",
    "\n",
    "    Parameters:\n",
    "        train_data (list or np.array): The training dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated training dataset and validation dataset.\n",
    "    \"\"\"\n",
    "    # Select every 10th sample for the validation set\n",
    "    validation_data = train_data[::10]\n",
    "\n",
    "    # Remove the selected samples from the training dataset\n",
    "    updated_train_data = [train_data[i] for i in range(len(train_data)) if i % 10 != 0]\n",
    "\n",
    "    return np.array(updated_train_data), np.array(validation_data)\n",
    "\n",
    "\n",
    "# Perform the operation for each dataset\n",
    "train_hog_ori_actor_real, val_hog_ori_actor_real = extract_validation(ori_actor_train_real)\n",
    "train_hog_ori_youtube_real, val_hog_ori_youtube_real = extract_validation(ori_youtube_train_real)\n",
    "train_hog_mni_dfd_fake, val_hog_mni_dfd_fake = extract_validation(mni_dfd_train_fake)\n",
    "train_hog_mni_df_fake, val_hog_mni_df_fake = extract_validation(mni_df_train_fake)\n",
    "train_hog_mni_f2f_fake, val_hog_mni_f2f_fake = extract_validation(mni_f2f_train_fake)\n",
    "train_hog_mni_fshifter_fake, val_hog_mni_fshifter_fake = extract_validation(mni_fshifter_train_fake)\n",
    "train_hog_mni_fswap_fake, val_hog_mni_fswap_fake = extract_validation(mni_fswap_train_fake)\n",
    "train_hog_mni_nt_fake, val_hog_mni_nt_fake = extract_validation(mni_nt_train_fake)\n",
    "# Print results for verification\n",
    "print(f\"train_ori_actor hog_real: {len(train_hog_ori_actor_real)} images, val_ori_actor hog_real: {len(val_hog_ori_actor_real)} images\")\n",
    "print(f\"train_ ori_youtube hog_real: {len(train_hog_ori_youtube_real)} images, val_ ori_youtube hog_real: {len(val_hog_ori_youtube_real)} images\")\n",
    "print(f\"train_hog_mni_dfd_fake: {len(train_hog_mni_dfd_fake)} images, val_hog_mni_dfd_fake: {len(val_hog_mni_dfd_fake)} images\")\n",
    "print(f\"train_hog_mni_df_fake: {len(train_hog_mni_df_fake)} images, val_hog_mni_df_fake: {len(val_hog_mni_df_fake)} images\")\n",
    "print(f\"train_hog_mni_f2f_fake: {len(train_hog_mni_f2f_fake)} images, val_hog_mni_f2f_fake: {len(val_hog_mni_f2f_fake)} images\")\n",
    "print(f\"train_hog_mni_fshifter_fake: {len(train_hog_mni_fshifter_fake)} images, val_hog_mni_fshifter_fake: {len(val_hog_mni_fshifter_fake)} images\")\n",
    "print(f\"train_hog_mni_fswap_fake: {len(train_hog_mni_fswap_fake)} images, val_hog_mni_fswap_fake: {len(val_hog_mni_fswap_fake)} images\")\n",
    "print(f\"train_hog_mni_nt_fake: {len(train_hog_mni_nt_fake)} images, val_hog_mni_nt_fake: {len(val_hog_mni_nt_fake)} images\")\n",
    "############################################################################################################################################################\n",
    "#################################################concatenate the labels 0,1 real and fake\n",
    "#############################################################################################################################################################\n",
    "\n",
    "\n",
    "train_ori_actor_labels_real = np.zeros(len(train_hog_ori_actor_real), dtype=int)\n",
    "train_ori_youtube_labels_real = np.zeros(len(train_hog_ori_youtube_real), dtype=int)\n",
    "train_mni_dfd_labels_fake = np.ones(len(train_hog_mni_dfd_fake), dtype=int)\n",
    "train_mni_df_labels_fake = np.ones(len(train_hog_mni_df_fake), dtype=int)\n",
    "train_mni_f2f_labels_fake = np.ones(len(train_hog_mni_f2f_fake), dtype=int)\n",
    "train_mni_fshifter_labels_fake = np.ones(len(train_hog_mni_fshifter_fake), dtype=int)\n",
    "train_mni_fswap_labels_fake = np.ones(len(train_hog_mni_fswap_fake), dtype=int)\n",
    "train_mni_nt_labels_fake = np.ones(len(train_hog_mni_nt_fake), dtype=int)\n",
    "\n",
    "test_ori_actor_labels_real = np.zeros(len(ori_actor_test_real), dtype=int)\n",
    "test_ori_youtube_labels_real = np.zeros(len(ori_youtube_test_real), dtype=int)\n",
    "test_mni_dfd_labels_fake = np.ones(len(mni_dfd_test_fake), dtype=int)\n",
    "test_mni_df_labels_fake = np.ones(len(mni_df_test_fake), dtype=int)\n",
    "test_mni_f2f_labels_fake = np.ones(len(mni_f2f_test_fake), dtype=int)\n",
    "test_mni_fshifter_labels_fake = np.ones(len(mni_fshifter_test_fake), dtype=int)\n",
    "test_mni_fswap_labels_fake = np.ones(len(mni_fswap_test_fake), dtype=int)\n",
    "test_mni_nt_labels_fake = np.ones(len(mni_nt_test_fake), dtype=int)\n",
    "\n",
    "\n",
    "val_ori_actor_labels_real = np.zeros(len(val_hog_ori_actor_real), dtype=int)\n",
    "val_ori_youtube_labels_real = np.zeros(len(val_hog_ori_youtube_real), dtype=int)\n",
    "val_mni_dfd_labels_fake = np.ones(len(val_hog_mni_dfd_fake), dtype=int)\n",
    "val_mni_df_labels_fake = np.ones(len(val_hog_mni_df_fake), dtype=int)\n",
    "val_mni_f2f_labels_fake = np.ones(len(val_hog_mni_f2f_fake), dtype=int)\n",
    "val_mni_fshifter_labels_fake = np.ones(len(val_hog_mni_fshifter_fake), dtype=int)\n",
    "val_mni_fswap_labels_fake = np.ones(len(val_hog_mni_fswap_fake), dtype=int)\n",
    "val_mni_nt_labels_fake = np.ones(len(val_hog_mni_nt_fake), dtype=int)\n",
    "##################################################################################################################\n",
    "\n",
    "# Concatenate all training datasets into a single `train` variable\n",
    "train_ff = np.concatenate([train_hog_ori_actor_real, train_hog_ori_youtube_real,train_hog_mni_dfd_fake,train_hog_mni_df_fake,\n",
    "                            train_hog_mni_f2f_fake,train_hog_mni_fshifter_fake,train_hog_mni_fswap_fake,train_hog_mni_nt_fake], axis=0)\n",
    "\n",
    "train_labels_ff = np.concatenate([train_ori_actor_labels_real, train_ori_youtube_labels_real,train_mni_dfd_labels_fake,train_mni_df_labels_fake,\n",
    "                            train_mni_f2f_labels_fake,train_mni_fshifter_labels_fake,train_mni_fswap_labels_fake,train_mni_nt_labels_fake], axis=0)\n",
    "\n",
    "# Concatenate all validation datasets into a single `val` variable\n",
    "val_ff = np.concatenate([val_hog_ori_actor_real, val_hog_ori_youtube_real, val_hog_mni_dfd_fake, val_hog_mni_df_fake,\n",
    "                            val_hog_mni_f2f_fake, val_hog_mni_fshifter_fake, val_hog_mni_fswap_fake, val_hog_mni_nt_fake], axis=0)\n",
    "val_labels_ff = np.concatenate([val_ori_actor_labels_real, val_ori_youtube_labels_real, val_mni_dfd_labels_fake, val_mni_df_labels_fake,\n",
    "                            val_mni_f2f_labels_fake, val_mni_fshifter_labels_fake, val_mni_fswap_labels_fake, val_mni_nt_labels_fake], axis=0)\n",
    "# Concatenate all testing datasets into a single `test` variable\n",
    "test_ff = np.concatenate([ori_actor_test_real, ori_youtube_test_real, mni_dfd_test_fake,\n",
    "                           mni_df_test_fake, mni_f2f_test_fake, mni_fshifter_test_fake,\n",
    "                           mni_fswap_test_fake, mni_nt_test_fake], axis=0)\n",
    "test_labels_ff = np.concatenate([test_ori_actor_labels_real, test_ori_youtube_labels_real, test_mni_dfd_labels_fake, test_mni_df_labels_fake,\n",
    "                            test_mni_f2f_labels_fake, test_mni_fshifter_labels_fake, test_mni_fswap_labels_fake, test_mni_nt_labels_fake], axis=0)\n",
    "\n",
    "\n",
    "# Print the results for verification\n",
    "# Print the results for verification\n",
    "print(f\"Total train: {len(train_ff)} images, and shape:{train_ff.shape}\")\n",
    "print(f\"Total test: {len(test_ff)} images, and shape:{test_ff.shape}\")\n",
    "print(f\"Total val: {len(val_ff)} images, and shape:{val_ff.shape}\")\n",
    "\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"Train Labels: {len(train_labels_ff)} \")\n",
    "print(f\"Test Labels: {len(test_labels_ff)} \")\n",
    "print(f\"Val Labels: {len(val_labels_ff)} \")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7a4081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "353/353 [==============================] - 16s 27ms/step - loss: 0.5607 - accuracy: 0.7334 - auc: 0.6410 - val_loss: 0.5448 - val_accuracy: 0.7373 - val_auc: 0.6782\n",
      "Epoch 2/100\n",
      "353/353 [==============================] - 8s 24ms/step - loss: 0.5422 - accuracy: 0.7445 - auc: 0.6761 - val_loss: 0.5376 - val_accuracy: 0.7381 - val_auc: 0.6880\n",
      "Epoch 3/100\n",
      "353/353 [==============================] - 9s 24ms/step - loss: 0.5328 - accuracy: 0.7517 - auc: 0.6902 - val_loss: 0.5356 - val_accuracy: 0.7436 - val_auc: 0.6903\n",
      "Epoch 4/100\n",
      "353/353 [==============================] - 17s 49ms/step - loss: 0.5245 - accuracy: 0.7597 - auc: 0.7035 - val_loss: 0.5329 - val_accuracy: 0.7404 - val_auc: 0.6949\n",
      "Epoch 5/100\n",
      "353/353 [==============================] - 12s 34ms/step - loss: 0.5190 - accuracy: 0.7659 - auc: 0.7129 - val_loss: 0.5317 - val_accuracy: 0.7500 - val_auc: 0.6965\n",
      "Epoch 6/100\n",
      "353/353 [==============================] - 19s 53ms/step - loss: 0.5139 - accuracy: 0.7693 - auc: 0.7193 - val_loss: 0.5311 - val_accuracy: 0.7532 - val_auc: 0.6973\n",
      "Epoch 7/100\n",
      "353/353 [==============================] - 19s 53ms/step - loss: 0.5085 - accuracy: 0.7725 - auc: 0.7273 - val_loss: 0.5287 - val_accuracy: 0.7484 - val_auc: 0.7020\n",
      "Epoch 8/100\n",
      "353/353 [==============================] - 18s 52ms/step - loss: 0.5041 - accuracy: 0.7745 - auc: 0.7342 - val_loss: 0.5284 - val_accuracy: 0.7532 - val_auc: 0.7001\n",
      "Epoch 9/100\n",
      "353/353 [==============================] - 19s 55ms/step - loss: 0.4966 - accuracy: 0.7799 - auc: 0.7438 - val_loss: 0.5264 - val_accuracy: 0.7564 - val_auc: 0.7011\n",
      "Epoch 10/100\n",
      "353/353 [==============================] - 21s 61ms/step - loss: 0.4935 - accuracy: 0.7858 - auc: 0.7472 - val_loss: 0.5268 - val_accuracy: 0.7588 - val_auc: 0.7009\n",
      "Epoch 11/100\n",
      "353/353 [==============================] - 13s 38ms/step - loss: 0.4879 - accuracy: 0.7864 - auc: 0.7570 - val_loss: 0.5262 - val_accuracy: 0.7540 - val_auc: 0.7022\n",
      "Epoch 12/100\n",
      "353/353 [==============================] - 8s 24ms/step - loss: 0.4813 - accuracy: 0.7862 - auc: 0.7663 - val_loss: 0.5250 - val_accuracy: 0.7556 - val_auc: 0.7021\n",
      "Epoch 13/100\n",
      "353/353 [==============================] - 17s 48ms/step - loss: 0.4777 - accuracy: 0.7957 - auc: 0.7695 - val_loss: 0.5251 - val_accuracy: 0.7524 - val_auc: 0.7038\n",
      "Epoch 14/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.4752 - accuracy: 0.7935 - auc: 0.7734 - val_loss: 0.5234 - val_accuracy: 0.7611 - val_auc: 0.7062\n",
      "Epoch 15/100\n",
      "353/353 [==============================] - 22s 62ms/step - loss: 0.4693 - accuracy: 0.7985 - auc: 0.7785 - val_loss: 0.5236 - val_accuracy: 0.7635 - val_auc: 0.7035\n",
      "Epoch 16/100\n",
      "353/353 [==============================] - 20s 56ms/step - loss: 0.4648 - accuracy: 0.7976 - auc: 0.7862 - val_loss: 0.5236 - val_accuracy: 0.7619 - val_auc: 0.7062\n",
      "Epoch 17/100\n",
      "353/353 [==============================] - 19s 54ms/step - loss: 0.4607 - accuracy: 0.8009 - auc: 0.7891 - val_loss: 0.5231 - val_accuracy: 0.7596 - val_auc: 0.7059\n",
      "Epoch 18/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.4576 - accuracy: 0.8057 - auc: 0.7957 - val_loss: 0.5242 - val_accuracy: 0.7627 - val_auc: 0.7052\n",
      "Epoch 19/100\n",
      "353/353 [==============================] - 20s 58ms/step - loss: 0.4543 - accuracy: 0.8040 - auc: 0.7993 - val_loss: 0.5248 - val_accuracy: 0.7635 - val_auc: 0.7089\n",
      "Epoch 20/100\n",
      "353/353 [==============================] - 20s 56ms/step - loss: 0.4495 - accuracy: 0.8080 - auc: 0.8034 - val_loss: 0.5244 - val_accuracy: 0.7627 - val_auc: 0.7026\n",
      "Epoch 21/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.4465 - accuracy: 0.8075 - auc: 0.8066 - val_loss: 0.5245 - val_accuracy: 0.7604 - val_auc: 0.7033\n",
      "Epoch 22/100\n",
      "353/353 [==============================] - 19s 54ms/step - loss: 0.4428 - accuracy: 0.8101 - auc: 0.8130 - val_loss: 0.5269 - val_accuracy: 0.7643 - val_auc: 0.7035\n",
      "Epoch 23/100\n",
      "353/353 [==============================] - 17s 47ms/step - loss: 0.4388 - accuracy: 0.8111 - auc: 0.8167 - val_loss: 0.5252 - val_accuracy: 0.7588 - val_auc: 0.7039\n",
      "Epoch 24/100\n",
      "353/353 [==============================] - 18s 50ms/step - loss: 0.4357 - accuracy: 0.8133 - auc: 0.8196 - val_loss: 0.5302 - val_accuracy: 0.7643 - val_auc: 0.7015\n",
      "Epoch 25/100\n",
      "353/353 [==============================] - 18s 51ms/step - loss: 0.4313 - accuracy: 0.8147 - auc: 0.8236 - val_loss: 0.5241 - val_accuracy: 0.7651 - val_auc: 0.7063\n",
      "Epoch 26/100\n",
      "353/353 [==============================] - 18s 51ms/step - loss: 0.4264 - accuracy: 0.8164 - auc: 0.8304 - val_loss: 0.5270 - val_accuracy: 0.7691 - val_auc: 0.7080\n",
      "Epoch 27/100\n",
      "353/353 [==============================] - 18s 52ms/step - loss: 0.4230 - accuracy: 0.8172 - auc: 0.8346 - val_loss: 0.5274 - val_accuracy: 0.7596 - val_auc: 0.7077\n",
      "Epoch 28/100\n",
      "353/353 [==============================] - 18s 50ms/step - loss: 0.4216 - accuracy: 0.8183 - auc: 0.8354 - val_loss: 0.5267 - val_accuracy: 0.7596 - val_auc: 0.7053\n",
      "Epoch 29/100\n",
      "353/353 [==============================] - 17s 49ms/step - loss: 0.4175 - accuracy: 0.8220 - auc: 0.8408 - val_loss: 0.5272 - val_accuracy: 0.7611 - val_auc: 0.7075\n",
      "Epoch 30/100\n",
      "353/353 [==============================] - 18s 51ms/step - loss: 0.4149 - accuracy: 0.8230 - auc: 0.8403 - val_loss: 0.5285 - val_accuracy: 0.7627 - val_auc: 0.7055\n",
      "Epoch 31/100\n",
      "353/353 [==============================] - 16s 46ms/step - loss: 0.4084 - accuracy: 0.8262 - auc: 0.8483 - val_loss: 0.5293 - val_accuracy: 0.7619 - val_auc: 0.7066\n",
      "Epoch 32/100\n",
      "353/353 [==============================] - 17s 48ms/step - loss: 0.4073 - accuracy: 0.8249 - auc: 0.8503 - val_loss: 0.5326 - val_accuracy: 0.7699 - val_auc: 0.7063\n",
      "Epoch 33/100\n",
      "353/353 [==============================] - 18s 52ms/step - loss: 0.4018 - accuracy: 0.8284 - auc: 0.8553 - val_loss: 0.5293 - val_accuracy: 0.7659 - val_auc: 0.7077\n",
      "Epoch 34/100\n",
      "353/353 [==============================] - 16s 47ms/step - loss: 0.3991 - accuracy: 0.8288 - auc: 0.8580 - val_loss: 0.5307 - val_accuracy: 0.7675 - val_auc: 0.7073\n",
      "Epoch 35/100\n",
      "353/353 [==============================] - 18s 51ms/step - loss: 0.3965 - accuracy: 0.8291 - auc: 0.8598 - val_loss: 0.5348 - val_accuracy: 0.7596 - val_auc: 0.7060\n",
      "Epoch 36/100\n",
      "353/353 [==============================] - 19s 55ms/step - loss: 0.3936 - accuracy: 0.8320 - auc: 0.8620 - val_loss: 0.5324 - val_accuracy: 0.7675 - val_auc: 0.7088\n",
      "Epoch 37/100\n",
      "353/353 [==============================] - 22s 63ms/step - loss: 0.3894 - accuracy: 0.8339 - auc: 0.8664 - val_loss: 0.5360 - val_accuracy: 0.7611 - val_auc: 0.7048\n",
      "Epoch 38/100\n",
      "353/353 [==============================] - 20s 58ms/step - loss: 0.3859 - accuracy: 0.8367 - auc: 0.8683 - val_loss: 0.5366 - val_accuracy: 0.7604 - val_auc: 0.7030\n",
      "Epoch 39/100\n",
      "353/353 [==============================] - 21s 59ms/step - loss: 0.3834 - accuracy: 0.8365 - auc: 0.8715 - val_loss: 0.5357 - val_accuracy: 0.7627 - val_auc: 0.7028\n",
      "Epoch 40/100\n",
      "353/353 [==============================] - 20s 56ms/step - loss: 0.3800 - accuracy: 0.8417 - auc: 0.8741 - val_loss: 0.5374 - val_accuracy: 0.7683 - val_auc: 0.7082\n",
      "Epoch 41/100\n",
      "353/353 [==============================] - 18s 52ms/step - loss: 0.3753 - accuracy: 0.8417 - auc: 0.8775 - val_loss: 0.5395 - val_accuracy: 0.7651 - val_auc: 0.7032\n",
      "Epoch 42/100\n",
      "353/353 [==============================] - 19s 53ms/step - loss: 0.3742 - accuracy: 0.8427 - auc: 0.8807 - val_loss: 0.5421 - val_accuracy: 0.7635 - val_auc: 0.7030\n",
      "Epoch 43/100\n",
      "353/353 [==============================] - 19s 55ms/step - loss: 0.3706 - accuracy: 0.8411 - auc: 0.8843 - val_loss: 0.5397 - val_accuracy: 0.7619 - val_auc: 0.6966\n",
      "Epoch 44/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.3680 - accuracy: 0.8443 - auc: 0.8849 - val_loss: 0.5418 - val_accuracy: 0.7643 - val_auc: 0.6988\n",
      "Epoch 45/100\n",
      "353/353 [==============================] - 20s 56ms/step - loss: 0.3634 - accuracy: 0.8457 - auc: 0.8894 - val_loss: 0.5452 - val_accuracy: 0.7611 - val_auc: 0.7051\n",
      "Epoch 46/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.3563 - accuracy: 0.8525 - auc: 0.8920 - val_loss: 0.5423 - val_accuracy: 0.7619 - val_auc: 0.7016\n",
      "Epoch 47/100\n",
      "353/353 [==============================] - 19s 54ms/step - loss: 0.3573 - accuracy: 0.8503 - auc: 0.8929 - val_loss: 0.5468 - val_accuracy: 0.7691 - val_auc: 0.6964\n",
      "Epoch 48/100\n",
      "353/353 [==============================] - 19s 55ms/step - loss: 0.3538 - accuracy: 0.8504 - auc: 0.8947 - val_loss: 0.5464 - val_accuracy: 0.7611 - val_auc: 0.6931\n",
      "Epoch 49/100\n",
      "353/353 [==============================] - 16s 47ms/step - loss: 0.3544 - accuracy: 0.8496 - auc: 0.8952 - val_loss: 0.5494 - val_accuracy: 0.7675 - val_auc: 0.6962\n",
      "Epoch 50/100\n",
      "353/353 [==============================] - 16s 45ms/step - loss: 0.3485 - accuracy: 0.8550 - auc: 0.8994 - val_loss: 0.5510 - val_accuracy: 0.7667 - val_auc: 0.6949\n",
      "Epoch 51/100\n",
      "353/353 [==============================] - 18s 50ms/step - loss: 0.3441 - accuracy: 0.8575 - auc: 0.9023 - val_loss: 0.5611 - val_accuracy: 0.7707 - val_auc: 0.7022\n",
      "Epoch 52/100\n",
      "353/353 [==============================] - 19s 54ms/step - loss: 0.3455 - accuracy: 0.8573 - auc: 0.8998 - val_loss: 0.5490 - val_accuracy: 0.7651 - val_auc: 0.7010\n",
      "Epoch 53/100\n",
      "353/353 [==============================] - 19s 54ms/step - loss: 0.3429 - accuracy: 0.8566 - auc: 0.9031 - val_loss: 0.5527 - val_accuracy: 0.7659 - val_auc: 0.6952\n",
      "Epoch 54/100\n",
      "353/353 [==============================] - 18s 51ms/step - loss: 0.3356 - accuracy: 0.8614 - auc: 0.9097 - val_loss: 0.5589 - val_accuracy: 0.7627 - val_auc: 0.6985\n",
      "Epoch 55/100\n",
      "353/353 [==============================] - 18s 51ms/step - loss: 0.3302 - accuracy: 0.8632 - auc: 0.9127 - val_loss: 0.5541 - val_accuracy: 0.7643 - val_auc: 0.7001\n",
      "Epoch 56/100\n",
      "353/353 [==============================] - 18s 50ms/step - loss: 0.3311 - accuracy: 0.8614 - auc: 0.9111 - val_loss: 0.5589 - val_accuracy: 0.7604 - val_auc: 0.7005\n",
      "Epoch 57/100\n",
      "353/353 [==============================] - 19s 54ms/step - loss: 0.3281 - accuracy: 0.8651 - auc: 0.9132 - val_loss: 0.5584 - val_accuracy: 0.7651 - val_auc: 0.6946\n",
      "Epoch 58/100\n",
      "353/353 [==============================] - 19s 53ms/step - loss: 0.3280 - accuracy: 0.8630 - auc: 0.9133 - val_loss: 0.5617 - val_accuracy: 0.7611 - val_auc: 0.6910\n",
      "Epoch 59/100\n",
      "353/353 [==============================] - 17s 48ms/step - loss: 0.3238 - accuracy: 0.8695 - auc: 0.9164 - val_loss: 0.5622 - val_accuracy: 0.7635 - val_auc: 0.6927\n",
      "Epoch 60/100\n",
      "353/353 [==============================] - 18s 51ms/step - loss: 0.3204 - accuracy: 0.8663 - auc: 0.9188 - val_loss: 0.5661 - val_accuracy: 0.7651 - val_auc: 0.6977\n",
      "Epoch 61/100\n",
      "353/353 [==============================] - 19s 54ms/step - loss: 0.3135 - accuracy: 0.8734 - auc: 0.9231 - val_loss: 0.5705 - val_accuracy: 0.7651 - val_auc: 0.6959\n",
      "Epoch 62/100\n",
      "353/353 [==============================] - 21s 59ms/step - loss: 0.3172 - accuracy: 0.8691 - auc: 0.9210 - val_loss: 0.5694 - val_accuracy: 0.7715 - val_auc: 0.6957\n",
      "Epoch 63/100\n",
      "353/353 [==============================] - 21s 60ms/step - loss: 0.3114 - accuracy: 0.8747 - auc: 0.9234 - val_loss: 0.5659 - val_accuracy: 0.7611 - val_auc: 0.6953\n",
      "Epoch 64/100\n",
      "353/353 [==============================] - 20s 57ms/step - loss: 0.3101 - accuracy: 0.8742 - auc: 0.9240 - val_loss: 0.5682 - val_accuracy: 0.7572 - val_auc: 0.6983\n",
      "Epoch 65/100\n",
      "353/353 [==============================] - 19s 54ms/step - loss: 0.3063 - accuracy: 0.8732 - auc: 0.9272 - val_loss: 0.5756 - val_accuracy: 0.7723 - val_auc: 0.6949\n",
      "Epoch 66/100\n",
      "353/353 [==============================] - 14s 41ms/step - loss: 0.3088 - accuracy: 0.8759 - auc: 0.9254 - val_loss: 0.5680 - val_accuracy: 0.7572 - val_auc: 0.6978\n",
      "Epoch 67/100\n",
      "353/353 [==============================] - 14s 39ms/step - loss: 0.3000 - accuracy: 0.8778 - auc: 0.9319 - val_loss: 0.5726 - val_accuracy: 0.7683 - val_auc: 0.6973\n",
      "Epoch 68/100\n",
      "353/353 [==============================] - 14s 39ms/step - loss: 0.2992 - accuracy: 0.8803 - auc: 0.9317 - val_loss: 0.5748 - val_accuracy: 0.7635 - val_auc: 0.7046\n",
      "Epoch 69/100\n",
      "353/353 [==============================] - 14s 41ms/step - loss: 0.2953 - accuracy: 0.8780 - auc: 0.9348 - val_loss: 0.5794 - val_accuracy: 0.7667 - val_auc: 0.6990\n",
      "Epoch 70/100\n",
      "353/353 [==============================] - 14s 40ms/step - loss: 0.2959 - accuracy: 0.8795 - auc: 0.9340 - val_loss: 0.5769 - val_accuracy: 0.7643 - val_auc: 0.6978\n",
      "Epoch 71/100\n",
      "353/353 [==============================] - 14s 40ms/step - loss: 0.2894 - accuracy: 0.8842 - auc: 0.9374 - val_loss: 0.5951 - val_accuracy: 0.7667 - val_auc: 0.6948\n",
      "Epoch 72/100\n",
      "353/353 [==============================] - 15s 41ms/step - loss: 0.2910 - accuracy: 0.8830 - auc: 0.9355 - val_loss: 0.5826 - val_accuracy: 0.7643 - val_auc: 0.6986\n",
      "Epoch 73/100\n",
      "353/353 [==============================] - 15s 41ms/step - loss: 0.2861 - accuracy: 0.8870 - auc: 0.9380 - val_loss: 0.5794 - val_accuracy: 0.7619 - val_auc: 0.6951\n",
      "Epoch 74/100\n",
      "353/353 [==============================] - 14s 41ms/step - loss: 0.2817 - accuracy: 0.8856 - auc: 0.9417 - val_loss: 0.5855 - val_accuracy: 0.7619 - val_auc: 0.6934\n",
      "Epoch 75/100\n",
      "353/353 [==============================] - 14s 41ms/step - loss: 0.2803 - accuracy: 0.8884 - auc: 0.9432 - val_loss: 0.5890 - val_accuracy: 0.7627 - val_auc: 0.7001\n",
      "Epoch 76/100\n",
      "353/353 [==============================] - 12s 34ms/step - loss: 0.2803 - accuracy: 0.8877 - auc: 0.9415 - val_loss: 0.5990 - val_accuracy: 0.7596 - val_auc: 0.6951\n",
      "Epoch 77/100\n",
      "353/353 [==============================] - 17s 47ms/step - loss: 0.2752 - accuracy: 0.8905 - auc: 0.9445 - val_loss: 0.5871 - val_accuracy: 0.7635 - val_auc: 0.6994\n",
      "Epoch 78/100\n",
      "353/353 [==============================] - 18s 51ms/step - loss: 0.2743 - accuracy: 0.8918 - auc: 0.9451 - val_loss: 0.5925 - val_accuracy: 0.7667 - val_auc: 0.6967\n",
      "Epoch 79/100\n",
      "353/353 [==============================] - 18s 52ms/step - loss: 0.2729 - accuracy: 0.8917 - auc: 0.9465 - val_loss: 0.5935 - val_accuracy: 0.7675 - val_auc: 0.6987\n",
      "Epoch 80/100\n",
      "353/353 [==============================] - 17s 48ms/step - loss: 0.2734 - accuracy: 0.8908 - auc: 0.9449 - val_loss: 0.5885 - val_accuracy: 0.7691 - val_auc: 0.7008\n",
      "Epoch 81/100\n",
      "353/353 [==============================] - 19s 53ms/step - loss: 0.2697 - accuracy: 0.8928 - auc: 0.9469 - val_loss: 0.5936 - val_accuracy: 0.7588 - val_auc: 0.6957\n",
      "Epoch 82/100\n",
      "353/353 [==============================] - 17s 49ms/step - loss: 0.2613 - accuracy: 0.8983 - auc: 0.9511 - val_loss: 0.5971 - val_accuracy: 0.7611 - val_auc: 0.7015\n",
      "Epoch 83/100\n",
      "353/353 [==============================] - 18s 51ms/step - loss: 0.2603 - accuracy: 0.8971 - auc: 0.9529 - val_loss: 0.5968 - val_accuracy: 0.7611 - val_auc: 0.6969\n",
      "Epoch 84/100\n",
      "353/353 [==============================] - 18s 50ms/step - loss: 0.2593 - accuracy: 0.8989 - auc: 0.9519 - val_loss: 0.6027 - val_accuracy: 0.7643 - val_auc: 0.6921\n",
      "Epoch 85/100\n",
      "353/353 [==============================] - 18s 52ms/step - loss: 0.2577 - accuracy: 0.8984 - auc: 0.9533 - val_loss: 0.6031 - val_accuracy: 0.7659 - val_auc: 0.6974\n",
      "Epoch 86/100\n",
      "353/353 [==============================] - 16s 45ms/step - loss: 0.2536 - accuracy: 0.9011 - auc: 0.9548 - val_loss: 0.6071 - val_accuracy: 0.7604 - val_auc: 0.6957\n",
      "Epoch 87/100\n",
      "353/353 [==============================] - 14s 40ms/step - loss: 0.2540 - accuracy: 0.9009 - auc: 0.9553 - val_loss: 0.6096 - val_accuracy: 0.7588 - val_auc: 0.6962\n",
      "Epoch 88/100\n",
      "353/353 [==============================] - 13s 38ms/step - loss: 0.2519 - accuracy: 0.9002 - auc: 0.9549 - val_loss: 0.6188 - val_accuracy: 0.7627 - val_auc: 0.6979\n",
      "Epoch 89/100\n",
      "353/353 [==============================] - 14s 41ms/step - loss: 0.2508 - accuracy: 0.9005 - auc: 0.9564 - val_loss: 0.6118 - val_accuracy: 0.7675 - val_auc: 0.6986\n",
      "Epoch 90/100\n",
      "353/353 [==============================] - 14s 40ms/step - loss: 0.2493 - accuracy: 0.9050 - auc: 0.9557 - val_loss: 0.6117 - val_accuracy: 0.7596 - val_auc: 0.6981\n",
      "Epoch 91/100\n",
      "353/353 [==============================] - 14s 40ms/step - loss: 0.2464 - accuracy: 0.9042 - auc: 0.9579 - val_loss: 0.6099 - val_accuracy: 0.7508 - val_auc: 0.6972\n",
      "Epoch 92/100\n",
      "353/353 [==============================] - 14s 41ms/step - loss: 0.2415 - accuracy: 0.9063 - auc: 0.9606 - val_loss: 0.6157 - val_accuracy: 0.7564 - val_auc: 0.6937\n",
      "Epoch 93/100\n",
      "353/353 [==============================] - 15s 42ms/step - loss: 0.2432 - accuracy: 0.9056 - auc: 0.9582 - val_loss: 0.6229 - val_accuracy: 0.7604 - val_auc: 0.6972\n",
      "Epoch 94/100\n",
      "353/353 [==============================] - 15s 42ms/step - loss: 0.2394 - accuracy: 0.9071 - auc: 0.9612 - val_loss: 0.6288 - val_accuracy: 0.7675 - val_auc: 0.6998\n",
      "Epoch 95/100\n",
      "353/353 [==============================] - 14s 40ms/step - loss: 0.2351 - accuracy: 0.9086 - auc: 0.9631 - val_loss: 0.6214 - val_accuracy: 0.7588 - val_auc: 0.6995\n",
      "Epoch 96/100\n",
      "353/353 [==============================] - 15s 42ms/step - loss: 0.2352 - accuracy: 0.9103 - auc: 0.9621 - val_loss: 0.6249 - val_accuracy: 0.7596 - val_auc: 0.7000\n",
      "Epoch 97/100\n",
      "353/353 [==============================] - 15s 41ms/step - loss: 0.2316 - accuracy: 0.9113 - auc: 0.9640 - val_loss: 0.6284 - val_accuracy: 0.7548 - val_auc: 0.6964\n",
      "Epoch 98/100\n",
      "353/353 [==============================] - 14s 41ms/step - loss: 0.2299 - accuracy: 0.9122 - auc: 0.9645 - val_loss: 0.6274 - val_accuracy: 0.7532 - val_auc: 0.6959\n",
      "Epoch 99/100\n",
      "353/353 [==============================] - 14s 41ms/step - loss: 0.2275 - accuracy: 0.9116 - auc: 0.9653 - val_loss: 0.6274 - val_accuracy: 0.7572 - val_auc: 0.6978\n",
      "Epoch 100/100\n",
      "353/353 [==============================] - 15s 42ms/step - loss: 0.2279 - accuracy: 0.9145 - auc: 0.9645 - val_loss: 0.6293 - val_accuracy: 0.7508 - val_auc: 0.7009\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ff, train_labels_ff,\n",
    "    validation_data=(val_ff, val_labels_ff),\n",
    "    epochs=100,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10c27211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "353/353 [==============================] - 15s 25ms/step - loss: 0.5624 - accuracy: 0.7285 - auc: 0.6388 - val_loss: 0.5396 - val_accuracy: 0.7404 - val_auc: 0.6880\n",
      "Epoch 2/100\n",
      "353/353 [==============================] - 8s 23ms/step - loss: 0.5397 - accuracy: 0.7454 - auc: 0.6804 - val_loss: 0.5377 - val_accuracy: 0.7389 - val_auc: 0.6893\n",
      "Epoch 3/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.5301 - accuracy: 0.7530 - auc: 0.6966 - val_loss: 0.5354 - val_accuracy: 0.7460 - val_auc: 0.6947\n",
      "Epoch 4/100\n",
      "353/353 [==============================] - 8s 23ms/step - loss: 0.5249 - accuracy: 0.7576 - auc: 0.7044 - val_loss: 0.5338 - val_accuracy: 0.7373 - val_auc: 0.6962\n",
      "Epoch 5/100\n",
      "353/353 [==============================] - 8s 23ms/step - loss: 0.5165 - accuracy: 0.7645 - auc: 0.7192 - val_loss: 0.5314 - val_accuracy: 0.7484 - val_auc: 0.6980\n",
      "Epoch 6/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.5118 - accuracy: 0.7706 - auc: 0.7230 - val_loss: 0.5322 - val_accuracy: 0.7468 - val_auc: 0.6979\n",
      "Epoch 7/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.5072 - accuracy: 0.7728 - auc: 0.7308 - val_loss: 0.5302 - val_accuracy: 0.7468 - val_auc: 0.7003\n",
      "Epoch 8/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.5003 - accuracy: 0.7808 - auc: 0.7391 - val_loss: 0.5286 - val_accuracy: 0.7484 - val_auc: 0.7029\n",
      "Epoch 9/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4929 - accuracy: 0.7815 - auc: 0.7527 - val_loss: 0.5295 - val_accuracy: 0.7500 - val_auc: 0.7028\n",
      "Epoch 10/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4881 - accuracy: 0.7845 - auc: 0.7585 - val_loss: 0.5277 - val_accuracy: 0.7532 - val_auc: 0.7048\n",
      "Epoch 11/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4848 - accuracy: 0.7865 - auc: 0.7631 - val_loss: 0.5265 - val_accuracy: 0.7492 - val_auc: 0.7025\n",
      "Epoch 12/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4791 - accuracy: 0.7916 - auc: 0.7695 - val_loss: 0.5244 - val_accuracy: 0.7540 - val_auc: 0.7037\n",
      "Epoch 13/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4755 - accuracy: 0.7945 - auc: 0.7722 - val_loss: 0.5255 - val_accuracy: 0.7540 - val_auc: 0.7023\n",
      "Epoch 14/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4720 - accuracy: 0.7939 - auc: 0.7796 - val_loss: 0.5244 - val_accuracy: 0.7596 - val_auc: 0.7063\n",
      "Epoch 15/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4668 - accuracy: 0.7965 - auc: 0.7865 - val_loss: 0.5242 - val_accuracy: 0.7548 - val_auc: 0.7051\n",
      "Epoch 16/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4635 - accuracy: 0.8009 - auc: 0.7879 - val_loss: 0.5225 - val_accuracy: 0.7604 - val_auc: 0.7036\n",
      "Epoch 17/100\n",
      "353/353 [==============================] - 8s 23ms/step - loss: 0.4581 - accuracy: 0.8014 - auc: 0.7956 - val_loss: 0.5231 - val_accuracy: 0.7596 - val_auc: 0.7046\n",
      "Epoch 18/100\n",
      "353/353 [==============================] - 8s 23ms/step - loss: 0.4545 - accuracy: 0.8019 - auc: 0.8023 - val_loss: 0.5244 - val_accuracy: 0.7596 - val_auc: 0.7098\n",
      "Epoch 19/100\n",
      "353/353 [==============================] - 8s 23ms/step - loss: 0.4508 - accuracy: 0.8050 - auc: 0.8045 - val_loss: 0.5236 - val_accuracy: 0.7540 - val_auc: 0.7085\n",
      "Epoch 20/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4449 - accuracy: 0.8078 - auc: 0.8110 - val_loss: 0.5260 - val_accuracy: 0.7540 - val_auc: 0.7053\n",
      "Epoch 21/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4425 - accuracy: 0.8121 - auc: 0.8112 - val_loss: 0.5241 - val_accuracy: 0.7611 - val_auc: 0.7094\n",
      "Epoch 22/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4378 - accuracy: 0.8117 - auc: 0.8197 - val_loss: 0.5238 - val_accuracy: 0.7635 - val_auc: 0.7114\n",
      "Epoch 23/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4342 - accuracy: 0.8133 - auc: 0.8231 - val_loss: 0.5236 - val_accuracy: 0.7611 - val_auc: 0.7091\n",
      "Epoch 24/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4318 - accuracy: 0.8142 - auc: 0.8257 - val_loss: 0.5227 - val_accuracy: 0.7572 - val_auc: 0.7108\n",
      "Epoch 25/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4276 - accuracy: 0.8153 - auc: 0.8302 - val_loss: 0.5253 - val_accuracy: 0.7619 - val_auc: 0.7074\n",
      "Epoch 26/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4232 - accuracy: 0.8200 - auc: 0.8355 - val_loss: 0.5242 - val_accuracy: 0.7619 - val_auc: 0.7077\n",
      "Epoch 27/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4211 - accuracy: 0.8196 - auc: 0.8370 - val_loss: 0.5230 - val_accuracy: 0.7651 - val_auc: 0.7091\n",
      "Epoch 28/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4177 - accuracy: 0.8220 - auc: 0.8411 - val_loss: 0.5267 - val_accuracy: 0.7643 - val_auc: 0.7076\n",
      "Epoch 29/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4135 - accuracy: 0.8229 - auc: 0.8443 - val_loss: 0.5280 - val_accuracy: 0.7588 - val_auc: 0.7075\n",
      "Epoch 30/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4077 - accuracy: 0.8246 - auc: 0.8513 - val_loss: 0.5252 - val_accuracy: 0.7659 - val_auc: 0.7106\n",
      "Epoch 31/100\n",
      "353/353 [==============================] - 8s 23ms/step - loss: 0.4030 - accuracy: 0.8299 - auc: 0.8538 - val_loss: 0.5285 - val_accuracy: 0.7635 - val_auc: 0.7071\n",
      "Epoch 32/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.4026 - accuracy: 0.8280 - auc: 0.8551 - val_loss: 0.5281 - val_accuracy: 0.7667 - val_auc: 0.7078\n",
      "Epoch 33/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3991 - accuracy: 0.8282 - auc: 0.8588 - val_loss: 0.5291 - val_accuracy: 0.7643 - val_auc: 0.7034\n",
      "Epoch 34/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3937 - accuracy: 0.8322 - auc: 0.8648 - val_loss: 0.5349 - val_accuracy: 0.7715 - val_auc: 0.7065\n",
      "Epoch 35/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3898 - accuracy: 0.8346 - auc: 0.8658 - val_loss: 0.5314 - val_accuracy: 0.7627 - val_auc: 0.7061\n",
      "Epoch 36/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3878 - accuracy: 0.8351 - auc: 0.8686 - val_loss: 0.5290 - val_accuracy: 0.7627 - val_auc: 0.7117\n",
      "Epoch 37/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3837 - accuracy: 0.8385 - auc: 0.8717 - val_loss: 0.5319 - val_accuracy: 0.7604 - val_auc: 0.7105\n",
      "Epoch 38/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3798 - accuracy: 0.8369 - auc: 0.8761 - val_loss: 0.5334 - val_accuracy: 0.7683 - val_auc: 0.7070\n",
      "Epoch 39/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3774 - accuracy: 0.8407 - auc: 0.8771 - val_loss: 0.5313 - val_accuracy: 0.7651 - val_auc: 0.7105\n",
      "Epoch 40/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3726 - accuracy: 0.8418 - auc: 0.8811 - val_loss: 0.5374 - val_accuracy: 0.7707 - val_auc: 0.7060\n",
      "Epoch 41/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3713 - accuracy: 0.8432 - auc: 0.8816 - val_loss: 0.5306 - val_accuracy: 0.7739 - val_auc: 0.7050\n",
      "Epoch 42/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3687 - accuracy: 0.8445 - auc: 0.8849 - val_loss: 0.5374 - val_accuracy: 0.7691 - val_auc: 0.7095\n",
      "Epoch 43/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3657 - accuracy: 0.8461 - auc: 0.8866 - val_loss: 0.5349 - val_accuracy: 0.7707 - val_auc: 0.7116\n",
      "Epoch 44/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3626 - accuracy: 0.8475 - auc: 0.8904 - val_loss: 0.5333 - val_accuracy: 0.7619 - val_auc: 0.7124\n",
      "Epoch 45/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3603 - accuracy: 0.8482 - auc: 0.8914 - val_loss: 0.5331 - val_accuracy: 0.7643 - val_auc: 0.7112\n",
      "Epoch 46/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3565 - accuracy: 0.8529 - auc: 0.8936 - val_loss: 0.5357 - val_accuracy: 0.7715 - val_auc: 0.7146\n",
      "Epoch 47/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3511 - accuracy: 0.8515 - auc: 0.8978 - val_loss: 0.5374 - val_accuracy: 0.7707 - val_auc: 0.7071\n",
      "Epoch 48/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3490 - accuracy: 0.8565 - auc: 0.8999 - val_loss: 0.5407 - val_accuracy: 0.7771 - val_auc: 0.7054\n",
      "Epoch 49/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3468 - accuracy: 0.8539 - auc: 0.9021 - val_loss: 0.5427 - val_accuracy: 0.7707 - val_auc: 0.7047\n",
      "Epoch 50/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3423 - accuracy: 0.8563 - auc: 0.9054 - val_loss: 0.5397 - val_accuracy: 0.7667 - val_auc: 0.7073\n",
      "Epoch 51/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3403 - accuracy: 0.8599 - auc: 0.9074 - val_loss: 0.5449 - val_accuracy: 0.7659 - val_auc: 0.7082\n",
      "Epoch 52/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3353 - accuracy: 0.8625 - auc: 0.9090 - val_loss: 0.5451 - val_accuracy: 0.7691 - val_auc: 0.7089\n",
      "Epoch 53/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3344 - accuracy: 0.8624 - auc: 0.9091 - val_loss: 0.5478 - val_accuracy: 0.7715 - val_auc: 0.7081\n",
      "Epoch 54/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3319 - accuracy: 0.8611 - auc: 0.9117 - val_loss: 0.5465 - val_accuracy: 0.7667 - val_auc: 0.7101\n",
      "Epoch 55/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3252 - accuracy: 0.8658 - auc: 0.9171 - val_loss: 0.5477 - val_accuracy: 0.7707 - val_auc: 0.7073\n",
      "Epoch 56/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3235 - accuracy: 0.8653 - auc: 0.9185 - val_loss: 0.5491 - val_accuracy: 0.7627 - val_auc: 0.7109\n",
      "Epoch 57/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3228 - accuracy: 0.8657 - auc: 0.9185 - val_loss: 0.5494 - val_accuracy: 0.7675 - val_auc: 0.7076\n",
      "Epoch 58/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3192 - accuracy: 0.8677 - auc: 0.9208 - val_loss: 0.5522 - val_accuracy: 0.7691 - val_auc: 0.7089\n",
      "Epoch 59/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3158 - accuracy: 0.8689 - auc: 0.9229 - val_loss: 0.5535 - val_accuracy: 0.7635 - val_auc: 0.7012\n",
      "Epoch 60/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3126 - accuracy: 0.8719 - auc: 0.9256 - val_loss: 0.5590 - val_accuracy: 0.7596 - val_auc: 0.7024\n",
      "Epoch 61/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3117 - accuracy: 0.8712 - auc: 0.9247 - val_loss: 0.5542 - val_accuracy: 0.7667 - val_auc: 0.7069\n",
      "Epoch 62/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.3109 - accuracy: 0.8711 - auc: 0.9262 - val_loss: 0.5519 - val_accuracy: 0.7588 - val_auc: 0.7120\n",
      "Epoch 63/100\n",
      "353/353 [==============================] - 8s 23ms/step - loss: 0.3051 - accuracy: 0.8754 - auc: 0.9287 - val_loss: 0.5616 - val_accuracy: 0.7635 - val_auc: 0.7080\n",
      "Epoch 64/100\n",
      "353/353 [==============================] - 8s 23ms/step - loss: 0.3014 - accuracy: 0.8769 - auc: 0.9313 - val_loss: 0.5583 - val_accuracy: 0.7588 - val_auc: 0.7024\n",
      "Epoch 65/100\n",
      "353/353 [==============================] - 8s 23ms/step - loss: 0.3002 - accuracy: 0.8787 - auc: 0.9328 - val_loss: 0.5820 - val_accuracy: 0.7739 - val_auc: 0.7048\n",
      "Epoch 66/100\n",
      "353/353 [==============================] - 8s 23ms/step - loss: 0.2970 - accuracy: 0.8802 - auc: 0.9342 - val_loss: 0.5632 - val_accuracy: 0.7667 - val_auc: 0.7075\n",
      "Epoch 67/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2969 - accuracy: 0.8783 - auc: 0.9334 - val_loss: 0.5604 - val_accuracy: 0.7532 - val_auc: 0.7039\n",
      "Epoch 68/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2891 - accuracy: 0.8833 - auc: 0.9392 - val_loss: 0.5691 - val_accuracy: 0.7619 - val_auc: 0.7026\n",
      "Epoch 69/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2878 - accuracy: 0.8820 - auc: 0.9402 - val_loss: 0.5777 - val_accuracy: 0.7643 - val_auc: 0.7040\n",
      "Epoch 70/100\n",
      "353/353 [==============================] - 8s 23ms/step - loss: 0.2850 - accuracy: 0.8831 - auc: 0.9407 - val_loss: 0.5767 - val_accuracy: 0.7611 - val_auc: 0.7018\n",
      "Epoch 71/100\n",
      "353/353 [==============================] - 8s 23ms/step - loss: 0.2819 - accuracy: 0.8855 - auc: 0.9428 - val_loss: 0.5784 - val_accuracy: 0.7659 - val_auc: 0.7015\n",
      "Epoch 72/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2808 - accuracy: 0.8874 - auc: 0.9432 - val_loss: 0.5817 - val_accuracy: 0.7691 - val_auc: 0.7064\n",
      "Epoch 73/100\n",
      "353/353 [==============================] - 8s 23ms/step - loss: 0.2766 - accuracy: 0.8888 - auc: 0.9454 - val_loss: 0.5830 - val_accuracy: 0.7659 - val_auc: 0.7039\n",
      "Epoch 74/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2735 - accuracy: 0.8886 - auc: 0.9475 - val_loss: 0.5761 - val_accuracy: 0.7627 - val_auc: 0.7058\n",
      "Epoch 75/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2719 - accuracy: 0.8909 - auc: 0.9472 - val_loss: 0.5810 - val_accuracy: 0.7667 - val_auc: 0.7092\n",
      "Epoch 76/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2700 - accuracy: 0.8898 - auc: 0.9481 - val_loss: 0.5864 - val_accuracy: 0.7604 - val_auc: 0.7040\n",
      "Epoch 77/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2668 - accuracy: 0.8927 - auc: 0.9502 - val_loss: 0.5848 - val_accuracy: 0.7635 - val_auc: 0.7043\n",
      "Epoch 78/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2618 - accuracy: 0.8963 - auc: 0.9528 - val_loss: 0.5846 - val_accuracy: 0.7635 - val_auc: 0.7053\n",
      "Epoch 79/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2621 - accuracy: 0.8982 - auc: 0.9520 - val_loss: 0.5884 - val_accuracy: 0.7556 - val_auc: 0.7009\n",
      "Epoch 80/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2601 - accuracy: 0.8975 - auc: 0.9529 - val_loss: 0.5944 - val_accuracy: 0.7564 - val_auc: 0.6995\n",
      "Epoch 81/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2594 - accuracy: 0.8986 - auc: 0.9531 - val_loss: 0.5984 - val_accuracy: 0.7675 - val_auc: 0.7058\n",
      "Epoch 82/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2565 - accuracy: 0.8978 - auc: 0.9547 - val_loss: 0.5989 - val_accuracy: 0.7564 - val_auc: 0.7060\n",
      "Epoch 83/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2520 - accuracy: 0.8987 - auc: 0.9576 - val_loss: 0.6034 - val_accuracy: 0.7588 - val_auc: 0.7041\n",
      "Epoch 84/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2529 - accuracy: 0.9013 - auc: 0.9563 - val_loss: 0.6164 - val_accuracy: 0.7675 - val_auc: 0.7081\n",
      "Epoch 85/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2464 - accuracy: 0.9014 - auc: 0.9592 - val_loss: 0.6050 - val_accuracy: 0.7500 - val_auc: 0.6994\n",
      "Epoch 86/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2445 - accuracy: 0.9055 - auc: 0.9606 - val_loss: 0.6045 - val_accuracy: 0.7580 - val_auc: 0.7016\n",
      "Epoch 87/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2447 - accuracy: 0.9039 - auc: 0.9592 - val_loss: 0.6044 - val_accuracy: 0.7572 - val_auc: 0.7040\n",
      "Epoch 88/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2417 - accuracy: 0.9057 - auc: 0.9610 - val_loss: 0.6134 - val_accuracy: 0.7596 - val_auc: 0.7055\n",
      "Epoch 89/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2375 - accuracy: 0.9066 - auc: 0.9631 - val_loss: 0.6211 - val_accuracy: 0.7651 - val_auc: 0.6989\n",
      "Epoch 90/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2351 - accuracy: 0.9088 - auc: 0.9644 - val_loss: 0.6348 - val_accuracy: 0.7667 - val_auc: 0.7035\n",
      "Epoch 91/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2365 - accuracy: 0.9089 - auc: 0.9631 - val_loss: 0.6225 - val_accuracy: 0.7667 - val_auc: 0.6975\n",
      "Epoch 92/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2332 - accuracy: 0.9102 - auc: 0.9643 - val_loss: 0.6145 - val_accuracy: 0.7667 - val_auc: 0.7045\n",
      "Epoch 93/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2306 - accuracy: 0.9127 - auc: 0.9653 - val_loss: 0.6261 - val_accuracy: 0.7604 - val_auc: 0.6975\n",
      "Epoch 94/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2302 - accuracy: 0.9106 - auc: 0.9651 - val_loss: 0.6268 - val_accuracy: 0.7611 - val_auc: 0.6995\n",
      "Epoch 95/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2272 - accuracy: 0.9119 - auc: 0.9667 - val_loss: 0.6377 - val_accuracy: 0.7659 - val_auc: 0.7011\n",
      "Epoch 96/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2221 - accuracy: 0.9156 - auc: 0.9686 - val_loss: 0.6307 - val_accuracy: 0.7596 - val_auc: 0.7027\n",
      "Epoch 97/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2241 - accuracy: 0.9145 - auc: 0.9681 - val_loss: 0.6307 - val_accuracy: 0.7635 - val_auc: 0.7007\n",
      "Epoch 98/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2207 - accuracy: 0.9172 - auc: 0.9684 - val_loss: 0.6304 - val_accuracy: 0.7627 - val_auc: 0.7060\n",
      "Epoch 99/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2218 - accuracy: 0.9148 - auc: 0.9683 - val_loss: 0.6264 - val_accuracy: 0.7412 - val_auc: 0.7002\n",
      "Epoch 100/100\n",
      "353/353 [==============================] - 8s 22ms/step - loss: 0.2176 - accuracy: 0.9172 - auc: 0.9704 - val_loss: 0.6299 - val_accuracy: 0.7627 - val_auc: 0.7086\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ff, train_labels_ff,\n",
    "    validation_data=(val_ff, val_labels_ff),\n",
    "    epochs=100,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59aa49e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 6s 34ms/step - loss: 0.6008 - accuracy: 0.7550 - auc: 0.7218\n",
      "\n",
      "Test Accuracy of FF++ on Inceptionnet: 75.50%\n",
      "169/169 [==============================] - 9s 30ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.44      0.49      1468\n",
      "           1       0.80      0.87      0.84      3911\n",
      "\n",
      "    accuracy                           0.75      5379\n",
      "   macro avg       0.69      0.66      0.67      5379\n",
      "weighted avg       0.74      0.75      0.74      5379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_auc = model.evaluate(test_ff, test_labels_ff)\n",
    "print(f'\\nTest Accuracy of FF++ on Inceptionnet: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test_ff)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels_ff, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37dc62c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n",
      "169/169 [==============================] - 3s 19ms/step - loss: 0.6067 - accuracy: 0.7620 - auc: 0.7222\n",
      "\n",
      "Test Accuracy of FF++ on EfficientNetB0: 76.20%\n",
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 1.1%\n",
      "RAM Used: 411.8 MB\n",
      "Time Usage: 5.6 s\n",
      "GPU Memory Used: 1331.9 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor.get_stats()\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_auc = model.evaluate(test_ff, test_labels_ff)\n",
    "print(f'\\nTest Accuracy of FF++ on EfficientNetB0: {test_acc*100:.2f}%')\n",
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d84a37fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# After training the model\n",
    "model.save('Inceptionnet_160_ff.h5')  # Saves the entire model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "907ed965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 12.3%\n",
      "RAM Used: 3821.8 MB\n",
      "Time Usage: 1746.6 s\n",
      "GPU Memory Used: 1725.9 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1f82fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 2s 21ms/step - loss: 1.2588 - accuracy: 0.5483 - auc: 0.5503\n",
      "\n",
      "Test Accuracy of DFC dataset on Efficentnet for FF++: 54.83%\n",
      "94/94 [==============================] - 2s 19ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.38      0.46      1500\n",
      "           1       0.54      0.72      0.61      1500\n",
      "\n",
      "    accuracy                           0.55      3000\n",
      "   macro avg       0.55      0.55      0.53      3000\n",
      "weighted avg       0.55      0.55      0.53      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_auc = model.evaluate(test_hog, test_labels)\n",
    "print(f'\\nTest Accuracy of DFC dataset on Efficentnet for FF++: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test_hog)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2648a7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 7s 22ms/step - loss: 0.7910 - accuracy: 0.6989 - auc: 0.5697\n",
      "\n",
      "Test Accuracy of Celeb-df dataset on Efficentnet for FF++: 69.89%\n",
      "340/340 [==============================] - 6s 19ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.16      0.22      2961\n",
      "           1       0.74      0.90      0.81      7891\n",
      "\n",
      "    accuracy                           0.70     10852\n",
      "   macro avg       0.56      0.53      0.52     10852\n",
      "weighted avg       0.64      0.70      0.65     10852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_auc = model.evaluate(test, test_labels)\n",
    "print(f'\\nTest Accuracy of Celeb-df dataset on Efficentnet for FF++: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c667401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 6s 32ms/step - loss: 1.5210 - accuracy: 0.7382 - auc: 0.6626\n",
      "Test Accuracy of FF++ on Inceptionnet: 73.82%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('Inceptionnet_160_ff.h5')\n",
    "test_loss, test_acc, test_auc = model.evaluate(test_ff, test_labels_ff)\n",
    "print(f'Test Accuracy of FF++ on Inceptionnet: {test_acc * 100:.2f}%')\n",
    "# You can now use the model for testing or inference\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
