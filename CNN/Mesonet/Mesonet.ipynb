{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a643551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import psutil\n",
    "\n",
    "class PowerMonitor:\n",
    "    def __init__(self):\n",
    "        self.gpu_available = tf.config.list_physical_devices('GPU')\n",
    "        \n",
    "        # Hardware power specifications (adjust these values for your system)\n",
    "        self.cpu_tdp = 65    # Typical TDP for desktop CPUs in watts\n",
    "        self.gpu_tdp = 250   # Typical TDP for desktop GPUs in watts\n",
    "        \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get system stats with power estimation\"\"\"\n",
    "        stats = {\n",
    "            'timestamp': time.time(),\n",
    "            'cpu_%': psutil.cpu_percent(interval=0.1),\n",
    "            'ram_mb': psutil.virtual_memory().used / (1024**2),\n",
    "            'gpu_mem_mb': 0,\n",
    "            'power_w': self.cpu_tdp * (psutil.cpu_percent()/100) * 0.85  # Base CPU power\n",
    "        }\n",
    "        \n",
    "        if self.gpu_available:\n",
    "            try:\n",
    "                # TensorFlow GPU memory monitoring\n",
    "                mem_info = tf.config.experimental.get_memory_info('GPU:0')\n",
    "                stats.update({\n",
    "                    'gpu_mem_mb': mem_info['current'] / (1024**2),\n",
    "                    'power_w': self.cpu_tdp * (psutil.cpu_percent()/100) * 0.85 + \n",
    "                              self.gpu_tdp * 0.5 * 0.75  # Add GPU power estimate\n",
    "                })\n",
    "            except:\n",
    "                pass\n",
    "                \n",
    "        return stats\n",
    "\n",
    "# Initialize monitor\n",
    "monitor = PowerMonitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a293c1",
   "metadata": {},
   "source": [
    "# Celeb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63683390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9870, 160, 160, 3), (11274, 160, 160, 3))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import h5py\n",
    "\n",
    "# Open the HDF5 file for reading\n",
    "#with h5py.File(\"D:\\\\thesis\\dataset\\deepfake dataset\\images_celeb_224R_processed.h5\", \"r\") as h5f:\n",
    "with h5py.File(\"D:\\\\thesis\\dataset\\Celeb-Df-v2\\images_celeb_balanced_224R_processed.h5\", \"r\") as h5f:\n",
    "    # Load HOG features\n",
    "    real_frames_array1 = h5f[\"ori_actor\"][:]\n",
    "    fake_frames_array1 = h5f[\"ori_youtube\"][:]\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Function to resize images from (224, 224) to (160, 160)\n",
    "def resize_images(image_array, target_size=(160, 160)):\n",
    "    resized_images = np.array([cv2.resize(img, target_size) for img in image_array])\n",
    "    return resized_images\n",
    "\n",
    "\n",
    "# Resize the images\n",
    "real_frames_array1 = resize_images(real_frames_array1, target_size=(160, 160))\n",
    "fake_frames_array1 = resize_images(fake_frames_array1, target_size=(160, 160))\n",
    "\n",
    "# Checking the new shapes\n",
    "real_frames_array1.shape, fake_frames_array1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed4a7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data real shape: (6909, 160, 160, 3)\n",
      "Testing real data shape: (2961, 160, 160, 3)\n",
      "Training fake data shape: (7891, 160, 160, 3)\n",
      "Testing  fake data shape: (3383, 160, 160, 3)\n",
      "train_hog_real: 6218 images, val_hog_real: 691 images\n",
      "train_hog_fake: 7101 images, val_hog_fake: 790 images\n",
      "Total train: 13319 images\n",
      "Total test: 10852 images\n",
      "Total val: 1481 images\n",
      "Train Labels: 13319 \n",
      "Test Labels: 10852 \n",
      "Val Labels: 1481 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the data into train (70%) and test (30%)\n",
    "X_train_real, X_test_real = train_test_split(real_frames_array1, test_size=0.3, random_state=42)\n",
    "X_train_fake, X_test_fake = train_test_split(fake_frames_array1, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Output the shape to confirm the split dimensions\n",
    "print(\"Training data real shape:\", X_train_real.shape)\n",
    "print(\"Testing real data shape:\", X_test_real.shape)\n",
    "print(\"Training fake data shape:\", X_train_fake.shape)\n",
    "print(\"Testing  fake data shape:\", X_test_fake.shape)\n",
    "########################################################################################################################################\n",
    "#######################################divide into 60,10 train and val\n",
    "#########################################################################################################################################\n",
    "def extract_validation(train_data):\n",
    "    \"\"\"\n",
    "    Extract every 10th sample from the training data and store it in a validation set.\n",
    "\n",
    "    Parameters:\n",
    "        train_data (list or np.array): The training dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated training dataset and validation dataset.\n",
    "    \"\"\"\n",
    "    # Select every 10th sample for the validation set\n",
    "    validation_data = train_data[::10]\n",
    "\n",
    "    # Remove the selected samples from the training dataset\n",
    "    updated_train_data = [train_data[i] for i in range(len(train_data)) if i % 10 != 0]\n",
    "\n",
    "    return np.array(updated_train_data), np.array(validation_data)\n",
    "\n",
    "\n",
    "# Perform the operation for each dataset\n",
    "train_hog_real, val_hog_real = extract_validation(X_train_real)\n",
    "train_hog_fake, val_hog_fake = extract_validation(X_train_fake)\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"train_hog_real: {len(train_hog_real)} images, val_hog_real: {len(val_hog_real)} images\")\n",
    "print(f\"train_hog_fake: {len(train_hog_fake)} images, val_hog_fake: {len(val_hog_fake)} images\")\n",
    "\n",
    "\n",
    "############################################################################################################################################################\n",
    "#################################################concatenate the labels 0,1 real and fake\n",
    "#############################################################################################################################################################\n",
    "\n",
    "\n",
    "train_labels_real = np.zeros(len(train_hog_real), dtype=int)\n",
    "train_labels_fake = np.ones(len(train_hog_fake), dtype=int)\n",
    "\n",
    "# Concatenate all training datasets into a single `train` variable\n",
    "train = np.concatenate([train_hog_real, train_hog_fake], axis=0)\n",
    "train_labels=np.concatenate([train_labels_real, train_labels_fake], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "test_labels_real = np.zeros(len(X_test_real), dtype=int)\n",
    "test_labels_fake = np.ones(len(X_train_fake), dtype=int)\n",
    "\n",
    "# Concatenate all testing datasets into a single `test` variable\n",
    "test = np.concatenate([X_test_real, X_train_fake], axis=0)\n",
    "test_labels = np.concatenate([test_labels_real, test_labels_fake], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "val_labels_real = np.zeros(len(val_hog_real), dtype=int)\n",
    "val_labels_fake = np.ones(len(val_hog_fake), dtype=int)\n",
    "\n",
    "# Concatenate all validation datasets into a single `val` variable\n",
    "val = np.concatenate([val_hog_real, val_hog_fake], axis=0)\n",
    "val_labels = np.concatenate([val_labels_real, val_labels_fake], axis=0)\n",
    "\n",
    "# Print the results for verification\n",
    "print(f\"Total train: {len(train)} images\")\n",
    "print(f\"Total test: {len(test)} images\")\n",
    "print(f\"Total val: {len(val)} images\")\n",
    "\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"Train Labels: {len(train_labels)} \")\n",
    "print(f\"Test Labels: {len(test_labels)} \")\n",
    "print(f\"Val Labels: {len(val_labels)} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3add8a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42d4cc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 160, 160, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 160, 160, 8)       224       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 160, 160, 8)      32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 80, 80, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 80, 80, 8)         1608      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 80, 80, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 40, 40, 8)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 40, 40, 16)        3216      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 40, 40, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 20, 20, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 20, 20, 16)        6416      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 20, 20, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 5, 5, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 400)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 400)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                6416      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,089\n",
      "Trainable params: 17,993\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "def mesonet4_official(input_shape=(160, 160, 3)):\n",
    "    model = models.Sequential([\n",
    "        # Preprocessing (normalization)\n",
    "        layers.Rescaling(1./255, input_shape=input_shape),\n",
    "        \n",
    "        # Block 1\n",
    "        layers.Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2,2), padding='same'),\n",
    "        \n",
    "        # Block 2\n",
    "        layers.Conv2D(8, (5,5), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2,2), padding='same'),\n",
    "        \n",
    "        # Block 3\n",
    "        layers.Conv2D(16, (5,5), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2,2), padding='same'),\n",
    "        \n",
    "        # Block 4\n",
    "        layers.Conv2D(16, (5,5), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((4,4), padding='same'),\n",
    "        \n",
    "        # Classifier\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Verify\n",
    "model = mesonet4_official()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26c2e544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "417/417 [==============================] - 10s 13ms/step - loss: 0.8719 - accuracy: 0.5136 - val_loss: 0.6885 - val_accuracy: 0.5449\n",
      "Epoch 2/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.7106 - accuracy: 0.5404 - val_loss: 0.6853 - val_accuracy: 0.5469\n",
      "Epoch 3/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.6912 - accuracy: 0.5606 - val_loss: 0.6821 - val_accuracy: 0.5436\n",
      "Epoch 4/100\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.6782 - accuracy: 0.5735 - val_loss: 0.6723 - val_accuracy: 0.5955\n",
      "Epoch 5/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.6687 - accuracy: 0.5903 - val_loss: 0.6561 - val_accuracy: 0.6097\n",
      "Epoch 6/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.6572 - accuracy: 0.6106 - val_loss: 0.6484 - val_accuracy: 0.6124\n",
      "Epoch 7/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.6425 - accuracy: 0.6287 - val_loss: 0.6306 - val_accuracy: 0.6442\n",
      "Epoch 8/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.6313 - accuracy: 0.6443 - val_loss: 0.6227 - val_accuracy: 0.6293\n",
      "Epoch 9/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.6166 - accuracy: 0.6595 - val_loss: 0.6039 - val_accuracy: 0.6583\n",
      "Epoch 10/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.6097 - accuracy: 0.6671 - val_loss: 0.6078 - val_accuracy: 0.6475\n",
      "Epoch 11/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.5923 - accuracy: 0.6823 - val_loss: 0.5810 - val_accuracy: 0.6860\n",
      "Epoch 12/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.5876 - accuracy: 0.6896 - val_loss: 0.5677 - val_accuracy: 0.6995\n",
      "Epoch 13/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.5805 - accuracy: 0.6917 - val_loss: 0.5596 - val_accuracy: 0.7056\n",
      "Epoch 14/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.5680 - accuracy: 0.7019 - val_loss: 0.5528 - val_accuracy: 0.7090\n",
      "Epoch 15/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.5577 - accuracy: 0.7183 - val_loss: 0.5458 - val_accuracy: 0.7063\n",
      "Epoch 16/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.5526 - accuracy: 0.7181 - val_loss: 0.5520 - val_accuracy: 0.7016\n",
      "Epoch 17/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.5406 - accuracy: 0.7245 - val_loss: 0.5690 - val_accuracy: 0.6995\n",
      "Epoch 18/100\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.5368 - accuracy: 0.7258 - val_loss: 0.5251 - val_accuracy: 0.7245\n",
      "Epoch 19/100\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.5242 - accuracy: 0.7413 - val_loss: 0.5421 - val_accuracy: 0.7292\n",
      "Epoch 20/100\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.5192 - accuracy: 0.7413 - val_loss: 0.5176 - val_accuracy: 0.7319\n",
      "Epoch 21/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.5054 - accuracy: 0.7549 - val_loss: 0.5069 - val_accuracy: 0.7448\n",
      "Epoch 22/100\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.5007 - accuracy: 0.7532 - val_loss: 0.4965 - val_accuracy: 0.7515\n",
      "Epoch 23/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.4980 - accuracy: 0.7569 - val_loss: 0.4955 - val_accuracy: 0.7616\n",
      "Epoch 24/100\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.4920 - accuracy: 0.7622 - val_loss: 0.4887 - val_accuracy: 0.7562\n",
      "Epoch 25/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.4743 - accuracy: 0.7716 - val_loss: 0.4811 - val_accuracy: 0.7556\n",
      "Epoch 26/100\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.4761 - accuracy: 0.7712 - val_loss: 0.4910 - val_accuracy: 0.7549\n",
      "Epoch 27/100\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.4713 - accuracy: 0.7794 - val_loss: 0.5065 - val_accuracy: 0.7346\n",
      "Epoch 28/100\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.4601 - accuracy: 0.7820 - val_loss: 0.4718 - val_accuracy: 0.7664\n",
      "Epoch 29/100\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.4609 - accuracy: 0.7834 - val_loss: 0.4685 - val_accuracy: 0.7738\n",
      "Epoch 30/100\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.4506 - accuracy: 0.7891 - val_loss: 0.4569 - val_accuracy: 0.7826\n",
      "Epoch 31/100\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.4487 - accuracy: 0.7901 - val_loss: 0.4551 - val_accuracy: 0.7860\n",
      "Epoch 32/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.4389 - accuracy: 0.7937 - val_loss: 0.4739 - val_accuracy: 0.7799\n",
      "Epoch 33/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.4323 - accuracy: 0.8033 - val_loss: 0.4664 - val_accuracy: 0.7725\n",
      "Epoch 34/100\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.4279 - accuracy: 0.8034 - val_loss: 0.4351 - val_accuracy: 0.7887\n",
      "Epoch 35/100\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.4217 - accuracy: 0.8051 - val_loss: 0.4337 - val_accuracy: 0.7860\n",
      "Epoch 36/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.4156 - accuracy: 0.8077 - val_loss: 0.4330 - val_accuracy: 0.7947\n",
      "Epoch 37/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.4086 - accuracy: 0.8120 - val_loss: 0.4541 - val_accuracy: 0.7846\n",
      "Epoch 38/100\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.4128 - accuracy: 0.8134 - val_loss: 0.4268 - val_accuracy: 0.7961\n",
      "Epoch 39/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.4050 - accuracy: 0.8158 - val_loss: 0.4249 - val_accuracy: 0.7995\n",
      "Epoch 40/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.4037 - accuracy: 0.8169 - val_loss: 0.4202 - val_accuracy: 0.8015\n",
      "Epoch 41/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3908 - accuracy: 0.8235 - val_loss: 0.4316 - val_accuracy: 0.7974\n",
      "Epoch 42/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3853 - accuracy: 0.8301 - val_loss: 0.4045 - val_accuracy: 0.8150\n",
      "Epoch 43/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3887 - accuracy: 0.8232 - val_loss: 0.4064 - val_accuracy: 0.8022\n",
      "Epoch 44/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3811 - accuracy: 0.8294 - val_loss: 0.3977 - val_accuracy: 0.8076\n",
      "Epoch 45/100\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.3870 - accuracy: 0.8266 - val_loss: 0.3907 - val_accuracy: 0.8143\n",
      "Epoch 46/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3766 - accuracy: 0.8307 - val_loss: 0.3913 - val_accuracy: 0.8197\n",
      "Epoch 47/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3725 - accuracy: 0.8375 - val_loss: 0.3884 - val_accuracy: 0.8211\n",
      "Epoch 48/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3723 - accuracy: 0.8351 - val_loss: 0.3994 - val_accuracy: 0.8089\n",
      "Epoch 49/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3625 - accuracy: 0.8411 - val_loss: 0.3811 - val_accuracy: 0.8163\n",
      "Epoch 50/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3596 - accuracy: 0.8417 - val_loss: 0.4537 - val_accuracy: 0.7873\n",
      "Epoch 51/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3626 - accuracy: 0.8379 - val_loss: 0.3961 - val_accuracy: 0.8109\n",
      "Epoch 52/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3560 - accuracy: 0.8403 - val_loss: 0.3782 - val_accuracy: 0.8170\n",
      "Epoch 53/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3589 - accuracy: 0.8413 - val_loss: 0.4402 - val_accuracy: 0.7900\n",
      "Epoch 54/100\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.3443 - accuracy: 0.8426 - val_loss: 0.3837 - val_accuracy: 0.8332\n",
      "Epoch 55/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3458 - accuracy: 0.8473 - val_loss: 0.3777 - val_accuracy: 0.8217\n",
      "Epoch 56/100\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.3389 - accuracy: 0.8509 - val_loss: 0.3825 - val_accuracy: 0.8224\n",
      "Epoch 57/100\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.3394 - accuracy: 0.8522 - val_loss: 0.3675 - val_accuracy: 0.8332\n",
      "Epoch 58/100\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.3392 - accuracy: 0.8534 - val_loss: 0.3819 - val_accuracy: 0.8204\n",
      "Epoch 59/100\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.3297 - accuracy: 0.8534 - val_loss: 0.3594 - val_accuracy: 0.8319\n",
      "Epoch 60/100\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.3201 - accuracy: 0.8580 - val_loss: 0.3589 - val_accuracy: 0.8427\n",
      "Epoch 61/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3274 - accuracy: 0.8571 - val_loss: 0.4026 - val_accuracy: 0.8251\n",
      "Epoch 62/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3231 - accuracy: 0.8566 - val_loss: 0.3589 - val_accuracy: 0.8325\n",
      "Epoch 63/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3164 - accuracy: 0.8618 - val_loss: 0.3428 - val_accuracy: 0.8420\n",
      "Epoch 64/100\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.3140 - accuracy: 0.8634 - val_loss: 0.3634 - val_accuracy: 0.8298\n",
      "Epoch 65/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3177 - accuracy: 0.8637 - val_loss: 0.3605 - val_accuracy: 0.8359\n",
      "Epoch 66/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3150 - accuracy: 0.8619 - val_loss: 0.4006 - val_accuracy: 0.8096\n",
      "Epoch 67/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3078 - accuracy: 0.8655 - val_loss: 0.3578 - val_accuracy: 0.8400\n",
      "Epoch 68/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3056 - accuracy: 0.8693 - val_loss: 0.3547 - val_accuracy: 0.8366\n",
      "Epoch 69/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3050 - accuracy: 0.8685 - val_loss: 0.3512 - val_accuracy: 0.8393\n",
      "Epoch 70/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2959 - accuracy: 0.8709 - val_loss: 0.3676 - val_accuracy: 0.8325\n",
      "Epoch 71/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.3027 - accuracy: 0.8676 - val_loss: 0.3580 - val_accuracy: 0.8386\n",
      "Epoch 72/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2970 - accuracy: 0.8715 - val_loss: 0.3412 - val_accuracy: 0.8440\n",
      "Epoch 73/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2935 - accuracy: 0.8729 - val_loss: 0.3563 - val_accuracy: 0.8379\n",
      "Epoch 74/100\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.2989 - accuracy: 0.8676 - val_loss: 0.4191 - val_accuracy: 0.8096\n",
      "Epoch 75/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2905 - accuracy: 0.8757 - val_loss: 0.3449 - val_accuracy: 0.8393\n",
      "Epoch 76/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2857 - accuracy: 0.8783 - val_loss: 0.3375 - val_accuracy: 0.8393\n",
      "Epoch 77/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2815 - accuracy: 0.8771 - val_loss: 0.3952 - val_accuracy: 0.8373\n",
      "Epoch 78/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2768 - accuracy: 0.8817 - val_loss: 0.3491 - val_accuracy: 0.8373\n",
      "Epoch 79/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2886 - accuracy: 0.8775 - val_loss: 0.3471 - val_accuracy: 0.8406\n",
      "Epoch 80/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2787 - accuracy: 0.8823 - val_loss: 0.3490 - val_accuracy: 0.8427\n",
      "Epoch 81/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2770 - accuracy: 0.8826 - val_loss: 0.3310 - val_accuracy: 0.8535\n",
      "Epoch 82/100\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.2782 - accuracy: 0.8819 - val_loss: 0.3549 - val_accuracy: 0.8427\n",
      "Epoch 83/100\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.2770 - accuracy: 0.8797 - val_loss: 0.3646 - val_accuracy: 0.8366\n",
      "Epoch 84/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2786 - accuracy: 0.8792 - val_loss: 0.3527 - val_accuracy: 0.8413\n",
      "Epoch 85/100\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.2761 - accuracy: 0.8835 - val_loss: 0.3440 - val_accuracy: 0.8433\n",
      "Epoch 86/100\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.2696 - accuracy: 0.8825 - val_loss: 0.3477 - val_accuracy: 0.8427\n",
      "Epoch 87/100\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.2660 - accuracy: 0.8864 - val_loss: 0.4328 - val_accuracy: 0.8136\n",
      "Epoch 88/100\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.2691 - accuracy: 0.8851 - val_loss: 0.3307 - val_accuracy: 0.8467\n",
      "Epoch 89/100\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.2722 - accuracy: 0.8815 - val_loss: 0.3656 - val_accuracy: 0.8339\n",
      "Epoch 90/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2675 - accuracy: 0.8849 - val_loss: 0.3270 - val_accuracy: 0.8562\n",
      "Epoch 91/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2707 - accuracy: 0.8842 - val_loss: 0.3282 - val_accuracy: 0.8555\n",
      "Epoch 92/100\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.2570 - accuracy: 0.8889 - val_loss: 0.4458 - val_accuracy: 0.8082\n",
      "Epoch 93/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2602 - accuracy: 0.8906 - val_loss: 0.3290 - val_accuracy: 0.8575\n",
      "Epoch 94/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2607 - accuracy: 0.8896 - val_loss: 0.3233 - val_accuracy: 0.8656\n",
      "Epoch 95/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2591 - accuracy: 0.8892 - val_loss: 0.3436 - val_accuracy: 0.8474\n",
      "Epoch 96/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2586 - accuracy: 0.8893 - val_loss: 0.3507 - val_accuracy: 0.8488\n",
      "Epoch 97/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2537 - accuracy: 0.8953 - val_loss: 0.3324 - val_accuracy: 0.8494\n",
      "Epoch 98/100\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.2487 - accuracy: 0.8928 - val_loss: 0.3458 - val_accuracy: 0.8521\n",
      "Epoch 99/100\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2478 - accuracy: 0.8977 - val_loss: 0.3368 - val_accuracy: 0.8548\n",
      "Epoch 100/100\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.2435 - accuracy: 0.8957 - val_loss: 0.3236 - val_accuracy: 0.8548\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history = model.fit(\n",
    "    train, train_labels,\n",
    "    validation_data=(val, val_labels),\n",
    "    epochs=100,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be6944e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 1s 4ms/step - loss: 0.1922 - accuracy: 0.9294\n",
      "\n",
      "Test Accuracy of Celeb-DF on MesoNet: 92.94%\n",
      "340/340 [==============================] - 1s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      2961\n",
      "           1       0.95      0.95      0.95      7891\n",
      "\n",
      "    accuracy                           0.93     10852\n",
      "   macro avg       0.91      0.91      0.91     10852\n",
      "weighted avg       0.93      0.93      0.93     10852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test, test_labels)\n",
    "print(f'\\nTest Accuracy of Celeb-DF on MesoNet: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3466dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# After training the model\n",
    "model.save('mesonet_160_celeb.h5')  # Saves the entire model to a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7862e8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 3.5%\n",
      "RAM Used: 4857.9 MB\n",
      "Time Usage: 594.8 s\n",
      "GPU Memory Used: 2673.9 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01266c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 2s 4ms/step - loss: 0.1922 - accuracy: 0.9294\n",
      "Test Accuracy of Celeb-df on Meso NET: 92.94%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('mesonet_160_celeb.h5')\n",
    "test_loss, test_acc = model.evaluate(test, test_labels)\n",
    "print(f'Test Accuracy of Celeb-df on Meso NET: {test_acc * 100:.2f}%')\n",
    "# You can now use the model for testing or inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2b1e895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n",
      "340/340 [==============================] - 5s 4ms/step - loss: 0.1922 - accuracy: 0.9294\n",
      "Test Accuracy of Celeb-df on Meso NET: 92.94%\n",
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 3.1%\n",
      "RAM Used: 3732.7 MB\n",
      "Time Usage: 9.3 s\n",
      "GPU Memory Used: 795.1 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor.get_stats()\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('mesonet_160_celeb.h5')\n",
    "test_loss, test_acc = model.evaluate(test, test_labels)\n",
    "print(f'Test Accuracy of Celeb-df on Meso NET: {test_acc * 100:.2f}%')\n",
    "# You can now use the model for testing or inference\n",
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5348f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 3s 5ms/step - loss: 2.3804 - accuracy: 0.4853\n",
      "\n",
      "Test Accuracy of DFC on Meso NET from Celebdf: 48.53%\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.93      0.64      1500\n",
      "           1       0.36      0.04      0.07      1500\n",
      "\n",
      "    accuracy                           0.49      3000\n",
      "   macro avg       0.43      0.49      0.36      3000\n",
      "weighted avg       0.43      0.49      0.36      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('mesonet_160_celeb.h5')\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc= model.evaluate(test_hog, test_labels)\n",
    "print(f'\\nTest Accuracy of DFC on Meso NET from Celebdf: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test_hog)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbb933b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 1s 4ms/step - loss: 3.4890 - accuracy: 0.3454\n",
      "\n",
      "Test Accuracy of FF++ on Meso NET from Celebdf: 34.54%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('mesonet_160_celeb.h5')\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test_ff, test_labels_ff)\n",
    "print(f'\\nTest Accuracy of FF++ on Meso NET from Celebdf: {test_acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a768d8ae",
   "metadata": {},
   "source": [
    "# DFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5493048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celeb shape: (5000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (5000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "ffhq shape: (1000, 224, 224, 3), dtype: uint8\n",
      "celeb shape: (2500, 160, 160, 3), dtype: uint8\n",
      "ffhq shape: (2500, 160, 160, 3), dtype: uint8\n",
      "gdwct shape: (1000, 160, 160, 3), dtype: uint8\n",
      "attagan shape: (1000, 160, 160, 3), dtype: uint8\n",
      "stargan shape: (1000, 160, 160, 3), dtype: uint8\n",
      "stylegan2 shape: (1000, 160, 160, 3), dtype: uint8\n",
      "stylegan shape: (1000, 160, 160, 3), dtype: uint8\n",
      "celeb_train: 1750 images, celeb_test: 750 images\n",
      "ffhq_train: 1750 images, ffhq_test: 750 images\n",
      "attgan_train: 700 images, attgan_test: 300 images\n",
      "stargan_train: 700 images, stargan_test: 300 images\n",
      "gdwct_train: 700 images, gdwct_test: 300 images\n",
      "stylegan2_train: 700 images, stylegan2_test: 300 images\n",
      "stylegan_train: 700 images, stylegan_test: 300 images\n",
      "celeb_train: 1575 images, celeb_val: 175 images\n",
      "ffhq_train: 1575 images, ffhq_val: 175 images\n",
      "attgan_train: 630 images, attgan_val: 70 images\n",
      "stargan_train: 630 images, stargan_val: 70 images\n",
      "gdwct_train: 630 images, gdwct_val: 70 images\n",
      "stylegan2_train: 630 images, stylegan2_val: 70 images\n",
      "stylegan_train: 630 images, stylegan_val: 70 images\n",
      "Total train: 6300 images\n",
      "Total test: 3000 images\n",
      "Total val: 700 images\n",
      "Train Labels: 6300 \n",
      "Test Labels: 3000 \n",
      "Val Labels: 700 \n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "# Open the HDF5 file in read mode\n",
    "with h5py.File('D://thesis//dataset//deepfake dataset//resized_images.h5', 'r') as h5f:\n",
    "    # Access each dataset\n",
    "    celeb = np.array(h5f['celeb'])\n",
    "    ffhq = np.array(h5f['ffhq'])\n",
    "    gdwct = np.array(h5f['gdwct'])\n",
    "    attgan = np.array(h5f['attgan'])\n",
    "    stargan = np.array(h5f['stargan'])\n",
    "    stylegan2 = np.array(h5f['stylegan2'])\n",
    "    stylegan = np.array(h5f['stylegan'])\n",
    "\n",
    "# Now, 'celeb', 'ffhq', etc., are NumPy arrays containing your datasets\n",
    "print(f\"celeb shape: {celeb.shape}, dtype: {celeb.dtype}\")\n",
    "print(f\"ffhq shape: {ffhq.shape}, dtype: {ffhq.dtype}\")\n",
    "print(f\"ffhq shape: {gdwct.shape}, dtype: {gdwct.dtype}\")\n",
    "print(f\"ffhq shape: {attgan.shape}, dtype: {attgan.dtype}\")\n",
    "print(f\"ffhq shape: {stargan.shape}, dtype: {stargan.dtype}\")\n",
    "print(f\"ffhq shape: {stylegan2.shape}, dtype: {stylegan2.dtype}\")\n",
    "print(f\"ffhq shape: {stylegan.shape}, dtype: {stylegan.dtype}\")\n",
    "# Repeat for other datasets as needed\n",
    "import cv2\n",
    "# Function to resize images from (224, 224) to (160, 160)\n",
    "def resize_images(image_array, target_size=(160, 160)):\n",
    "    resized_images = np.array([cv2.resize(img, target_size) for img in image_array])\n",
    "    return resized_images\n",
    "\n",
    "celeb = resize_images(celeb, target_size=(160, 160))\n",
    "ffhq = resize_images(ffhq, target_size=(160, 160))\n",
    "gdwct = resize_images(gdwct, target_size=(160, 160))\n",
    "attgan = resize_images(attgan, target_size=(160, 160))\n",
    "stargan = resize_images(stargan, target_size=(160, 160))\n",
    "stylegan = resize_images(stargan, target_size=(160, 160))\n",
    "stylegan2 = resize_images(stylegan2, target_size=(160, 160))\n",
    "import random\n",
    "# Randomly select 2500 distinct images\n",
    "random_indices = random.sample(range(len(celeb)), 2500)  # Get 2500 random indices\n",
    "celeb = celeb[random_indices]  # Select the random subse\n",
    "\n",
    "import random\n",
    "# Randomly select 2500 distinct images\n",
    "random_indices = random.sample(range(len(ffhq)), 2500)  # Get 2500 random indices\n",
    "ffhq = ffhq[random_indices]  # Select the random subse\n",
    "print(f\"celeb shape: {celeb.shape}, dtype: {celeb.dtype}\")\n",
    "print(f\"ffhq shape: {ffhq.shape}, dtype: {ffhq.dtype}\")\n",
    "print(f\"gdwct shape: {gdwct.shape}, dtype: {gdwct.dtype}\")\n",
    "print(f\"attagan shape: {attgan.shape}, dtype: {attgan.dtype}\")\n",
    "print(f\"stargan shape: {stargan.shape}, dtype: {stargan.dtype}\")\n",
    "print(f\"stylegan2 shape: {stylegan2.shape}, dtype: {stylegan2.dtype}\")\n",
    "print(f\"stylegan shape: {stylegan.shape}, dtype: {stylegan.dtype}\")\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def split_data(data, train_ratio=0.7):\n",
    "    \"\"\"\n",
    "    Splits data into training and testing sets based on the specified ratio.\n",
    "\n",
    "    Parameters:\n",
    "        data (list or np.array): The dataset to split.\n",
    "        train_ratio (float): The ratio of the data to include in the training set.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two datasets - train and test.\n",
    "    \"\"\"\n",
    "    # Shuffle the data\n",
    "    random.shuffle(data)\n",
    "\n",
    "    # Calculate the split index\n",
    "    split_index = int(len(data) * train_ratio)\n",
    "\n",
    "    # Split the data\n",
    "    train_data = data[:split_index]\n",
    "    test_data = data[split_index:]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "# Split `celeb` into 70% train and 30% test\n",
    "celeb_train_hog, celeb_test_hog = split_data(celeb, train_ratio=0.7)\n",
    "\n",
    "# Split `ffhq` into 70% train and 30% test\n",
    "ffhq_train_hog, ffhq_test_hog = split_data(ffhq, train_ratio=0.7)\n",
    "\n",
    "# Split `attgan` into 70% train and 30% test\n",
    "attgan_train_hog, attgan_test_hog = split_data(attgan, train_ratio=0.7)\n",
    "\n",
    "# Split `stargan` into 70% train and 30% test\n",
    "stargan_train_hog, stargan_test_hog = split_data(stargan, train_ratio=0.7)\n",
    "\n",
    "# Split `gdwct` into 70% train and 30% test\n",
    "gdwct_train_hog, gdwct_test_hog = split_data(gdwct, train_ratio=0.7)\n",
    "\n",
    "# Split `stylegan2` into 70% train and 30% test_hog\n",
    "stylegan2_train_hog, stylegan2_test_hog = split_data(stylegan2, train_ratio=0.7)\n",
    "\n",
    "# Split `stylegan` into 70% train and 30% test_hog\n",
    "stylegan_train_hog, stylegan_test_hog = split_data(stylegan, train_ratio=0.7)\n",
    "\n",
    "# Convert to NumPy arrays if needed\n",
    "celeb_train_hog, celeb_test_hog = np.array(celeb_train_hog), np.array(celeb_test_hog)\n",
    "ffhq_train_hog, ffhq_test_hog = np.array(ffhq_train_hog), np.array(ffhq_test_hog)\n",
    "attgan_train_hog, attgan_test_hog = np.array(attgan_train_hog), np.array(attgan_test_hog)\n",
    "stargan_train_hog, stargan_test_hog = np.array(stargan_train_hog), np.array(stargan_test_hog)\n",
    "gdwct_train_hog, gdwct_test_hog = np.array(gdwct_train_hog), np.array(gdwct_test_hog)\n",
    "stylegan2_train_hog, stylegan2_test_hog = np.array(stylegan2_train_hog), np.array(stylegan2_test_hog)\n",
    "stylegan_train_hog, stylegan_test_hog = np.array(stylegan_train_hog), np.array(stylegan_test_hog)\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"celeb_train: {len(celeb_train_hog)} images, celeb_test: {len(celeb_test_hog)} images\")\n",
    "print(f\"ffhq_train: {len(ffhq_train_hog)} images, ffhq_test: {len(ffhq_test_hog)} images\")\n",
    "print(f\"attgan_train: {len(attgan_train_hog)} images, attgan_test: {len(attgan_test_hog)} images\")\n",
    "print(f\"stargan_train: {len(stargan_train_hog)} images, stargan_test: {len(stargan_test_hog)} images\")\n",
    "print(f\"gdwct_train: {len(gdwct_train_hog)} images, gdwct_test: {len(gdwct_test_hog)} images\")\n",
    "print(f\"stylegan2_train: {len(stylegan2_train_hog)} images, stylegan2_test: {len(stylegan2_test_hog)} images\")\n",
    "print(f\"stylegan_train: {len(stylegan_train_hog)} images, stylegan_test: {len(stylegan_test_hog)} images\")\n",
    "\n",
    "########################################################################################################################################\n",
    "#######################################divide into 60,10 train and val\n",
    "#########################################################################################################################################\n",
    "def extract_validation(train_data):\n",
    "    \"\"\"\n",
    "    Extract every 10th sample from the training data and store it in a validation set.\n",
    "\n",
    "    Parameters:\n",
    "        train_data (list or np.array): The training dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated training dataset and validation dataset.\n",
    "    \"\"\"\n",
    "    # Select every 10th sample for the validation set\n",
    "    validation_data = train_data[::10]\n",
    "\n",
    "    # Remove the selected samples from the training dataset\n",
    "    updated_train_data = [train_data[i] for i in range(len(train_data)) if i % 10 != 0]\n",
    "\n",
    "    return np.array(updated_train_data), np.array(validation_data)\n",
    "\n",
    "\n",
    "# Perform the operation for each dataset\n",
    "celeb_train_hog, celeb_val_hog = extract_validation(celeb_train_hog)\n",
    "ffhq_train_hog, ffhq_val_hog = extract_validation(ffhq_train_hog)\n",
    "attgan_train_hog, attgan_val_hog = extract_validation(attgan_train_hog)\n",
    "stargan_train_hog, stargan_val_hog = extract_validation(stargan_train_hog)\n",
    "gdwct_train_hog, gdwct_val_hog = extract_validation(gdwct_train_hog)\n",
    "stylegan2_train_hog, stylegan2_val_hog = extract_validation(stylegan2_train_hog)\n",
    "stylegan_train_hog, stylegan_val_hog = extract_validation(stylegan_train_hog)\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"celeb_train: {len(celeb_train_hog)} images, celeb_val: {len(celeb_val_hog)} images\")\n",
    "print(f\"ffhq_train: {len(ffhq_train_hog)} images, ffhq_val: {len(ffhq_val_hog)} images\")\n",
    "print(f\"attgan_train: {len(attgan_train_hog)} images, attgan_val: {len(attgan_val_hog)} images\")\n",
    "print(f\"stargan_train: {len(stargan_train_hog)} images, stargan_val: {len(stargan_val_hog)} images\")\n",
    "print(f\"gdwct_train: {len(gdwct_train_hog)} images, gdwct_val: {len(gdwct_val_hog)} images\")\n",
    "print(f\"stylegan2_train: {len(stylegan2_train_hog)} images, stylegan2_val: {len(stylegan2_val_hog)} images\")\n",
    "print(f\"stylegan_train: {len(stylegan_train_hog)} images, stylegan_val: {len(stylegan_val_hog)} images\")\n",
    "############################################################################################################################################################\n",
    "#################################################concatenate the labels 0,1 real and fake\n",
    "#############################################################################################################################################################\n",
    "\n",
    "\n",
    "celeb_train_labels = np.zeros(len(celeb_train_hog), dtype=int)\n",
    "ffhq_train_labels = np.zeros(len(ffhq_train_hog), dtype=int)\n",
    "atta_train_labels = np.ones(len(attgan_train_hog), dtype=int)\n",
    "star_train_labels = np.ones(len(stargan_train_hog), dtype=int)\n",
    "gdwct_train_labels = np.ones(len(gdwct_train_hog), dtype=int)\n",
    "stylegan2_train_labels = np.ones(len(stylegan2_train_hog), dtype=int)\n",
    "stylegan_train_labels = np.ones(len(stylegan_train_hog), dtype=int)\n",
    "\n",
    "# Concatenate all training datasets into a single `train` variable\n",
    "train_hog = np.concatenate([celeb_train_hog, ffhq_train_hog, attgan_train_hog, stargan_train_hog, gdwct_train_hog, stylegan2_train_hog, stylegan_train_hog], axis=0)\n",
    "train_labels=np.concatenate([celeb_train_labels, ffhq_train_labels, atta_train_labels, star_train_labels, gdwct_train_labels, stylegan2_train_labels,\n",
    "                              stylegan_train_labels], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "celeb_test_labels = np.zeros(len(celeb_test_hog), dtype=int)\n",
    "ffhq_test_labels = np.zeros(len(ffhq_test_hog), dtype=int)\n",
    "atta_test_labels = np.ones(len(attgan_test_hog), dtype=int)\n",
    "star_test_labels = np.ones(len(stargan_test_hog), dtype=int)\n",
    "gdwct_test_labels = np.ones(len(gdwct_test_hog), dtype=int)\n",
    "stylegan2_test_labels = np.ones(len(stylegan2_test_hog), dtype=int)\n",
    "stylegan_test_labels = np.ones(len(stylegan_test_hog), dtype=int)\n",
    "\n",
    "# Concatenate all testing datasets into a single `test` variable\n",
    "test_hog = np.concatenate([celeb_test_hog, ffhq_test_hog, attgan_test_hog, stargan_test_hog, gdwct_test_hog, stylegan2_test_hog, stylegan_test_hog], axis=0)\n",
    "test_labels = np.concatenate([celeb_test_labels, ffhq_test_labels, atta_test_labels, star_test_labels, gdwct_test_labels, stylegan2_test_labels,\n",
    "                        stylegan_test_labels], axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "celeb_val_labels = np.zeros(len(celeb_val_hog), dtype=int)\n",
    "ffhq_val_labels = np.zeros(len(ffhq_val_hog), dtype=int)\n",
    "atta_val_labels = np.ones(len(attgan_val_hog), dtype=int)\n",
    "star_val_labels = np.ones(len(stargan_val_hog), dtype=int)\n",
    "gdwct_val_labels = np.ones(len(gdwct_val_hog), dtype=int)\n",
    "stylegan2_val_labels = np.ones(len(stylegan2_val_hog), dtype=int)\n",
    "stylegan_val_labels = np.ones(len(stylegan_val_hog), dtype=int)\n",
    "\n",
    "# Concatenate all validation datasets into a single `val` variable\n",
    "val_hog = np.concatenate([celeb_val_hog, ffhq_val_hog, attgan_val_hog, stargan_val_hog, gdwct_val_hog, stylegan2_val_hog, stylegan_val_hog], axis=0)\n",
    "val_labels = np.concatenate([celeb_val_labels, ffhq_val_labels, atta_val_labels, star_val_labels, gdwct_val_labels, stylegan2_val_labels,\n",
    "                       stylegan_val_labels], axis=0)\n",
    "\n",
    "# Print the results for verification\n",
    "print(f\"Total train: {len(train_hog)} images\")\n",
    "print(f\"Total test: {len(test_hog)} images\")\n",
    "print(f\"Total val: {len(val_hog)} images\")\n",
    "\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"Train Labels: {len(train_labels)} \")\n",
    "print(f\"Test Labels: {len(test_labels)} \")\n",
    "print(f\"Val Labels: {len(val_labels)} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c9a640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "197/197 [==============================] - 6s 13ms/step - loss: 1.0595 - accuracy: 0.5481 - val_loss: 0.7790 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.7479 - accuracy: 0.6032 - val_loss: 0.7396 - val_accuracy: 0.5057\n",
      "Epoch 3/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.6662 - accuracy: 0.6497 - val_loss: 0.6394 - val_accuracy: 0.6257\n",
      "Epoch 4/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.6238 - accuracy: 0.6789 - val_loss: 0.5569 - val_accuracy: 0.7271\n",
      "Epoch 5/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.5801 - accuracy: 0.7086 - val_loss: 0.5257 - val_accuracy: 0.7600\n",
      "Epoch 6/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.5595 - accuracy: 0.7289 - val_loss: 0.5082 - val_accuracy: 0.7829\n",
      "Epoch 7/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.5384 - accuracy: 0.7395 - val_loss: 0.4973 - val_accuracy: 0.7700\n",
      "Epoch 8/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.5168 - accuracy: 0.7544 - val_loss: 0.4715 - val_accuracy: 0.7957\n",
      "Epoch 9/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.5084 - accuracy: 0.7654 - val_loss: 0.4556 - val_accuracy: 0.8214\n",
      "Epoch 10/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.4760 - accuracy: 0.7790 - val_loss: 0.4407 - val_accuracy: 0.8114\n",
      "Epoch 11/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.4667 - accuracy: 0.7833 - val_loss: 0.4345 - val_accuracy: 0.8157\n",
      "Epoch 12/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.4500 - accuracy: 0.7952 - val_loss: 0.4070 - val_accuracy: 0.8200\n",
      "Epoch 13/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.4233 - accuracy: 0.8135 - val_loss: 0.3843 - val_accuracy: 0.8443\n",
      "Epoch 14/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.3971 - accuracy: 0.8251 - val_loss: 0.3716 - val_accuracy: 0.8400\n",
      "Epoch 15/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.3830 - accuracy: 0.8327 - val_loss: 0.3610 - val_accuracy: 0.8386\n",
      "Epoch 16/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.3669 - accuracy: 0.8406 - val_loss: 0.3388 - val_accuracy: 0.8600\n",
      "Epoch 17/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.3475 - accuracy: 0.8525 - val_loss: 0.3348 - val_accuracy: 0.8543\n",
      "Epoch 18/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.3291 - accuracy: 0.8610 - val_loss: 0.3327 - val_accuracy: 0.8529\n",
      "Epoch 19/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.3151 - accuracy: 0.8663 - val_loss: 0.2938 - val_accuracy: 0.8871\n",
      "Epoch 20/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.2891 - accuracy: 0.8775 - val_loss: 0.2803 - val_accuracy: 0.8986\n",
      "Epoch 21/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.2865 - accuracy: 0.8852 - val_loss: 0.2771 - val_accuracy: 0.9000\n",
      "Epoch 22/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.2681 - accuracy: 0.8921 - val_loss: 0.2515 - val_accuracy: 0.9100\n",
      "Epoch 23/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.2573 - accuracy: 0.8948 - val_loss: 0.2534 - val_accuracy: 0.9043\n",
      "Epoch 24/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.2428 - accuracy: 0.9002 - val_loss: 0.2700 - val_accuracy: 0.8929\n",
      "Epoch 25/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.2232 - accuracy: 0.9121 - val_loss: 0.2231 - val_accuracy: 0.9229\n",
      "Epoch 26/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.2187 - accuracy: 0.9117 - val_loss: 0.2462 - val_accuracy: 0.9100\n",
      "Epoch 27/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.2101 - accuracy: 0.9187 - val_loss: 0.2178 - val_accuracy: 0.9257\n",
      "Epoch 28/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.2079 - accuracy: 0.9159 - val_loss: 0.2008 - val_accuracy: 0.9243\n",
      "Epoch 29/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.1953 - accuracy: 0.9205 - val_loss: 0.1832 - val_accuracy: 0.9386\n",
      "Epoch 30/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.1907 - accuracy: 0.9260 - val_loss: 0.1928 - val_accuracy: 0.9314\n",
      "Epoch 31/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.1748 - accuracy: 0.9333 - val_loss: 0.1800 - val_accuracy: 0.9386\n",
      "Epoch 32/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.1746 - accuracy: 0.9314 - val_loss: 0.1704 - val_accuracy: 0.9457\n",
      "Epoch 33/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.1641 - accuracy: 0.9332 - val_loss: 0.1670 - val_accuracy: 0.9457\n",
      "Epoch 34/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.1608 - accuracy: 0.9343 - val_loss: 0.1632 - val_accuracy: 0.9529\n",
      "Epoch 35/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.1512 - accuracy: 0.9387 - val_loss: 0.1656 - val_accuracy: 0.9486\n",
      "Epoch 36/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.1478 - accuracy: 0.9422 - val_loss: 0.1584 - val_accuracy: 0.9471\n",
      "Epoch 37/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.1533 - accuracy: 0.9408 - val_loss: 0.1445 - val_accuracy: 0.9571\n",
      "Epoch 38/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.1460 - accuracy: 0.9443 - val_loss: 0.1469 - val_accuracy: 0.9614\n",
      "Epoch 39/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.1305 - accuracy: 0.9492 - val_loss: 0.1540 - val_accuracy: 0.9557\n",
      "Epoch 40/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.1313 - accuracy: 0.9495 - val_loss: 0.1453 - val_accuracy: 0.9543\n",
      "Epoch 41/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.1289 - accuracy: 0.9519 - val_loss: 0.1316 - val_accuracy: 0.9586\n",
      "Epoch 42/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.1217 - accuracy: 0.9540 - val_loss: 0.1402 - val_accuracy: 0.9600\n",
      "Epoch 43/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.1170 - accuracy: 0.9568 - val_loss: 0.1225 - val_accuracy: 0.9629\n",
      "Epoch 44/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.1208 - accuracy: 0.9551 - val_loss: 0.1579 - val_accuracy: 0.9414\n",
      "Epoch 45/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.1137 - accuracy: 0.9546 - val_loss: 0.1348 - val_accuracy: 0.9529\n",
      "Epoch 46/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.1059 - accuracy: 0.9614 - val_loss: 0.1233 - val_accuracy: 0.9571\n",
      "Epoch 47/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.1050 - accuracy: 0.9587 - val_loss: 0.1156 - val_accuracy: 0.9686\n",
      "Epoch 48/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.1019 - accuracy: 0.9621 - val_loss: 0.1268 - val_accuracy: 0.9586\n",
      "Epoch 49/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.0978 - accuracy: 0.9638 - val_loss: 0.1494 - val_accuracy: 0.9529\n",
      "Epoch 50/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.1019 - accuracy: 0.9621 - val_loss: 0.1071 - val_accuracy: 0.9686\n",
      "Epoch 51/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.0924 - accuracy: 0.9649 - val_loss: 0.1169 - val_accuracy: 0.9686\n",
      "Epoch 52/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0876 - accuracy: 0.9684 - val_loss: 0.0982 - val_accuracy: 0.9700\n",
      "Epoch 53/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0849 - accuracy: 0.9689 - val_loss: 0.1192 - val_accuracy: 0.9614\n",
      "Epoch 54/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0916 - accuracy: 0.9648 - val_loss: 0.0937 - val_accuracy: 0.9757\n",
      "Epoch 55/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.0824 - accuracy: 0.9710 - val_loss: 0.1079 - val_accuracy: 0.9671\n",
      "Epoch 56/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0876 - accuracy: 0.9643 - val_loss: 0.1053 - val_accuracy: 0.9714\n",
      "Epoch 57/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.0776 - accuracy: 0.9732 - val_loss: 0.1011 - val_accuracy: 0.9643\n",
      "Epoch 58/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.0747 - accuracy: 0.9732 - val_loss: 0.0928 - val_accuracy: 0.9729\n",
      "Epoch 59/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0702 - accuracy: 0.9754 - val_loss: 0.0902 - val_accuracy: 0.9714\n",
      "Epoch 60/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0733 - accuracy: 0.9727 - val_loss: 0.0933 - val_accuracy: 0.9729\n",
      "Epoch 61/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0687 - accuracy: 0.9754 - val_loss: 0.0944 - val_accuracy: 0.9757\n",
      "Epoch 62/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0671 - accuracy: 0.9729 - val_loss: 0.0989 - val_accuracy: 0.9757\n",
      "Epoch 63/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0636 - accuracy: 0.9783 - val_loss: 0.0993 - val_accuracy: 0.9757\n",
      "Epoch 64/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0673 - accuracy: 0.9756 - val_loss: 0.1050 - val_accuracy: 0.9743\n",
      "Epoch 65/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0644 - accuracy: 0.9759 - val_loss: 0.1123 - val_accuracy: 0.9671\n",
      "Epoch 66/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0610 - accuracy: 0.9781 - val_loss: 0.0939 - val_accuracy: 0.9729\n",
      "Epoch 67/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0622 - accuracy: 0.9770 - val_loss: 0.1116 - val_accuracy: 0.9714\n",
      "Epoch 68/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.0578 - accuracy: 0.9787 - val_loss: 0.0951 - val_accuracy: 0.9771\n",
      "Epoch 69/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0556 - accuracy: 0.9803 - val_loss: 0.1024 - val_accuracy: 0.9714\n",
      "Epoch 70/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.0574 - accuracy: 0.9783 - val_loss: 0.0926 - val_accuracy: 0.9757\n",
      "Epoch 71/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.0535 - accuracy: 0.9795 - val_loss: 0.1051 - val_accuracy: 0.9743\n",
      "Epoch 72/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0563 - accuracy: 0.9775 - val_loss: 0.0952 - val_accuracy: 0.9743\n",
      "Epoch 73/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0499 - accuracy: 0.9816 - val_loss: 0.0855 - val_accuracy: 0.9743\n",
      "Epoch 74/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0454 - accuracy: 0.9843 - val_loss: 0.0906 - val_accuracy: 0.9743\n",
      "Epoch 75/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0479 - accuracy: 0.9821 - val_loss: 0.0941 - val_accuracy: 0.9729\n",
      "Epoch 76/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0521 - accuracy: 0.9802 - val_loss: 0.0933 - val_accuracy: 0.9743\n",
      "Epoch 77/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0513 - accuracy: 0.9802 - val_loss: 0.0859 - val_accuracy: 0.9771\n",
      "Epoch 78/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0492 - accuracy: 0.9816 - val_loss: 0.0914 - val_accuracy: 0.9729\n",
      "Epoch 79/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0483 - accuracy: 0.9816 - val_loss: 0.0881 - val_accuracy: 0.9757\n",
      "Epoch 80/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0414 - accuracy: 0.9849 - val_loss: 0.0975 - val_accuracy: 0.9729\n",
      "Epoch 81/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0417 - accuracy: 0.9838 - val_loss: 0.1120 - val_accuracy: 0.9700\n",
      "Epoch 82/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0496 - accuracy: 0.9814 - val_loss: 0.0880 - val_accuracy: 0.9743\n",
      "Epoch 83/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0400 - accuracy: 0.9860 - val_loss: 0.0813 - val_accuracy: 0.9786\n",
      "Epoch 84/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.0413 - accuracy: 0.9844 - val_loss: 0.0951 - val_accuracy: 0.9771\n",
      "Epoch 85/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0390 - accuracy: 0.9851 - val_loss: 0.0987 - val_accuracy: 0.9757\n",
      "Epoch 86/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0442 - accuracy: 0.9852 - val_loss: 0.0964 - val_accuracy: 0.9771\n",
      "Epoch 87/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0436 - accuracy: 0.9838 - val_loss: 0.1024 - val_accuracy: 0.9757\n",
      "Epoch 88/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.0405 - accuracy: 0.9849 - val_loss: 0.1008 - val_accuracy: 0.9743\n",
      "Epoch 89/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.0369 - accuracy: 0.9867 - val_loss: 0.0899 - val_accuracy: 0.9771\n",
      "Epoch 90/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.0346 - accuracy: 0.9881 - val_loss: 0.0854 - val_accuracy: 0.9786\n",
      "Epoch 91/100\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.0386 - accuracy: 0.9862 - val_loss: 0.0950 - val_accuracy: 0.9771\n",
      "Epoch 92/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0407 - accuracy: 0.9854 - val_loss: 0.0917 - val_accuracy: 0.9814\n",
      "Epoch 93/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0357 - accuracy: 0.9865 - val_loss: 0.0887 - val_accuracy: 0.9786\n",
      "Epoch 94/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0380 - accuracy: 0.9859 - val_loss: 0.0977 - val_accuracy: 0.9757\n",
      "Epoch 95/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0342 - accuracy: 0.9876 - val_loss: 0.1031 - val_accuracy: 0.9800\n",
      "Epoch 96/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0392 - accuracy: 0.9849 - val_loss: 0.0945 - val_accuracy: 0.9714\n",
      "Epoch 97/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0338 - accuracy: 0.9881 - val_loss: 0.0976 - val_accuracy: 0.9757\n",
      "Epoch 98/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0306 - accuracy: 0.9876 - val_loss: 0.1041 - val_accuracy: 0.9800\n",
      "Epoch 99/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0342 - accuracy: 0.9871 - val_loss: 0.0886 - val_accuracy: 0.9814\n",
      "Epoch 100/100\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.0385 - accuracy: 0.9876 - val_loss: 0.1092 - val_accuracy: 0.9757\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_hog, train_labels,\n",
    "    validation_data=(val_hog, val_labels),\n",
    "    epochs=100,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57f67017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 4ms/step - loss: 0.2040 - accuracy: 0.9393\n",
      "\n",
      "Test Accuracy of DFC on MESONet: 93.93%\n",
      "94/94 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      1500\n",
      "           1       0.96      0.92      0.94      1500\n",
      "\n",
      "    accuracy                           0.94      3000\n",
      "   macro avg       0.94      0.94      0.94      3000\n",
      "weighted avg       0.94      0.94      0.94      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test_hog, test_labels)\n",
    "print(f'\\nTest Accuracy of DFC on MESONet: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test_hog)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b46fb48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# After training the model\n",
    "model.save('mesonet_160_dfc.h5')  # Saves the entire model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c23af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 10.7%\n",
      "RAM Used: 4591.6 MB\n",
      "Time Usage: 252.1 s\n",
      "GPU Memory Used: 768.3 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3c1caf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 1s 4ms/step - loss: 0.2040 - accuracy: 0.9393\n",
      "Test Accuracy of DFC on MESONET: 93.93%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('mesonet_160_dfc.h5')\n",
    "test_loss, test_acc = model.evaluate(test_hog, test_labels)\n",
    "print(f'Test Accuracy of DFC on MESONET: {test_acc * 100:.2f}%')\n",
    "# You can now use the model for testing or inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a80767c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n",
      "94/94 [==============================] - 4s 5ms/step - loss: 0.2824 - accuracy: 0.9277\n",
      "Test Accuracy of DFC on MESONET: 92.77%\n",
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 4.6%\n",
      "RAM Used: 3313.5 MB\n",
      "Time Usage: 7.3 s\n",
      "GPU Memory Used: 220.0 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor.get_stats()\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('mesonet_160_dfc.h5')\n",
    "test_loss, test_acc = model.evaluate(test_hog, test_labels)\n",
    "print(f'Test Accuracy of DFC on MESONET: {test_acc * 100:.2f}%')\n",
    "# You can now use the model for testing or inference\n",
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ce74377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 1s 4ms/step - loss: 1.4338 - accuracy: 0.5364\n",
      "\n",
      "Test Accuracy of Celeb-df dataset on MESONET for DFC: 53.64%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('mesonet_160_dfc.h5')\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test, test_labels)\n",
    "print(f'\\nTest Accuracy of Celeb-df dataset on MESONET for DFC: {test_acc*100:.2f}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afe2f30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 3s 4ms/step - loss: 2.7172 - accuracy: 0.4006\n",
      "\n",
      "Test Accuracy of FF++ on MESONET from DFC: 40.06%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('mesonet_160_dfc.h5')\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test_ff, test_labels_ff)\n",
    "print(f'\\nTest Accuracy of FF++ on MESONET from DFC: {test_acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4709c6",
   "metadata": {},
   "source": [
    "# FF++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca9f7307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from the HDF5 file.\n",
      "Data loaded successfully from the HDF5 file.\n",
      "Data loaded successfully from the HDF5 file.\n",
      "Data loaded successfully from the HDF5 file.\n",
      "Shape of the concatenated array: (2808, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (3299, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (2083, 160, 160, 3)\n",
      "Shape of the concatenated array: (1742, 160, 160, 3)\n",
      "Shape of the concatenated array: (1742, 160, 160, 3)\n",
      "Training data ACTOR real shape: (1965, 160, 160, 3) Testing real data shape: (843, 160, 160, 3)\n",
      "Training data Youtube real shape: (1458, 160, 160, 3) Testing real data shape: (625, 160, 160, 3)\n",
      "Training data DFD fake shape: (2309, 160, 160, 3) Testing fake data shape: (990, 160, 160, 3)\n",
      "Training data DF fake shape: (1458, 160, 160, 3) Testing fake data shape: (625, 160, 160, 3)\n",
      "Training data f2f fake shape: (1458, 160, 160, 3) Testing fake data shape: (625, 160, 160, 3)\n",
      "Training data fshifter fake shape: (1458, 160, 160, 3) Testing fake data shape: (625, 160, 160, 3)\n",
      "Training data fswap fake shape: (1219, 160, 160, 3) Testing fake data shape: (523, 160, 160, 3)\n",
      "Training data nt fake shape: (1219, 160, 160, 3) Testing fake data shape: (523, 160, 160, 3)\n",
      "train_ori_actor hog_real: 1768 images, val_ori_actor hog_real: 197 images\n",
      "train_ ori_youtube hog_real: 1312 images, val_ ori_youtube hog_real: 146 images\n",
      "train_hog_mni_dfd_fake: 2078 images, val_hog_mni_dfd_fake: 231 images\n",
      "train_hog_mni_df_fake: 1312 images, val_hog_mni_df_fake: 146 images\n",
      "train_hog_mni_f2f_fake: 1312 images, val_hog_mni_f2f_fake: 146 images\n",
      "train_hog_mni_fshifter_fake: 1312 images, val_hog_mni_fshifter_fake: 146 images\n",
      "train_hog_mni_fswap_fake: 1097 images, val_hog_mni_fswap_fake: 122 images\n",
      "train_hog_mni_nt_fake: 1097 images, val_hog_mni_nt_fake: 122 images\n",
      "Total train: 11288 images, and shape:(11288, 160, 160, 3)\n",
      "Total test: 5379 images, and shape:(5379, 160, 160, 3)\n",
      "Total val: 1256 images, and shape:(1256, 160, 160, 3)\n",
      "Train Labels: 11288 \n",
      "Test Labels: 5379 \n",
      "Val Labels: 1256 \n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "# Open the HDF5 file for reading\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_orignal_processed.h5\", \"r\") as h5f:\n",
    "    org_seq_actor_array = h5f[\"ori_actor\"][:]\n",
    "    org_seq_youtube_array = h5f[\"ori_youtube\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_fake1_processed.h5\", \"r\") as h5f:\n",
    "    meni_seq_dfd_array = h5f[\"mni_dfd\"][:]\n",
    "    meni_seq_df_array = h5f[\"mni_df\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_fake2_processed.h5\", \"r\") as h5f:\n",
    "    meni_seq_f2f_array = h5f[\"mni_f2f\"][:]\n",
    "    meni_seq_fshifter_array = h5f[\"mni_fshifter\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "with h5py.File(\"D://thesis//dataset//ff++//images_ff++_fake3_processed.h5\", \"r\") as h5f:\n",
    "    meni_seq_fswap_array = h5f[\"mni_fswap\"][:]\n",
    "    meni_seq_nt_array = h5f[\"mni_nt\"][:]\n",
    "print(\"Data loaded successfully from the HDF5 file.\")\n",
    "# Output the shape of the resulting array\n",
    "print(f\"Shape of the concatenated array: {org_seq_actor_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {org_seq_youtube_array.shape}\")\n",
    "\n",
    "print(f\"Shape of the concatenated array: {meni_seq_dfd_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_df_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_fshifter_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_f2f_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_fswap_array.shape}\")\n",
    "print(f\"Shape of the concatenated array: {meni_seq_nt_array.shape}\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ori_actor_train_real, ori_actor_test_real = train_test_split(org_seq_actor_array, test_size=0.3, random_state=42)\n",
    "ori_youtube_train_real, ori_youtube_test_real = train_test_split(org_seq_youtube_array, test_size=0.3, random_state=42)\n",
    "# Split the data into train (70%) and test (30%)\n",
    "mni_dfd_train_fake, mni_dfd_test_fake = train_test_split(meni_seq_dfd_array, test_size=0.3, random_state=42)\n",
    "mni_df_train_fake, mni_df_test_fake = train_test_split(meni_seq_df_array, test_size=0.3, random_state=42)\n",
    "mni_f2f_train_fake, mni_f2f_test_fake = train_test_split(meni_seq_f2f_array, test_size=0.3, random_state=42)\n",
    "mni_fshifter_train_fake, mni_fshifter_test_fake = train_test_split(meni_seq_fshifter_array, test_size=0.3, random_state=42)\n",
    "mni_fswap_train_fake, mni_fswap_test_fake = train_test_split(meni_seq_fswap_array, test_size=0.3, random_state=42)\n",
    "mni_nt_train_fake, mni_nt_test_fake = train_test_split(meni_seq_nt_array, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Output the shape to confirm the split dimensions\n",
    "print(\"Training data ACTOR real shape:\", ori_actor_train_real.shape, \"Testing real data shape:\", ori_actor_test_real.shape)\n",
    "print(\"Training data Youtube real shape:\", ori_youtube_train_real.shape, \"Testing real data shape:\", ori_youtube_test_real.shape)\n",
    "\n",
    "print(\"Training data DFD fake shape:\", mni_dfd_train_fake.shape, \"Testing fake data shape:\", mni_dfd_test_fake.shape)\n",
    "print(\"Training data DF fake shape:\", mni_df_train_fake.shape, \"Testing fake data shape:\", mni_df_test_fake.shape)\n",
    "print(\"Training data f2f fake shape:\", mni_f2f_train_fake.shape, \"Testing fake data shape:\", mni_f2f_test_fake.shape)\n",
    "print(\"Training data fshifter fake shape:\", mni_fshifter_train_fake.shape, \"Testing fake data shape:\", mni_fshifter_test_fake.shape)\n",
    "print(\"Training data fswap fake shape:\", mni_fswap_train_fake.shape, \"Testing fake data shape:\", mni_fswap_test_fake.shape)\n",
    "print(\"Training data nt fake shape:\", mni_nt_train_fake.shape, \"Testing fake data shape:\", mni_nt_test_fake.shape)\n",
    "########################################################################################################################################\n",
    "#######################################divide into 60,10 train and val\n",
    "#########################################################################################################################################\n",
    "def extract_validation(train_data):\n",
    "    \"\"\"\n",
    "    Extract every 10th sample from the training data and store it in a validation set.\n",
    "\n",
    "    Parameters:\n",
    "        train_data (list or np.array): The training dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Updated training dataset and validation dataset.\n",
    "    \"\"\"\n",
    "    # Select every 10th sample for the validation set\n",
    "    validation_data = train_data[::10]\n",
    "\n",
    "    # Remove the selected samples from the training dataset\n",
    "    updated_train_data = [train_data[i] for i in range(len(train_data)) if i % 10 != 0]\n",
    "\n",
    "    return np.array(updated_train_data), np.array(validation_data)\n",
    "\n",
    "\n",
    "# Perform the operation for each dataset\n",
    "train_hog_ori_actor_real, val_hog_ori_actor_real = extract_validation(ori_actor_train_real)\n",
    "train_hog_ori_youtube_real, val_hog_ori_youtube_real = extract_validation(ori_youtube_train_real)\n",
    "train_hog_mni_dfd_fake, val_hog_mni_dfd_fake = extract_validation(mni_dfd_train_fake)\n",
    "train_hog_mni_df_fake, val_hog_mni_df_fake = extract_validation(mni_df_train_fake)\n",
    "train_hog_mni_f2f_fake, val_hog_mni_f2f_fake = extract_validation(mni_f2f_train_fake)\n",
    "train_hog_mni_fshifter_fake, val_hog_mni_fshifter_fake = extract_validation(mni_fshifter_train_fake)\n",
    "train_hog_mni_fswap_fake, val_hog_mni_fswap_fake = extract_validation(mni_fswap_train_fake)\n",
    "train_hog_mni_nt_fake, val_hog_mni_nt_fake = extract_validation(mni_nt_train_fake)\n",
    "# Print results for verification\n",
    "print(f\"train_ori_actor hog_real: {len(train_hog_ori_actor_real)} images, val_ori_actor hog_real: {len(val_hog_ori_actor_real)} images\")\n",
    "print(f\"train_ ori_youtube hog_real: {len(train_hog_ori_youtube_real)} images, val_ ori_youtube hog_real: {len(val_hog_ori_youtube_real)} images\")\n",
    "print(f\"train_hog_mni_dfd_fake: {len(train_hog_mni_dfd_fake)} images, val_hog_mni_dfd_fake: {len(val_hog_mni_dfd_fake)} images\")\n",
    "print(f\"train_hog_mni_df_fake: {len(train_hog_mni_df_fake)} images, val_hog_mni_df_fake: {len(val_hog_mni_df_fake)} images\")\n",
    "print(f\"train_hog_mni_f2f_fake: {len(train_hog_mni_f2f_fake)} images, val_hog_mni_f2f_fake: {len(val_hog_mni_f2f_fake)} images\")\n",
    "print(f\"train_hog_mni_fshifter_fake: {len(train_hog_mni_fshifter_fake)} images, val_hog_mni_fshifter_fake: {len(val_hog_mni_fshifter_fake)} images\")\n",
    "print(f\"train_hog_mni_fswap_fake: {len(train_hog_mni_fswap_fake)} images, val_hog_mni_fswap_fake: {len(val_hog_mni_fswap_fake)} images\")\n",
    "print(f\"train_hog_mni_nt_fake: {len(train_hog_mni_nt_fake)} images, val_hog_mni_nt_fake: {len(val_hog_mni_nt_fake)} images\")\n",
    "############################################################################################################################################################\n",
    "#################################################concatenate the labels 0,1 real and fake\n",
    "#############################################################################################################################################################\n",
    "\n",
    "\n",
    "train_ori_actor_labels_real = np.zeros(len(train_hog_ori_actor_real), dtype=int)\n",
    "train_ori_youtube_labels_real = np.zeros(len(train_hog_ori_youtube_real), dtype=int)\n",
    "train_mni_dfd_labels_fake = np.ones(len(train_hog_mni_dfd_fake), dtype=int)\n",
    "train_mni_df_labels_fake = np.ones(len(train_hog_mni_df_fake), dtype=int)\n",
    "train_mni_f2f_labels_fake = np.ones(len(train_hog_mni_f2f_fake), dtype=int)\n",
    "train_mni_fshifter_labels_fake = np.ones(len(train_hog_mni_fshifter_fake), dtype=int)\n",
    "train_mni_fswap_labels_fake = np.ones(len(train_hog_mni_fswap_fake), dtype=int)\n",
    "train_mni_nt_labels_fake = np.ones(len(train_hog_mni_nt_fake), dtype=int)\n",
    "\n",
    "test_ori_actor_labels_real = np.zeros(len(ori_actor_test_real), dtype=int)\n",
    "test_ori_youtube_labels_real = np.zeros(len(ori_youtube_test_real), dtype=int)\n",
    "test_mni_dfd_labels_fake = np.ones(len(mni_dfd_test_fake), dtype=int)\n",
    "test_mni_df_labels_fake = np.ones(len(mni_df_test_fake), dtype=int)\n",
    "test_mni_f2f_labels_fake = np.ones(len(mni_f2f_test_fake), dtype=int)\n",
    "test_mni_fshifter_labels_fake = np.ones(len(mni_fshifter_test_fake), dtype=int)\n",
    "test_mni_fswap_labels_fake = np.ones(len(mni_fswap_test_fake), dtype=int)\n",
    "test_mni_nt_labels_fake = np.ones(len(mni_nt_test_fake), dtype=int)\n",
    "\n",
    "\n",
    "val_ori_actor_labels_real = np.zeros(len(val_hog_ori_actor_real), dtype=int)\n",
    "val_ori_youtube_labels_real = np.zeros(len(val_hog_ori_youtube_real), dtype=int)\n",
    "val_mni_dfd_labels_fake = np.ones(len(val_hog_mni_dfd_fake), dtype=int)\n",
    "val_mni_df_labels_fake = np.ones(len(val_hog_mni_df_fake), dtype=int)\n",
    "val_mni_f2f_labels_fake = np.ones(len(val_hog_mni_f2f_fake), dtype=int)\n",
    "val_mni_fshifter_labels_fake = np.ones(len(val_hog_mni_fshifter_fake), dtype=int)\n",
    "val_mni_fswap_labels_fake = np.ones(len(val_hog_mni_fswap_fake), dtype=int)\n",
    "val_mni_nt_labels_fake = np.ones(len(val_hog_mni_nt_fake), dtype=int)\n",
    "##################################################################################################################\n",
    "\n",
    "# Concatenate all training datasets into a single `train` variable\n",
    "train_ff = np.concatenate([train_hog_ori_actor_real, train_hog_ori_youtube_real,train_hog_mni_dfd_fake,train_hog_mni_df_fake,\n",
    "                            train_hog_mni_f2f_fake,train_hog_mni_fshifter_fake,train_hog_mni_fswap_fake,train_hog_mni_nt_fake], axis=0)\n",
    "\n",
    "train_labels_ff = np.concatenate([train_ori_actor_labels_real, train_ori_youtube_labels_real,train_mni_dfd_labels_fake,train_mni_df_labels_fake,\n",
    "                            train_mni_f2f_labels_fake,train_mni_fshifter_labels_fake,train_mni_fswap_labels_fake,train_mni_nt_labels_fake], axis=0)\n",
    "\n",
    "# Concatenate all validation datasets into a single `val` variable\n",
    "val_ff = np.concatenate([val_hog_ori_actor_real, val_hog_ori_youtube_real, val_hog_mni_dfd_fake, val_hog_mni_df_fake,\n",
    "                            val_hog_mni_f2f_fake, val_hog_mni_fshifter_fake, val_hog_mni_fswap_fake, val_hog_mni_nt_fake], axis=0)\n",
    "val_labels_ff = np.concatenate([val_ori_actor_labels_real, val_ori_youtube_labels_real, val_mni_dfd_labels_fake, val_mni_df_labels_fake,\n",
    "                            val_mni_f2f_labels_fake, val_mni_fshifter_labels_fake, val_mni_fswap_labels_fake, val_mni_nt_labels_fake], axis=0)\n",
    "# Concatenate all testing datasets into a single `test` variable\n",
    "test_ff = np.concatenate([ori_actor_test_real, ori_youtube_test_real, mni_dfd_test_fake,\n",
    "                           mni_df_test_fake, mni_f2f_test_fake, mni_fshifter_test_fake,\n",
    "                           mni_fswap_test_fake, mni_nt_test_fake], axis=0)\n",
    "test_labels_ff = np.concatenate([test_ori_actor_labels_real, test_ori_youtube_labels_real, test_mni_dfd_labels_fake, test_mni_df_labels_fake,\n",
    "                            test_mni_f2f_labels_fake, test_mni_fshifter_labels_fake, test_mni_fswap_labels_fake, test_mni_nt_labels_fake], axis=0)\n",
    "\n",
    "\n",
    "# Print the results for verification\n",
    "# Print the results for verification\n",
    "print(f\"Total train: {len(train_ff)} images, and shape:{train_ff.shape}\")\n",
    "print(f\"Total test: {len(test_ff)} images, and shape:{test_ff.shape}\")\n",
    "print(f\"Total val: {len(val_ff)} images, and shape:{val_ff.shape}\")\n",
    "\n",
    "\n",
    "# Print results for verification\n",
    "print(f\"Train Labels: {len(train_labels_ff)} \")\n",
    "print(f\"Test Labels: {len(test_labels_ff)} \")\n",
    "print(f\"Val Labels: {len(val_labels_ff)} \")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7a4081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "353/353 [==============================] - 8s 13ms/step - loss: 0.8498 - accuracy: 0.6384 - val_loss: 0.5851 - val_accuracy: 0.7221\n",
      "Epoch 2/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.6294 - accuracy: 0.7025 - val_loss: 0.5845 - val_accuracy: 0.7349\n",
      "Epoch 3/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.6016 - accuracy: 0.7208 - val_loss: 0.5733 - val_accuracy: 0.7325\n",
      "Epoch 4/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.5866 - accuracy: 0.7213 - val_loss: 0.5699 - val_accuracy: 0.7317\n",
      "Epoch 5/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5761 - accuracy: 0.7283 - val_loss: 0.5643 - val_accuracy: 0.7309\n",
      "Epoch 6/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5682 - accuracy: 0.7323 - val_loss: 0.5611 - val_accuracy: 0.7325\n",
      "Epoch 7/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5653 - accuracy: 0.7300 - val_loss: 0.5584 - val_accuracy: 0.7325\n",
      "Epoch 8/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5630 - accuracy: 0.7293 - val_loss: 0.5577 - val_accuracy: 0.7309\n",
      "Epoch 9/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.5604 - accuracy: 0.7296 - val_loss: 0.5580 - val_accuracy: 0.7317\n",
      "Epoch 10/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.5579 - accuracy: 0.7314 - val_loss: 0.5568 - val_accuracy: 0.7317\n",
      "Epoch 11/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5549 - accuracy: 0.7318 - val_loss: 0.5568 - val_accuracy: 0.7333\n",
      "Epoch 12/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.5530 - accuracy: 0.7339 - val_loss: 0.5577 - val_accuracy: 0.7325\n",
      "Epoch 13/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.5532 - accuracy: 0.7335 - val_loss: 0.5547 - val_accuracy: 0.7317\n",
      "Epoch 14/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.5518 - accuracy: 0.7333 - val_loss: 0.5538 - val_accuracy: 0.7317\n",
      "Epoch 15/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5503 - accuracy: 0.7311 - val_loss: 0.5523 - val_accuracy: 0.7317\n",
      "Epoch 16/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5492 - accuracy: 0.7325 - val_loss: 0.5509 - val_accuracy: 0.7293\n",
      "Epoch 17/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5477 - accuracy: 0.7347 - val_loss: 0.5550 - val_accuracy: 0.7293\n",
      "Epoch 18/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5483 - accuracy: 0.7368 - val_loss: 0.5495 - val_accuracy: 0.7333\n",
      "Epoch 19/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5467 - accuracy: 0.7357 - val_loss: 0.5487 - val_accuracy: 0.7365\n",
      "Epoch 20/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.5443 - accuracy: 0.7387 - val_loss: 0.5493 - val_accuracy: 0.7333\n",
      "Epoch 21/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5441 - accuracy: 0.7367 - val_loss: 0.5451 - val_accuracy: 0.7309\n",
      "Epoch 22/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5421 - accuracy: 0.7394 - val_loss: 0.5455 - val_accuracy: 0.7325\n",
      "Epoch 23/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5416 - accuracy: 0.7385 - val_loss: 0.5441 - val_accuracy: 0.7333\n",
      "Epoch 24/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5399 - accuracy: 0.7399 - val_loss: 0.5450 - val_accuracy: 0.7357\n",
      "Epoch 25/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5383 - accuracy: 0.7416 - val_loss: 0.5420 - val_accuracy: 0.7365\n",
      "Epoch 26/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5343 - accuracy: 0.7462 - val_loss: 0.5476 - val_accuracy: 0.7412\n",
      "Epoch 27/100\n",
      "353/353 [==============================] - 10s 30ms/step - loss: 0.5333 - accuracy: 0.7426 - val_loss: 0.5375 - val_accuracy: 0.7341\n",
      "Epoch 28/100\n",
      "353/353 [==============================] - 10s 28ms/step - loss: 0.5334 - accuracy: 0.7450 - val_loss: 0.5427 - val_accuracy: 0.7476\n",
      "Epoch 29/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.5322 - accuracy: 0.7484 - val_loss: 0.5446 - val_accuracy: 0.7428\n",
      "Epoch 30/100\n",
      "353/353 [==============================] - 10s 27ms/step - loss: 0.5306 - accuracy: 0.7472 - val_loss: 0.5360 - val_accuracy: 0.7373\n",
      "Epoch 31/100\n",
      "353/353 [==============================] - 13s 36ms/step - loss: 0.5299 - accuracy: 0.7463 - val_loss: 0.5359 - val_accuracy: 0.7373\n",
      "Epoch 32/100\n",
      "353/353 [==============================] - 12s 34ms/step - loss: 0.5290 - accuracy: 0.7479 - val_loss: 0.5426 - val_accuracy: 0.7396\n",
      "Epoch 33/100\n",
      "353/353 [==============================] - 12s 34ms/step - loss: 0.5275 - accuracy: 0.7504 - val_loss: 0.5333 - val_accuracy: 0.7444\n",
      "Epoch 34/100\n",
      "353/353 [==============================] - 12s 34ms/step - loss: 0.5230 - accuracy: 0.7535 - val_loss: 0.5319 - val_accuracy: 0.7460\n",
      "Epoch 35/100\n",
      "353/353 [==============================] - 12s 33ms/step - loss: 0.5248 - accuracy: 0.7510 - val_loss: 0.5378 - val_accuracy: 0.7373\n",
      "Epoch 36/100\n",
      "353/353 [==============================] - 12s 33ms/step - loss: 0.5242 - accuracy: 0.7544 - val_loss: 0.5283 - val_accuracy: 0.7548\n",
      "Epoch 37/100\n",
      "353/353 [==============================] - 11s 30ms/step - loss: 0.5210 - accuracy: 0.7542 - val_loss: 0.5295 - val_accuracy: 0.7468\n",
      "Epoch 38/100\n",
      "353/353 [==============================] - 7s 19ms/step - loss: 0.5202 - accuracy: 0.7550 - val_loss: 0.5264 - val_accuracy: 0.7428\n",
      "Epoch 39/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5179 - accuracy: 0.7574 - val_loss: 0.5270 - val_accuracy: 0.7444\n",
      "Epoch 40/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5173 - accuracy: 0.7560 - val_loss: 0.5265 - val_accuracy: 0.7484\n",
      "Epoch 41/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5149 - accuracy: 0.7554 - val_loss: 0.5384 - val_accuracy: 0.7365\n",
      "Epoch 42/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5142 - accuracy: 0.7591 - val_loss: 0.5255 - val_accuracy: 0.7452\n",
      "Epoch 43/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.5131 - accuracy: 0.7580 - val_loss: 0.5338 - val_accuracy: 0.7444\n",
      "Epoch 44/100\n",
      "353/353 [==============================] - 10s 29ms/step - loss: 0.5094 - accuracy: 0.7582 - val_loss: 0.5258 - val_accuracy: 0.7389\n",
      "Epoch 45/100\n",
      "353/353 [==============================] - 12s 33ms/step - loss: 0.5116 - accuracy: 0.7595 - val_loss: 0.5241 - val_accuracy: 0.7412\n",
      "Epoch 46/100\n",
      "353/353 [==============================] - 11s 32ms/step - loss: 0.5082 - accuracy: 0.7636 - val_loss: 0.5344 - val_accuracy: 0.7428\n",
      "Epoch 47/100\n",
      "353/353 [==============================] - 12s 35ms/step - loss: 0.5079 - accuracy: 0.7617 - val_loss: 0.5253 - val_accuracy: 0.7412\n",
      "Epoch 48/100\n",
      "353/353 [==============================] - 11s 32ms/step - loss: 0.5038 - accuracy: 0.7640 - val_loss: 0.5294 - val_accuracy: 0.7476\n",
      "Epoch 49/100\n",
      "353/353 [==============================] - 10s 29ms/step - loss: 0.5018 - accuracy: 0.7680 - val_loss: 0.5239 - val_accuracy: 0.7492\n",
      "Epoch 50/100\n",
      "353/353 [==============================] - 11s 32ms/step - loss: 0.5044 - accuracy: 0.7652 - val_loss: 0.5283 - val_accuracy: 0.7476\n",
      "Epoch 51/100\n",
      "353/353 [==============================] - 11s 31ms/step - loss: 0.5018 - accuracy: 0.7634 - val_loss: 0.5227 - val_accuracy: 0.7476\n",
      "Epoch 52/100\n",
      "353/353 [==============================] - 11s 32ms/step - loss: 0.5018 - accuracy: 0.7682 - val_loss: 0.5264 - val_accuracy: 0.7508\n",
      "Epoch 53/100\n",
      "353/353 [==============================] - 11s 31ms/step - loss: 0.4981 - accuracy: 0.7689 - val_loss: 0.5339 - val_accuracy: 0.7524\n",
      "Epoch 54/100\n",
      "353/353 [==============================] - 11s 32ms/step - loss: 0.4948 - accuracy: 0.7722 - val_loss: 0.5258 - val_accuracy: 0.7484\n",
      "Epoch 55/100\n",
      "353/353 [==============================] - 11s 31ms/step - loss: 0.4978 - accuracy: 0.7686 - val_loss: 0.5308 - val_accuracy: 0.7420\n",
      "Epoch 56/100\n",
      "353/353 [==============================] - 11s 32ms/step - loss: 0.4955 - accuracy: 0.7712 - val_loss: 0.5244 - val_accuracy: 0.7404\n",
      "Epoch 57/100\n",
      "353/353 [==============================] - 11s 32ms/step - loss: 0.4920 - accuracy: 0.7712 - val_loss: 0.5228 - val_accuracy: 0.7468\n",
      "Epoch 58/100\n",
      "353/353 [==============================] - 11s 32ms/step - loss: 0.4942 - accuracy: 0.7709 - val_loss: 0.5520 - val_accuracy: 0.7357\n",
      "Epoch 59/100\n",
      "353/353 [==============================] - 6s 17ms/step - loss: 0.4950 - accuracy: 0.7721 - val_loss: 0.5262 - val_accuracy: 0.7508\n",
      "Epoch 60/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4929 - accuracy: 0.7725 - val_loss: 0.5240 - val_accuracy: 0.7452\n",
      "Epoch 61/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4877 - accuracy: 0.7761 - val_loss: 0.5267 - val_accuracy: 0.7492\n",
      "Epoch 62/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4860 - accuracy: 0.7775 - val_loss: 0.5232 - val_accuracy: 0.7564\n",
      "Epoch 63/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4870 - accuracy: 0.7775 - val_loss: 0.5260 - val_accuracy: 0.7476\n",
      "Epoch 64/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4857 - accuracy: 0.7787 - val_loss: 0.5212 - val_accuracy: 0.7532\n",
      "Epoch 65/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4821 - accuracy: 0.7785 - val_loss: 0.5378 - val_accuracy: 0.7484\n",
      "Epoch 66/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4802 - accuracy: 0.7799 - val_loss: 0.5419 - val_accuracy: 0.7476\n",
      "Epoch 67/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.4787 - accuracy: 0.7789 - val_loss: 0.5302 - val_accuracy: 0.7508\n",
      "Epoch 68/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4745 - accuracy: 0.7857 - val_loss: 0.5238 - val_accuracy: 0.7452\n",
      "Epoch 69/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4770 - accuracy: 0.7853 - val_loss: 0.5385 - val_accuracy: 0.7420\n",
      "Epoch 70/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4756 - accuracy: 0.7829 - val_loss: 0.5263 - val_accuracy: 0.7476\n",
      "Epoch 71/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.4768 - accuracy: 0.7845 - val_loss: 0.5356 - val_accuracy: 0.7476\n",
      "Epoch 72/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.4719 - accuracy: 0.7860 - val_loss: 0.5225 - val_accuracy: 0.7468\n",
      "Epoch 73/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.4743 - accuracy: 0.7866 - val_loss: 0.5277 - val_accuracy: 0.7468\n",
      "Epoch 74/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.4712 - accuracy: 0.7855 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 75/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.4690 - accuracy: 0.7883 - val_loss: 0.5551 - val_accuracy: 0.7389\n",
      "Epoch 76/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.4679 - accuracy: 0.7892 - val_loss: 0.5400 - val_accuracy: 0.7516\n",
      "Epoch 77/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.4698 - accuracy: 0.7869 - val_loss: 0.5330 - val_accuracy: 0.7492\n",
      "Epoch 78/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.4670 - accuracy: 0.7879 - val_loss: 0.5382 - val_accuracy: 0.7436\n",
      "Epoch 79/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.4649 - accuracy: 0.7905 - val_loss: 0.5298 - val_accuracy: 0.7572\n",
      "Epoch 80/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4630 - accuracy: 0.7893 - val_loss: 0.5325 - val_accuracy: 0.7484\n",
      "Epoch 81/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4631 - accuracy: 0.7924 - val_loss: 0.5298 - val_accuracy: 0.7436\n",
      "Epoch 82/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4605 - accuracy: 0.7874 - val_loss: 0.5379 - val_accuracy: 0.7452\n",
      "Epoch 83/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4541 - accuracy: 0.7957 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 84/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.4601 - accuracy: 0.7933 - val_loss: 0.5337 - val_accuracy: 0.7420\n",
      "Epoch 85/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4481 - accuracy: 0.7971 - val_loss: 0.5317 - val_accuracy: 0.7428\n",
      "Epoch 86/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4507 - accuracy: 0.7949 - val_loss: 0.5414 - val_accuracy: 0.7436\n",
      "Epoch 87/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4544 - accuracy: 0.7943 - val_loss: 0.5428 - val_accuracy: 0.7420\n",
      "Epoch 88/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4490 - accuracy: 0.8006 - val_loss: 0.5335 - val_accuracy: 0.7476\n",
      "Epoch 89/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.4499 - accuracy: 0.7985 - val_loss: 0.5326 - val_accuracy: 0.7500\n",
      "Epoch 90/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.4488 - accuracy: 0.7972 - val_loss: 0.5389 - val_accuracy: 0.7468\n",
      "Epoch 91/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4428 - accuracy: 0.8040 - val_loss: 0.5381 - val_accuracy: 0.7556\n",
      "Epoch 92/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4425 - accuracy: 0.8030 - val_loss: 0.5323 - val_accuracy: 0.7476\n",
      "Epoch 93/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4411 - accuracy: 0.8042 - val_loss: 0.5382 - val_accuracy: 0.7508\n",
      "Epoch 94/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4418 - accuracy: 0.8032 - val_loss: 0.5391 - val_accuracy: 0.7484\n",
      "Epoch 95/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4415 - accuracy: 0.7993 - val_loss: 0.5453 - val_accuracy: 0.7476\n",
      "Epoch 96/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4339 - accuracy: 0.8036 - val_loss: 0.5327 - val_accuracy: 0.7420\n",
      "Epoch 97/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4372 - accuracy: 0.8055 - val_loss: 0.5424 - val_accuracy: 0.7548\n",
      "Epoch 98/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.4364 - accuracy: 0.8031 - val_loss: 0.5449 - val_accuracy: 0.7444\n",
      "Epoch 99/100\n",
      "353/353 [==============================] - 4s 11ms/step - loss: 0.4345 - accuracy: 0.8050 - val_loss: 0.5372 - val_accuracy: 0.7484\n",
      "Epoch 100/100\n",
      "353/353 [==============================] - 4s 12ms/step - loss: 0.4368 - accuracy: 0.8039 - val_loss: 0.5384 - val_accuracy: 0.7572\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ff, train_labels_ff,\n",
    "    validation_data=(val_ff, val_labels_ff),\n",
    "    epochs=100,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59aa49e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 1s 5ms/step - loss: 0.5467 - accuracy: 0.7490\n",
      "\n",
      "Test Accuracy of FF++ on MesoNet: 74.90%\n",
      "169/169 [==============================] - 1s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.30      0.39      1468\n",
      "           1       0.78      0.92      0.84      3911\n",
      "\n",
      "    accuracy                           0.75      5379\n",
      "   macro avg       0.68      0.61      0.62      5379\n",
      "weighted avg       0.72      0.75      0.72      5379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test_ff, test_labels_ff)\n",
    "print(f'\\nTest Accuracy of FF++ on MesoNet: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test_ff)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels_ff, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d84a37fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# After training the model\n",
    "model.save('mesonet_160_ff.h5')  # Saves the entire model to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "907ed965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 9.2%\n",
      "RAM Used: 4635.1 MB\n",
      "Time Usage: 615.6 s\n",
      "GPU Memory Used: 919.0 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e22ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA LOADING ===\n",
      "169/169 [==============================] - 4s 5ms/step - loss: 0.5467 - accuracy: 0.7490\n",
      "Test Accuracy of FF++ on MESONET: 74.90%\n",
      "\n",
      "=== RESOURCE USAGE ===\n",
      "CPU Usage: 1.0%\n",
      "RAM Used: 3296.4 MB\n",
      "Time Usage: 7.6 s\n",
      "GPU Memory Used: 394.2 MB\n",
      "Power Consumption: 93W\n"
     ]
    }
   ],
   "source": [
    "print(\"=== DATA LOADING ===\")\n",
    "start = monitor.get_stats()\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('mesonet_160_ff.h5')\n",
    "test_loss, test_acc = model.evaluate(test_ff, test_labels_ff)\n",
    "print(f'Test Accuracy of FF++ on MESONET: {test_acc * 100:.2f}%')\n",
    "# You can now use the model for testing or inference\n",
    "# Your data loading operations here\n",
    "time.sleep(2)  # Simulate loading time\n",
    "\n",
    "end = monitor.get_stats()\n",
    "duration = end['timestamp'] - start['timestamp']\n",
    "\n",
    "print(\"\\n=== RESOURCE USAGE ===\")\n",
    "print(f\"CPU Usage: {end['cpu_%']:.1f}%\")\n",
    "print(f\"RAM Used: {end['ram_mb'] - start['ram_mb']:.1f} MB\")\n",
    "print(f\"Time Usage: {duration:.1f} s\")\n",
    "print(f\"GPU Memory Used: {end['gpu_mem_mb']:.1f} MB\")\n",
    "print(f\"Power Consumption: {int(end['power_w'])}W\")  # Rounded to whole watts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c667401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 1s 4ms/step - loss: 0.5467 - accuracy: 0.7490\n",
      "Test Accuracy of DFC on MESONET: 74.90%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('mesonet_160_ff.h5')\n",
    "test_loss, test_acc = model.evaluate(test_ff, test_labels_ff)\n",
    "print(f'Test Accuracy of DFC on MESONET: {test_acc * 100:.2f}%')\n",
    "# You can now use the model for testing or inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf55da44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 4ms/step - loss: 0.9306 - accuracy: 0.5257\n",
      "Test Accuracy of DFC on MESONET from FF++: 52.57%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('mesonet_160_ff.h5')\n",
    "test_loss, test_acc = model.evaluate(test_hog, test_labels)\n",
    "print(f'Test Accuracy of DFC on MESONET from FF++: {test_acc * 100:.2f}%')\n",
    "# You can now use the model for testing or inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3a6f47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340/340 [==============================] - 9s 5ms/step - loss: 0.6711 - accuracy: 0.7260\n",
      "\n",
      "Test Accuracy of Celeb-df dataset on MESONET for FF++: 72.60%\n",
      "340/340 [==============================] - 1s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.01      0.01      2961\n",
      "           1       0.73      1.00      0.84      7891\n",
      "\n",
      "    accuracy                           0.73     10852\n",
      "   macro avg       0.55      0.50      0.43     10852\n",
      "weighted avg       0.63      0.73      0.61     10852\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('mesonet_160_ff.h5')\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc = model.evaluate(test, test_labels)\n",
    "print(f'\\nTest Accuracy of Celeb-df dataset on MESONET for FF++: {test_acc*100:.2f}%')\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(test)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_labels, y_pred_binary))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
